{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler,StandardScaler\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Concatenate, Add\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/Regression_data_preprocessing.csv')\n",
    "df\n",
    "target = 'Rings'\n",
    "X = df.drop([target], axis=1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test val split\n",
    "feature_cols = df.columns.tolist()\n",
    "feature_cols.remove('Rings')\n",
    "target_cols = ['Rings']\n",
    "remove_list = ['Sex_I','Sex_F','Sex_M']\n",
    "for col in remove_list:\n",
    "    feature_cols.remove(col)\n",
    "pipeline = Pipeline([('normalizer', Normalizer()),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size= 0.2, random_state = 42)\n",
    "y_train, y_test = train_test_split(y, test_size= 0.2, random_state = 42)\n",
    "X_train, X_val = train_test_split(X_train, test_size = 0.25, random_state = 42)\n",
    "y_train, y_val = train_test_split(y_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# pipeline을 통해 normalize와 standard scaler 적용\n",
    "X_train[feature_cols] = pipeline.fit_transform(X_train[feature_cols])\n",
    "X_test[feature_cols] = pipeline.transform(X_test[feature_cols])\n",
    "X_val[feature_cols] = pipeline.transform(X_val[feature_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_opt2(n):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=n)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return 1 - tf.abs((y_true - y_pred) / y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Concatenate, Add, BatchNormalization, Activation, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 - 0s - loss: 4.7266 - accuracy: 0.8281 - 55ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.8570 - accuracy: 0.8248 - 55ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.7976 - accuracy: 0.8309 - 73ms/epoch - 3ms/step\n",
      "27/27 - 0s - loss: 4.9594 - accuracy: 0.8262 - 47ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.6892 - accuracy: 0.8284 - 52ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.8547 - accuracy: 0.8383 - 46ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.8272 - accuracy: 0.8390 - 45ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.8336 - accuracy: 0.8320 - 50ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.8142 - accuracy: 0.8436 - 45ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.8913 - accuracy: 0.8432 - 63ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 5.1846 - accuracy: 0.8373 - 56ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 5.1768 - accuracy: 0.8366 - 54ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.9422 - accuracy: 0.8367 - 53ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 5.0476 - accuracy: 0.8397 - 45ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 5.3087 - accuracy: 0.8319 - 46ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 5.2022 - accuracy: 0.8335 - 61ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 5.1535 - accuracy: 0.8382 - 51ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 5.1814 - accuracy: 0.8390 - 49ms/epoch - 2ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mj985\\Section4\\team\\run\\zz.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mj985/Section4/team/run/zz.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mj985/Section4/team/run/zz.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mj985/Section4/team/run/zz.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), callbacks\u001b[39m=\u001b[39;49m[early_stopping],verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mj985/Section4/team/run/zz.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mj985/Section4/team/run/zz.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m val_loss, val_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_val, y_val, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\keras\\engine\\training.py:1676\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1674\u001b[0m callbacks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1675\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1676\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   1677\u001b[0m         \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m             epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m             _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m         ):\n\u001b[0;32m   1684\u001b[0m             callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\keras\\engine\\data_adapter.py:1375\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1375\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m   1376\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[0;32m   1377\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1378\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m original_spe\n\u001b[0;32m   1380\u001b[0m )\n\u001b[0;32m   1382\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:647\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    646\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 647\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    648\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    649\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:774\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \n\u001b[0;32m    767\u001b[0m \u001b[39mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[39m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    773\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mRead\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 774\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n\u001b[0;32m    775\u001b[0m \u001b[39m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    776\u001b[0m \u001b[39m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:753\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    751\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    752\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 753\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    755\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    756\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    757\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    758\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[0;32m    759\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[0;32m    760\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    761\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:743\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m    742\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[1;32m--> 743\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[0;32m    744\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[0;32m    745\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[0;32m    746\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:580\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    579\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 580\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    581\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, resource, \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype)\n\u001b[0;32m    582\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    583\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(X_train.shape[1],))\n",
    "hidden1a = Dense(128, activation='relu')(input_layer)\n",
    "hidden1b = Dense(128, activation='relu')(input_layer)\n",
    "hidden1 = Concatenate()([hidden1a, hidden1b])\n",
    "dropout1 = Dropout(0.2)(hidden1)\n",
    "\n",
    "hidden2a = Dense(64, activation='relu')(dropout1)\n",
    "hidden2b = Dense(64, activation='relu')(dropout1)\n",
    "hidden2 = Add()([hidden2a, hidden2b])\n",
    "dropout2 = Dropout(0.2)(hidden2)\n",
    "\n",
    "hidden3a = Dense(32, activation='relu')(dropout2)\n",
    "hidden3b = Dense(32, activation='relu')(dropout2)\n",
    "hidden3 = Concatenate()([hidden3a, hidden3b])\n",
    "dropout3 = Dropout(0.2)(hidden3)\n",
    "\n",
    "output_layer = Dense(1)(dropout3)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "batch_lst = [8, 32, 64, 128, 256]\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for i in [0.01,0.006,0.003,0.001,0.0001]:\n",
    "    for batch in batch_lst:\n",
    "                \n",
    "        # 모델 컴파일\n",
    "        model.compile(loss='mse', optimizer=custom_opt2(i), metrics=[accuracy])\n",
    "\n",
    "        # early stopping 구현 - 커스텀 정확도 기준\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=30)\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping],verbose = 0)\n",
    "        end_time = time.time()\n",
    "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "                best_accuracy = val_acc\n",
    "                best_hyperparams = {'batch_size': batch, 'learning_rate': i}\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 오르지 않는 것으로 확인 배제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_accuracy, best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 - 0s - loss: 5.8677 - accuracy: 0.7982 - 161ms/epoch - 6ms/step\n",
      "27/27 - 0s - loss: 4.7515 - accuracy: 0.8316 - 162ms/epoch - 6ms/step\n",
      "27/27 - 0s - loss: 4.6510 - accuracy: 0.8344 - 152ms/epoch - 6ms/step\n",
      "27/27 - 0s - loss: 4.5211 - accuracy: 0.8408 - 144ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.8068 - accuracy: 0.8417 - 127ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.6618 - accuracy: 0.8430 - 131ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.6025 - accuracy: 0.8499 - 143ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.5071 - accuracy: 0.8506 - 145ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.4481 - accuracy: 0.8435 - 148ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.4161 - accuracy: 0.8443 - 147ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.5057 - accuracy: 0.8449 - 139ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.3545 - accuracy: 0.8499 - 140ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.3542 - accuracy: 0.8500 - 138ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.4735 - accuracy: 0.8407 - 141ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.4031 - accuracy: 0.8419 - 139ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.5702 - accuracy: 0.8405 - 139ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.3151 - accuracy: 0.8514 - 135ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.3257 - accuracy: 0.8491 - 140ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.3638 - accuracy: 0.8469 - 140ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.3307 - accuracy: 0.8467 - 141ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.4686 - accuracy: 0.8416 - 140ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.3044 - accuracy: 0.8491 - 135ms/epoch - 5ms/step\n",
      "27/27 - 0s - loss: 4.3126 - accuracy: 0.8485 - 155ms/epoch - 6ms/step\n",
      "27/27 - 0s - loss: 4.3265 - accuracy: 0.8473 - 152ms/epoch - 6ms/step\n",
      "27/27 - 0s - loss: 4.3375 - accuracy: 0.8462 - 150ms/epoch - 6ms/step\n",
      "0.8514037728309631 {'batch_size': 32, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(X_train.shape[1],))\n",
    "hidden1a = Dense(128, kernel_regularizer=l2(0.001))(input_layer)\n",
    "hidden1a = BatchNormalization()(hidden1a)\n",
    "hidden1a = Activation('relu')(hidden1a)\n",
    "\n",
    "hidden1b = Dense(128, kernel_regularizer=l2(0.001))(input_layer)\n",
    "hidden1b = BatchNormalization()(hidden1b)\n",
    "hidden1b = Activation('relu')(hidden1b)\n",
    "\n",
    "hidden1c = Dense(128, kernel_regularizer=l2(0.001))(input_layer)\n",
    "hidden1c = BatchNormalization()(hidden1c)\n",
    "hidden1c = Activation('relu')(hidden1c)\n",
    "\n",
    "hidden1d = Dense(128, kernel_regularizer=l2(0.001))(input_layer)\n",
    "hidden1d = BatchNormalization()(hidden1d)\n",
    "hidden1d = Activation('relu')(hidden1d)\n",
    "\n",
    "hidden1 = Concatenate()([hidden1a, hidden1b, hidden1c, hidden1d])\n",
    "dropout1 = Dropout(0.2)(hidden1)\n",
    "\n",
    "hidden2a = Dense(64, kernel_regularizer=l2(0.001))(dropout1)\n",
    "hidden2a = BatchNormalization()(hidden2a)\n",
    "hidden2a = Activation('relu')(hidden2a)\n",
    "\n",
    "hidden2b = Dense(64, kernel_regularizer=l2(0.001))(dropout1)\n",
    "hidden2b = BatchNormalization()(hidden2b)\n",
    "hidden2b = Activation('relu')(hidden2b)\n",
    "\n",
    "hidden2c = Dense(64, kernel_regularizer=l2(0.001))(dropout1)\n",
    "hidden2c = BatchNormalization()(hidden2c)\n",
    "hidden2c = Activation('relu')(hidden2c)\n",
    "\n",
    "hidden2d = Dense(64, kernel_regularizer=l2(0.001))(dropout1)\n",
    "hidden2d = BatchNormalization()(hidden2d)\n",
    "hidden2d = Activation('relu')(hidden2d)\n",
    "\n",
    "hidden2 = Add()([hidden2a, hidden2b, hidden2c, hidden2d])\n",
    "dropout2 = Dropout(0.2)(hidden2)\n",
    "\n",
    "output_layer = Dense(1)(dropout2)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "batch_lst = [8, 32, 64, 128, 256]\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for i in [0.01,0.006,0.003,0.001,0.0005]:\n",
    "    for batch in batch_lst:\n",
    "                \n",
    "        # 모델 컴파일\n",
    "        model.compile(loss='mse', optimizer=custom_opt2(i), metrics=[accuracy])\n",
    "\n",
    "        # early stopping 구현 - 커스텀 정확도 기준\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_test, y_test), callbacks=[early_stopping],verbose = 0)\n",
    "        end_time = time.time()\n",
    "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "                best_accuracy = val_acc\n",
    "                best_hyperparams = {'batch_size': batch, 'learning_rate': i}\n",
    "        \n",
    "print(best_accuracy, best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 - 0s - loss: 4.3696 - accuracy: 0.8534 - 56ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.5673 - accuracy: 0.8339 - 56ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.5300 - accuracy: 0.8354 - 54ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.5354 - accuracy: 0.8308 - 59ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.5213 - accuracy: 0.8350 - 54ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.4513 - accuracy: 0.8497 - 55ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.4535 - accuracy: 0.8396 - 58ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3794 - accuracy: 0.8446 - 57ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.4008 - accuracy: 0.8393 - 55ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.5211 - accuracy: 0.8351 - 55ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.4714 - accuracy: 0.8430 - 57ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3982 - accuracy: 0.8385 - 55ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3816 - accuracy: 0.8388 - 54ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3546 - accuracy: 0.8408 - 56ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.4050 - accuracy: 0.8379 - 59ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3894 - accuracy: 0.8416 - 53ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3596 - accuracy: 0.8420 - 54ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3498 - accuracy: 0.8413 - 54ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3471 - accuracy: 0.8420 - 59ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3741 - accuracy: 0.8400 - 56ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3880 - accuracy: 0.8401 - 55ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3634 - accuracy: 0.8406 - 57ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3339 - accuracy: 0.8417 - 57ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3365 - accuracy: 0.8414 - 62ms/epoch - 2ms/step\n",
      "27/27 - 0s - loss: 4.3471 - accuracy: 0.8410 - 59ms/epoch - 2ms/step\n",
      "0.8534436225891113 {'batch_size': 10, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(X_train.shape[1],))\n",
    "hidden1a = Dense(10, kernel_regularizer=l2(0.001))(input_layer)\n",
    "hidden1a = BatchNormalization()(hidden1a)\n",
    "hidden1a = Activation('relu')(hidden1a)\n",
    "\n",
    "hidden1b = Dense(10, kernel_regularizer=l2(0.001))(input_layer)\n",
    "hidden1b = BatchNormalization()(hidden1b)\n",
    "hidden1b = Activation('relu')(hidden1b)\n",
    "\n",
    "hidden1c = Dense(10, kernel_regularizer=l2(0.001))(input_layer)\n",
    "hidden1c = BatchNormalization()(hidden1c)\n",
    "hidden1c = Activation('relu')(hidden1c)\n",
    "\n",
    "hidden1d = Dense(10, kernel_regularizer=l2(0.001))(input_layer)\n",
    "hidden1d = BatchNormalization()(hidden1d)\n",
    "hidden1d = Activation('relu')(hidden1d)\n",
    "\n",
    "hidden1 = Concatenate()([hidden1a, hidden1b, hidden1c, hidden1d])\n",
    "dropout1 = Dropout(0.2)(hidden1)\n",
    "\n",
    "hidden2a = Dense(5, kernel_regularizer=l2(0.001))(dropout1)\n",
    "hidden2a = BatchNormalization()(hidden2a)\n",
    "hidden2a = Activation('relu')(hidden2a)\n",
    "\n",
    "hidden2b = Dense(5, kernel_regularizer=l2(0.001))(dropout1)\n",
    "hidden2b = BatchNormalization()(hidden2b)\n",
    "hidden2b = Activation('relu')(hidden2b)\n",
    "\n",
    "hidden2c = Dense(5, kernel_regularizer=l2(0.001))(dropout1)\n",
    "hidden2c = BatchNormalization()(hidden2c)\n",
    "hidden2c = Activation('relu')(hidden2c)\n",
    "\n",
    "hidden2d = Dense(5, kernel_regularizer=l2(0.001))(dropout1)\n",
    "hidden2d = BatchNormalization()(hidden2d)\n",
    "hidden2d = Activation('relu')(hidden2d)\n",
    "\n",
    "hidden2 = Add()([hidden2a, hidden2b, hidden2c, hidden2d])\n",
    "dropout2 = Dropout(0.2)(hidden2)\n",
    "\n",
    "output_layer = Dense(1)(dropout2)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "batch_lst = [10, 40, 80, 160, 320]\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for i in [0.01,0.006,0.003,0.001,0.0005]:\n",
    "    for batch in batch_lst:\n",
    "                \n",
    "        # 모델 컴파일\n",
    "        model.compile(loss='mse', optimizer=custom_opt2(i), metrics=[accuracy])\n",
    "\n",
    "        # early stopping 구현 - 커스텀 정확도 기준\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_test, y_test), callbacks=[early_stopping],verbose = 0)\n",
    "        end_time = time.time()\n",
    "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "                best_accuracy = val_acc\n",
    "                best_hyperparams = {'batch_size': batch, 'learning_rate': i}\n",
    "        \n",
    "print(best_accuracy, best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 - 0s - loss: 6.0189 - accuracy: 0.8288 - 430ms/epoch - 16ms/step\n",
      "27/27 - 0s - loss: 6.6861 - accuracy: 0.8098 - 446ms/epoch - 17ms/step\n",
      "27/27 - 0s - loss: 5.1090 - accuracy: 0.8540 - 417ms/epoch - 15ms/step\n",
      "27/27 - 0s - loss: 5.4157 - accuracy: 0.8412 - 399ms/epoch - 15ms/step\n",
      "27/27 - 0s - loss: 5.5428 - accuracy: 0.8359 - 441ms/epoch - 16ms/step\n",
      "27/27 - 0s - loss: 6.1625 - accuracy: 0.8041 - 448ms/epoch - 17ms/step\n",
      "27/27 - 0s - loss: 4.8455 - accuracy: 0.8361 - 414ms/epoch - 15ms/step\n",
      "27/27 - 0s - loss: 4.8560 - accuracy: 0.8328 - 432ms/epoch - 16ms/step\n",
      "27/27 - 0s - loss: 4.8151 - accuracy: 0.8256 - 422ms/epoch - 16ms/step\n",
      "27/27 - 0s - loss: 4.8988 - accuracy: 0.8279 - 383ms/epoch - 14ms/step\n",
      "27/27 - 0s - loss: 4.8433 - accuracy: 0.8316 - 402ms/epoch - 15ms/step\n",
      "27/27 - 0s - loss: 4.7076 - accuracy: 0.8279 - 376ms/epoch - 14ms/step\n",
      "27/27 - 0s - loss: 5.5292 - accuracy: 0.7913 - 383ms/epoch - 14ms/step\n",
      "27/27 - 0s - loss: 5.0235 - accuracy: 0.8098 - 369ms/epoch - 14ms/step\n",
      "27/27 - 0s - loss: 4.9502 - accuracy: 0.8174 - 374ms/epoch - 14ms/step\n",
      "27/27 - 0s - loss: 4.8057 - accuracy: 0.8209 - 361ms/epoch - 13ms/step\n",
      "27/27 - 0s - loss: 4.6398 - accuracy: 0.8306 - 370ms/epoch - 14ms/step\n",
      "27/27 - 0s - loss: 4.3664 - accuracy: 0.8465 - 365ms/epoch - 14ms/step\n",
      "27/27 - 0s - loss: 4.5557 - accuracy: 0.8304 - 339ms/epoch - 13ms/step\n",
      "27/27 - 0s - loss: 4.6511 - accuracy: 0.8260 - 344ms/epoch - 13ms/step\n",
      "27/27 - 0s - loss: 4.3612 - accuracy: 0.8477 - 379ms/epoch - 14ms/step\n",
      "27/27 - 0s - loss: 4.3121 - accuracy: 0.8486 - 415ms/epoch - 15ms/step\n",
      "27/27 - 0s - loss: 4.3241 - accuracy: 0.8500 - 358ms/epoch - 13ms/step\n",
      "27/27 - 0s - loss: 4.3879 - accuracy: 0.8461 - 366ms/epoch - 14ms/step\n",
      "27/27 - 0s - loss: 4.4509 - accuracy: 0.8378 - 367ms/epoch - 14ms/step\n",
      "0.8540346622467041 {'batch_size': 64, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(X_train.shape[1],))\n",
    "# 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1024, kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256, kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "batch_lst = [8, 32, 64, 128, 256]\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for i in [0.01,0.006,0.003,0.001,0.0005]:\n",
    "    for batch in batch_lst:\n",
    "                \n",
    "        # 모델 컴파일\n",
    "        model.compile(loss='mse', optimizer=custom_opt2(i), metrics=[accuracy])\n",
    "\n",
    "        # early stopping 구현 - 커스텀 정확도 기준\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_test, y_test), callbacks=[early_stopping],verbose = 0)\n",
    "        end_time = time.time()\n",
    "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "                best_accuracy = val_acc\n",
    "                best_hyperparams = {'batch_size': batch, 'learning_rate': i}\n",
    "        \n",
    "print(best_accuracy, best_hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 - 0s - loss: 5.4978 - accuracy: 0.8238 - 209ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 7.7990 - accuracy: 0.7624 - 210ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 4.8383 - accuracy: 0.8378 - 203ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 5.2432 - accuracy: 0.8324 - 207ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 4.9110 - accuracy: 0.8250 - 205ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 5.3643 - accuracy: 0.8102 - 213ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 5.0833 - accuracy: 0.8178 - 208ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 4.9616 - accuracy: 0.8152 - 198ms/epoch - 7ms/step\n",
      "27/27 - 0s - loss: 4.5266 - accuracy: 0.8431 - 198ms/epoch - 7ms/step\n",
      "27/27 - 0s - loss: 4.6163 - accuracy: 0.8382 - 192ms/epoch - 7ms/step\n",
      "27/27 - 0s - loss: 4.6403 - accuracy: 0.8378 - 183ms/epoch - 7ms/step\n",
      "27/27 - 0s - loss: 4.7271 - accuracy: 0.8334 - 185ms/epoch - 7ms/step\n",
      "27/27 - 0s - loss: 4.5664 - accuracy: 0.8362 - 209ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 4.5885 - accuracy: 0.8477 - 217ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 4.7148 - accuracy: 0.8264 - 230ms/epoch - 9ms/step\n",
      "27/27 - 0s - loss: 4.5302 - accuracy: 0.8489 - 268ms/epoch - 10ms/step\n",
      "27/27 - 0s - loss: 4.5083 - accuracy: 0.8366 - 206ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 4.3963 - accuracy: 0.8463 - 223ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 4.3944 - accuracy: 0.8419 - 223ms/epoch - 8ms/step\n",
      "27/27 - 0s - loss: 4.3905 - accuracy: 0.8424 - 233ms/epoch - 9ms/step\n",
      "27/27 - 0s - loss: 4.4087 - accuracy: 0.8409 - 256ms/epoch - 9ms/step\n",
      "27/27 - 0s - loss: 4.3916 - accuracy: 0.8420 - 245ms/epoch - 9ms/step\n",
      "27/27 - 0s - loss: 4.3222 - accuracy: 0.8460 - 243ms/epoch - 9ms/step\n",
      "27/27 - 0s - loss: 4.3484 - accuracy: 0.8434 - 253ms/epoch - 9ms/step\n",
      "27/27 - 0s - loss: 4.3564 - accuracy: 0.8455 - 271ms/epoch - 10ms/step\n",
      "0.848878800868988 {'batch_size': 10, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(X_train.shape[1],))\n",
    "# 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Dense(160, input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(320, kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(640, kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(320, kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(160, kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "batch_lst = [10, 20, 40, 80, 160]\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for i in [0.01,0.006,0.003,0.001,0.0005]:\n",
    "    for batch in batch_lst:\n",
    "                \n",
    "        # 모델 컴파일\n",
    "        model.compile(loss='mse', optimizer=custom_opt2(i), metrics=[accuracy])\n",
    "\n",
    "        # early stopping 구현 - 커스텀 정확도 기준\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_test, y_test), callbacks=[early_stopping],verbose = 0)\n",
    "        end_time = time.time()\n",
    "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "                best_accuracy = val_acc\n",
    "                best_hyperparams = {'batch_size': batch, 'learning_rate': i}\n",
    "        \n",
    "print(best_accuracy, best_hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.0585 - accuracy: 0.8491\n",
      "Validation Accuracy: 0.849108099937439\n",
      "0.006\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.5707 - accuracy: 0.8529\n",
      "Validation Accuracy: 0.8528792262077332\n",
      "0.003\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.4788 - accuracy: 0.8511\n",
      "Validation Accuracy: 0.8510699272155762\n",
      "0.001\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.5157 - accuracy: 0.8558\n",
      "Validation Accuracy: 0.855845034122467\n",
      "0.0005\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.6648 - accuracy: 0.8432\n",
      "Validation Accuracy: 0.8431747555732727\n"
     ]
    }
   ],
   "source": [
    "for i in [0.01,0.006,0.003,0.001,0.0005]:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.compile(optimizer=custom_opt2(i), loss='mean_squared_error', metrics=[accuracy])\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "\n",
    "    # 검증 정확도 확인\n",
    "    print(i)\n",
    "    _, val_acc = model.evaluate(X_test, y_test)\n",
    "    print(\"Validation Accuracy:\", val_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종\n",
    "\n",
    "- 올리는 것에 실패 기존 모델 사용.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0.01,0.006,0.003,0.001,0.0001]:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.compile(optimizer=custom_opt2(i), loss='mean_squared_error', metrics=[accuracy])\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "\n",
    "    # 검증 정확도 확인\n",
    "    print(i)\n",
    "    _, val_acc = model.evaluate(X_test, y_test)\n",
    "    print(\"Validation Accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.sort_index()\n",
    "# y_train = y_train.sort_index()\n",
    "# X_test = X_test.sort_index()\n",
    "# y_test = y_test.sort_index()\n",
    "# X_val = X_val.sort_index()\n",
    "# y_val = y_val.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "# # 모델 생성\n",
    "# model = Sequential()\n",
    "# model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# # 모델 컴파일\n",
    "# model.compile(optimizer=custom_opt2(0.001), loss='mean_squared_error', metrics=[accuracy])\n",
    "\n",
    "# # K-fold 교차 검증 실행\n",
    "# fold = 1\n",
    "# val_accuracies = []\n",
    "# for train_index, val_index in kf.split(X_train):\n",
    "#     print(\"Fold:\", fold)\n",
    "    \n",
    "#     # 학습 데이터와 검증 데이터 분할\n",
    "#     X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "#     y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "#     # 모델 학습\n",
    "#     model.fit(X_train_fold, y_train_fold, epochs=200, batch_size=32, verbose=0)\n",
    "    \n",
    "#     # 검증 정확도 평가\n",
    "#     _, val_acc = model.evaluate(X_val_fold, y_val_fold)\n",
    "#     val_accuracies.append(val_acc)\n",
    "    \n",
    "#     fold += 1\n",
    "\n",
    "# # K-fold 교차 검증의 평균 검증 정확도 계산\n",
    "# mean_val_accuracy = np.mean(val_accuracies)\n",
    "# print(\"Mean Validation Accuracy:\", mean_val_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
