{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import keras.utils\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 (EDA)과정 진행 후 데이터\n",
    "X_train = pd.read_csv('csv/Multi_to_share/Multi_to_share/Basic/X_basic_train.csv')\n",
    "X_test = pd.read_csv('csv/Multi_to_share/Multi_to_share/Basic/X_basic_test.csv')\n",
    "X_val = pd.read_csv('csv/Multi_to_share/Multi_to_share/Basic/X_basic_val.csv')\n",
    "y_train = pd.read_csv('csv/Multi_to_share/Multi_to_share/Basic/y_basic_train.csv')\n",
    "y_test = pd.read_csv('csv/Multi_to_share/Multi_to_share/Basic/y_basic_test.csv')\n",
    "y_val = pd.read_csv('csv/Multi_to_share/Multi_to_share/Basic/y_basic_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['class']\n",
    "y_test = y_test['class']\n",
    "y_val = y_val['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 맵핑\t\t\t\t\n",
    "label_map = {'Pastry': 0, 'Z_Scratch': 1, 'K_Scatch': 2, 'Stains': 3, 'Dirtiness': 4, 'Bumps': 5, 'Other_Faults': 6}\n",
    "y_train = [label_map[label] for label in y_train]\n",
    "y_test = [label_map[label] for label in y_test]\n",
    "y_val = [label_map[label] for label in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train을 one-hot encoding으로 변환합니다\n",
    "num_classes = len(set(y_train))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현 \n",
    "- 임시로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss, validation accuracy\n",
      "10/10 - 0s - loss: 0.7985 - accuracy: 0.7428 - 39ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# 인터넷 참고\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "def custom_opt(n):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=n)\n",
    "    return opt\n",
    "\n",
    "# 모델구성\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim, input_dim=input_dim, activation='elu'))\n",
    "model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(input_dim*2, activation='relu'))\n",
    "model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(input_dim*2, activation='relu'))\n",
    "model.add(Dense(input_dim*2, activation='relu'))\n",
    "model.add(Dense(input_dim*2, activation='relu'))\n",
    "model.add(Dense(input_dim//2, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=custom_opt(0.005), metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20, monitor='val_accuracy')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "\n",
    "print(\"validation loss, validation accuracy\")\n",
    "loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.2269 - accuracy: 0.7331 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2295 - accuracy: 0.7621 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2116 - accuracy: 0.7428 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2683 - accuracy: 0.7460 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2861 - accuracy: 0.7138 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1867 - accuracy: 0.7524 - 28ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2240 - accuracy: 0.7428 - 46ms/epoch - 5ms/step\n",
      "10/10 - 0s - loss: 0.2334 - accuracy: 0.7203 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2536 - accuracy: 0.7299 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2987 - accuracy: 0.7299 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2132 - accuracy: 0.7428 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2043 - accuracy: 0.7781 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2811 - accuracy: 0.5916 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2652 - accuracy: 0.7203 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2181 - accuracy: 0.7331 - 42ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1960 - accuracy: 0.7556 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2357 - accuracy: 0.7492 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2280 - accuracy: 0.7524 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1960 - accuracy: 0.7299 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2133 - accuracy: 0.7042 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2000 - accuracy: 0.6688 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2123 - accuracy: 0.6849 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2673 - accuracy: 0.6688 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1964 - accuracy: 0.6817 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.5513 - accuracy: 0.2026 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2418 - accuracy: 0.5884 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2045 - accuracy: 0.6945 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2105 - accuracy: 0.6913 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2092 - accuracy: 0.6817 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2362 - accuracy: 0.6752 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2092 - accuracy: 0.7010 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1981 - accuracy: 0.7235 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1912 - accuracy: 0.7524 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2039 - accuracy: 0.7074 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1963 - accuracy: 0.7588 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1873 - accuracy: 0.7170 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1834 - accuracy: 0.7460 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1916 - accuracy: 0.7492 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2283 - accuracy: 0.6656 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2918 - accuracy: 0.5852 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1852 - accuracy: 0.7363 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1820 - accuracy: 0.7621 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2766 - accuracy: 0.6013 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3851 - accuracy: 0.3601 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4693 - accuracy: 0.2251 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2010 - accuracy: 0.7395 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2084 - accuracy: 0.7460 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3891 - accuracy: 0.5177 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4056 - accuracy: 0.5466 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4250 - accuracy: 0.5338 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2777 - accuracy: 0.4984 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2860 - accuracy: 0.4920 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2621 - accuracy: 0.5466 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3626 - accuracy: 0.3473 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3673 - accuracy: 0.3473 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3123 - accuracy: 0.4887 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3169 - accuracy: 0.4823 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3231 - accuracy: 0.4566 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3646 - accuracy: 0.3473 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3649 - accuracy: 0.3473 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2348 - accuracy: 0.5884 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3074 - accuracy: 0.4984 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2940 - accuracy: 0.5209 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4131 - accuracy: 0.0804 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3935 - accuracy: 0.3473 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3455 - accuracy: 0.3473 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3819 - accuracy: 0.3473 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3908 - accuracy: 0.3473 - 28ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.5047 - accuracy: 0.3473 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.5769 - accuracy: 0.0804 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2898 - accuracy: 0.5370 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4989 - accuracy: 0.0386 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4780 - accuracy: 0.0289 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.5731 - accuracy: 0.0289 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.7270 - accuracy: 0.0804 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1758 - accuracy: 0.7588 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2050 - accuracy: 0.7556 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2166 - accuracy: 0.7299 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2122 - accuracy: 0.7267 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2051 - accuracy: 0.7042 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1935 - accuracy: 0.7267 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2039 - accuracy: 0.7203 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2209 - accuracy: 0.7395 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2032 - accuracy: 0.7492 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1929 - accuracy: 0.7781 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2057 - accuracy: 0.7395 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2087 - accuracy: 0.7106 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2058 - accuracy: 0.7556 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2262 - accuracy: 0.7556 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1919 - accuracy: 0.7428 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1764 - accuracy: 0.7524 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1922 - accuracy: 0.7299 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1832 - accuracy: 0.7621 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1852 - accuracy: 0.7524 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2109 - accuracy: 0.7299 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1879 - accuracy: 0.7492 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1849 - accuracy: 0.7621 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1970 - accuracy: 0.7299 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1923 - accuracy: 0.7331 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4599 - accuracy: 0.2637 - 30ms/epoch - 3ms/step\n",
      "Best hyperparameters: {'activation': 'relu', 'learning_rate': 0.003, 'batch': 32}\n",
      "Best validation accuracy: 0.7781350612640381\n",
      "2.4109694957733154\n",
      "{'activation': 'sigmoid', 'learning_rate': 0.001, 'batch': 256}\n"
     ]
    }
   ],
   "source": [
    "# 복습한 내용으로 추가적인 진행\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "def custom_opt(n):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=n)\n",
    "    return opt\n",
    "\n",
    "# dropout, 배치 정규화 추가\n",
    "# 변수 리스트 생성\n",
    "act_func = ['relu', 'tanh', 'sigmoid', 'elu']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "lr_lst = [0.009, 0.006, 0.003, 0.001, 0.0005]\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "batch_lst = [16, 32, 64, 128, 256]\n",
    "\n",
    "# 모델 구현\n",
    "for func in act_func:\n",
    "    for i in lr_lst:\n",
    "        for batch in batch_lst:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(256, activation=func, input_dim=input_dim))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가              \n",
    "            model.add(Dense(64, activation=func))\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=custom_opt(i), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Early stopping 기능 추가\n",
    "            early_stopping = EarlyStopping(patience=10, monitor='val_accuracy')\n",
    "            start_time = time.time()\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            long_time = end_time - start_time\n",
    "            if long_time < best_time:\n",
    "                best_time = long_time\n",
    "                time_hyper = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "\n",
    "            \n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "print(best_time)\n",
    "print(time_hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.2085 - accuracy: 0.7363 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2015 - accuracy: 0.7524 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2185 - accuracy: 0.7588 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2483 - accuracy: 0.7138 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2404 - accuracy: 0.7010 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1757 - accuracy: 0.7653 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2264 - accuracy: 0.7653 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2238 - accuracy: 0.7170 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2166 - accuracy: 0.7492 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2036 - accuracy: 0.6817 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1743 - accuracy: 0.7685 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2292 - accuracy: 0.7331 - 43ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2007 - accuracy: 0.7524 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2317 - accuracy: 0.7460 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2470 - accuracy: 0.6559 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2004 - accuracy: 0.7556 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1824 - accuracy: 0.7524 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2062 - accuracy: 0.7588 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2021 - accuracy: 0.7749 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1983 - accuracy: 0.7299 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1751 - accuracy: 0.7524 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1822 - accuracy: 0.7588 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1843 - accuracy: 0.7621 - 42ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1738 - accuracy: 0.7781 - 41ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3201 - accuracy: 0.6945 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2238 - accuracy: 0.6141 - 44ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1954 - accuracy: 0.7395 - 40ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1845 - accuracy: 0.7428 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1809 - accuracy: 0.7524 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1876 - accuracy: 0.7363 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1928 - accuracy: 0.7203 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1742 - accuracy: 0.7524 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1822 - accuracy: 0.7299 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1829 - accuracy: 0.7588 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1985 - accuracy: 0.7299 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1865 - accuracy: 0.7363 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1795 - accuracy: 0.7588 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1687 - accuracy: 0.7685 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1817 - accuracy: 0.7331 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1864 - accuracy: 0.7299 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1676 - accuracy: 0.7524 - 39ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1751 - accuracy: 0.7588 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1671 - accuracy: 0.7749 - 40ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1690 - accuracy: 0.7685 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2258 - accuracy: 0.6913 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1728 - accuracy: 0.7621 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1706 - accuracy: 0.7781 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1683 - accuracy: 0.7749 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2029 - accuracy: 0.7138 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3101 - accuracy: 0.7138 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1963 - accuracy: 0.7331 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1772 - accuracy: 0.7460 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1776 - accuracy: 0.7492 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1854 - accuracy: 0.7460 - 41ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2095 - accuracy: 0.7267 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1792 - accuracy: 0.7524 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1706 - accuracy: 0.7717 - 42ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1758 - accuracy: 0.7524 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2048 - accuracy: 0.7363 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4128 - accuracy: 0.3473 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1705 - accuracy: 0.7814 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1714 - accuracy: 0.7460 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1778 - accuracy: 0.7395 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1932 - accuracy: 0.7363 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2019 - accuracy: 0.7460 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1678 - accuracy: 0.7749 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1784 - accuracy: 0.7460 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1680 - accuracy: 0.7685 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1780 - accuracy: 0.7814 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.4416 - accuracy: 0.2026 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1673 - accuracy: 0.7524 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1724 - accuracy: 0.7621 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1857 - accuracy: 0.7621 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.5671 - accuracy: 0.0386 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.6375 - accuracy: 0.3473 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2034 - accuracy: 0.7460 - 42ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2024 - accuracy: 0.7524 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2081 - accuracy: 0.7556 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2548 - accuracy: 0.7267 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2250 - accuracy: 0.7395 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1742 - accuracy: 0.7717 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1899 - accuracy: 0.7492 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1969 - accuracy: 0.7460 - 40ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2151 - accuracy: 0.7492 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1958 - accuracy: 0.7685 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1824 - accuracy: 0.7588 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1993 - accuracy: 0.7299 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1894 - accuracy: 0.7524 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2053 - accuracy: 0.7556 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1859 - accuracy: 0.7235 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1819 - accuracy: 0.7492 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1827 - accuracy: 0.7621 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1840 - accuracy: 0.7556 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1819 - accuracy: 0.7621 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1748 - accuracy: 0.7556 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1762 - accuracy: 0.7717 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1766 - accuracy: 0.7685 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1733 - accuracy: 0.7524 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1718 - accuracy: 0.7556 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1743 - accuracy: 0.7556 - 33ms/epoch - 3ms/step\n",
      "Best hyperparameters: {'activation': 'sigmoid', 'learning_rate': 0.003, 'batch': 16}\n",
      "Best validation accuracy: 0.7813504934310913\n",
      "3.221999406814575\n",
      "{'activation': 'sigmoid', 'learning_rate': 0.006, 'batch': 256}\n"
     ]
    }
   ],
   "source": [
    "# 복습한 내용으로 추가적인 진행 - 다이아몬드형\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "def custom_opt(n):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=n)\n",
    "    return opt\n",
    "\n",
    "# dropout, 배치 정규화 추가\n",
    "# 변수 리스트 생성\n",
    "act_func = ['relu', 'tanh', 'sigmoid', 'elu']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "lr_lst = [0.009, 0.006, 0.003, 0.001, 0.0005]\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "batch_lst = [16, 32, 64, 128, 256]\n",
    "\n",
    "# 모델 구현\n",
    "for func in act_func:\n",
    "    for i in lr_lst:\n",
    "        for batch in batch_lst:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(256, activation=func, input_dim=input_dim))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(512, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가              \n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가   \n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(32, activation=func))   \n",
    "            model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=custom_opt(i), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Early stopping 기능 추가\n",
    "            early_stopping = EarlyStopping(patience=10, monitor='val_accuracy')\n",
    "            start_time = time.time()\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            long_time = end_time - start_time\n",
    "            if long_time < best_time:\n",
    "                best_time = long_time\n",
    "                time_hyper = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "\n",
    "            \n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "print(best_time)\n",
    "print(time_hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.1935 - accuracy: 0.7460 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2113 - accuracy: 0.7363 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2243 - accuracy: 0.7428 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2505 - accuracy: 0.7556 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2912 - accuracy: 0.7106 - 41ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1828 - accuracy: 0.7460 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2031 - accuracy: 0.7460 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2442 - accuracy: 0.7395 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2647 - accuracy: 0.7363 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2666 - accuracy: 0.7203 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1852 - accuracy: 0.7428 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1976 - accuracy: 0.7395 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2175 - accuracy: 0.7331 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2544 - accuracy: 0.7653 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2620 - accuracy: 0.6270 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1871 - accuracy: 0.7395 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1846 - accuracy: 0.7428 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1993 - accuracy: 0.7203 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2203 - accuracy: 0.7428 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2113 - accuracy: 0.6785 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1875 - accuracy: 0.7331 - 39ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2034 - accuracy: 0.7556 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1915 - accuracy: 0.7588 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2201 - accuracy: 0.7588 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2222 - accuracy: 0.7331 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2664 - accuracy: 0.5498 - 40ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2310 - accuracy: 0.6399 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2264 - accuracy: 0.6688 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2065 - accuracy: 0.7074 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2043 - accuracy: 0.7106 - 48ms/epoch - 5ms/step\n",
      "10/10 - 0s - loss: 0.2304 - accuracy: 0.6431 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1991 - accuracy: 0.7138 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2021 - accuracy: 0.7010 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1917 - accuracy: 0.7170 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2021 - accuracy: 0.7138 - 40ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2073 - accuracy: 0.7010 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2000 - accuracy: 0.7235 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1904 - accuracy: 0.7299 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1900 - accuracy: 0.7621 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2068 - accuracy: 0.7299 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1718 - accuracy: 0.7556 - 40ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1809 - accuracy: 0.7331 - 42ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1795 - accuracy: 0.7749 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2174 - accuracy: 0.6945 - 39ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.4017 - accuracy: 0.6270 - 40ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1841 - accuracy: 0.7299 - 47ms/epoch - 5ms/step\n",
      "10/10 - 0s - loss: 0.2117 - accuracy: 0.7042 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1755 - accuracy: 0.7781 - 46ms/epoch - 5ms/step\n",
      "10/10 - 0s - loss: 0.2219 - accuracy: 0.7363 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.4570 - accuracy: 0.6206 - 40ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2712 - accuracy: 0.5113 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2242 - accuracy: 0.6592 - 40ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2161 - accuracy: 0.6624 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2053 - accuracy: 0.6977 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.4441 - accuracy: 0.3473 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2555 - accuracy: 0.5531 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2439 - accuracy: 0.6624 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2036 - accuracy: 0.7299 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2049 - accuracy: 0.6720 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3625 - accuracy: 0.3666 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2036 - accuracy: 0.7074 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1967 - accuracy: 0.7299 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2089 - accuracy: 0.6977 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2432 - accuracy: 0.6302 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4251 - accuracy: 0.0804 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2205 - accuracy: 0.6624 - 42ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2261 - accuracy: 0.6881 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2556 - accuracy: 0.5916 - 46ms/epoch - 5ms/step\n",
      "10/10 - 0s - loss: 0.3915 - accuracy: 0.3473 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.5839 - accuracy: 0.2058 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2051 - accuracy: 0.7170 - 42ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.4577 - accuracy: 0.0386 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3247 - accuracy: 0.5177 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.5155 - accuracy: 0.2058 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.6770 - accuracy: 0.2058 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2187 - accuracy: 0.7074 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1987 - accuracy: 0.7492 - 44ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2130 - accuracy: 0.7299 - 42ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2407 - accuracy: 0.7621 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2838 - accuracy: 0.7428 - 43ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1861 - accuracy: 0.7428 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2007 - accuracy: 0.7299 - 49ms/epoch - 5ms/step\n",
      "10/10 - 0s - loss: 0.2087 - accuracy: 0.7524 - 40ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2481 - accuracy: 0.7878 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2087 - accuracy: 0.7428 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1845 - accuracy: 0.7621 - 42ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1866 - accuracy: 0.7395 - 39ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1907 - accuracy: 0.7395 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2074 - accuracy: 0.7524 - 26ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2179 - accuracy: 0.7138 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1740 - accuracy: 0.7685 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1838 - accuracy: 0.7203 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1759 - accuracy: 0.7588 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1845 - accuracy: 0.7267 - 42ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3743 - accuracy: 0.5659 - 41ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1813 - accuracy: 0.7492 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1840 - accuracy: 0.7395 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1952 - accuracy: 0.7428 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1751 - accuracy: 0.7363 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1887 - accuracy: 0.7331 - 19ms/epoch - 2ms/step\n",
      "Best hyperparameters: {'activation': 'elu', 'learning_rate': 0.006, 'batch': 128}\n",
      "Best validation accuracy: 0.7877813577651978\n",
      "4.0999977588653564\n",
      "{'activation': 'sigmoid', 'learning_rate': 0.003, 'batch': 256}\n"
     ]
    }
   ],
   "source": [
    "# 복습한 내용으로 추가적인 진행 - 다이아몬드형\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "def custom_opt(n):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=n)\n",
    "    return opt\n",
    "\n",
    "# dropout, 배치 정규화 추가\n",
    "# 변수 리스트 생성\n",
    "act_func = ['relu', 'tanh', 'sigmoid', 'elu']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "lr_lst = [0.009, 0.006, 0.003, 0.001, 0.0005]\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "batch_lst = [16, 32, 64, 128, 256]\n",
    "\n",
    "# 모델 구현\n",
    "for func in act_func:\n",
    "    for i in lr_lst:\n",
    "        for batch in batch_lst:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(512, activation=func, input_dim=input_dim))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(256, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가              \n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가   \n",
    "            model.add(Dense(96, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(64, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(12, activation=func)) \n",
    "            model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=custom_opt(i), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Early stopping 기능 추가\n",
    "            early_stopping = EarlyStopping(patience=10, monitor='val_accuracy')\n",
    "            start_time = time.time()\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            long_time = end_time - start_time\n",
    "            if long_time < best_time:\n",
    "                best_time = long_time\n",
    "                time_hyper = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "\n",
    "            \n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "print(best_time)\n",
    "print(time_hyper)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
