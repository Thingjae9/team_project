{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import keras.utils\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 (EDA)과정 진행 후 데이터\n",
    "X_train = pd.read_csv('csv/Multi_to_share/Multi_to_share/fi로 drop 진행/X_fi_train.csv')\n",
    "X_test = pd.read_csv('csv/Multi_to_share/Multi_to_share/fi로 drop 진행/X_fi_test.csv')\n",
    "X_val = pd.read_csv('csv/Multi_to_share/Multi_to_share/fi로 drop 진행/X_fi_val.csv')\n",
    "y_train = pd.read_csv('csv/Multi_to_share/Multi_to_share/fi로 drop 진행/y_fi_train.csv')\n",
    "y_test = pd.read_csv('csv/Multi_to_share/Multi_to_share/fi로 drop 진행/y_fi_test.csv')\n",
    "y_val = pd.read_csv('csv/Multi_to_share/Multi_to_share/fi로 drop 진행/y_fi_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['class']\n",
    "y_test = y_test['class']\n",
    "y_val = y_val['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 맵핑\t\t\t\t\n",
    "label_map = {'Pastry': 0, 'Z_Scratch': 1, 'K_Scatch': 2, 'Stains': 3, 'Dirtiness': 4, 'Bumps': 5, 'Other_Faults': 6}\n",
    "y_train = [label_map[label] for label in y_train]\n",
    "y_test = [label_map[label] for label in y_test]\n",
    "y_val = [label_map[label] for label in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train을 one-hot encoding으로 변환합니다\n",
    "num_classes = len(set(y_train))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현 \n",
    "- 임시로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss, validation accuracy\n",
      "10/10 - 0s - loss: 0.6890 - accuracy: 0.7588 - 26ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# 인터넷 참고\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "def custom_opt(n):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=n)\n",
    "    return opt\n",
    "\n",
    "# 모델구성\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim, input_dim=input_dim, activation='elu'))\n",
    "model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(input_dim*2, activation='relu'))\n",
    "model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(input_dim*2, activation='relu'))\n",
    "model.add(Dense(input_dim*2, activation='relu'))\n",
    "model.add(Dense(input_dim*2, activation='relu'))\n",
    "model.add(Dense(input_dim//2, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=custom_opt(0.005), metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20, monitor='val_accuracy')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "\n",
    "print(\"validation loss, validation accuracy\")\n",
    "loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.2418 - accuracy: 0.7492 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2052 - accuracy: 0.7331 - 27ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2492 - accuracy: 0.7428 - 27ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2116 - accuracy: 0.7492 - 27ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3238 - accuracy: 0.7042 - 27ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2122 - accuracy: 0.7588 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2009 - accuracy: 0.7428 - 19ms/epoch - 2ms/step\n",
      "10/10 - 0s - loss: 0.2137 - accuracy: 0.6624 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2371 - accuracy: 0.6527 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2003 - accuracy: 0.7138 - 28ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2391 - accuracy: 0.7524 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1876 - accuracy: 0.7524 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2287 - accuracy: 0.7331 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2218 - accuracy: 0.7653 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1961 - accuracy: 0.7042 - 17ms/epoch - 2ms/step\n",
      "10/10 - 0s - loss: 0.2093 - accuracy: 0.7524 - 23ms/epoch - 2ms/step\n",
      "10/10 - 0s - loss: 0.2276 - accuracy: 0.7460 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2172 - accuracy: 0.7138 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2187 - accuracy: 0.7492 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2150 - accuracy: 0.6785 - 28ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1994 - accuracy: 0.7010 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2100 - accuracy: 0.7653 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4766 - accuracy: 0.0611 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2693 - accuracy: 0.6077 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4632 - accuracy: 0.3987 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2304 - accuracy: 0.6206 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2068 - accuracy: 0.7010 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2101 - accuracy: 0.7267 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1933 - accuracy: 0.7042 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2123 - accuracy: 0.7267 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1869 - accuracy: 0.7299 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1774 - accuracy: 0.7621 - 39ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1882 - accuracy: 0.7428 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1945 - accuracy: 0.7395 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2097 - accuracy: 0.7524 - 28ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1949 - accuracy: 0.7235 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1957 - accuracy: 0.7524 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1880 - accuracy: 0.7331 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2035 - accuracy: 0.7203 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3543 - accuracy: 0.5723 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2039 - accuracy: 0.6977 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1845 - accuracy: 0.7428 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2688 - accuracy: 0.5852 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2588 - accuracy: 0.6592 - 41ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.4339 - accuracy: 0.3698 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2214 - accuracy: 0.6752 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2510 - accuracy: 0.6399 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3290 - accuracy: 0.6141 - 26ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4122 - accuracy: 0.6174 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.5138 - accuracy: 0.4405 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3235 - accuracy: 0.4534 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2673 - accuracy: 0.5820 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3642 - accuracy: 0.3473 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3610 - accuracy: 0.3473 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3622 - accuracy: 0.3473 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2311 - accuracy: 0.5852 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3030 - accuracy: 0.4855 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3512 - accuracy: 0.3473 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3628 - accuracy: 0.3473 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3717 - accuracy: 0.3473 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2603 - accuracy: 0.5241 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3047 - accuracy: 0.4984 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2906 - accuracy: 0.5209 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.3706 - accuracy: 0.3473 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3992 - accuracy: 0.2026 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3464 - accuracy: 0.3473 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3713 - accuracy: 0.3473 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4423 - accuracy: 0.0804 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.5496 - accuracy: 0.2058 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.6296 - accuracy: 0.0804 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3673 - accuracy: 0.3473 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4214 - accuracy: 0.3473 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3989 - accuracy: 0.3473 - 38ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.6630 - accuracy: 0.0386 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.5738 - accuracy: 0.2058 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2006 - accuracy: 0.7428 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2270 - accuracy: 0.7331 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1938 - accuracy: 0.7460 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2104 - accuracy: 0.7460 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2153 - accuracy: 0.6913 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2011 - accuracy: 0.7395 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1900 - accuracy: 0.7395 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1945 - accuracy: 0.7524 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2134 - accuracy: 0.7170 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2120 - accuracy: 0.7363 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1911 - accuracy: 0.7460 - 39ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2107 - accuracy: 0.7524 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2235 - accuracy: 0.7395 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2153 - accuracy: 0.7395 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1935 - accuracy: 0.7428 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1848 - accuracy: 0.7460 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1817 - accuracy: 0.7685 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2080 - accuracy: 0.7556 - 28ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1908 - accuracy: 0.7363 - 27ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1851 - accuracy: 0.7749 - 27ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1813 - accuracy: 0.7653 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1835 - accuracy: 0.7460 - 28ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1881 - accuracy: 0.7428 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1892 - accuracy: 0.7170 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1940 - accuracy: 0.7428 - 29ms/epoch - 3ms/step\n",
      "Best hyperparameters: {'activation': 'elu', 'learning_rate': 0.001, 'batch': 256}\n",
      "Best validation accuracy: 0.7749196290969849\n",
      "2.832624673843384\n",
      "{'activation': 'sigmoid', 'learning_rate': 0.0005, 'batch': 256}\n"
     ]
    }
   ],
   "source": [
    "# 복습한 내용으로 추가적인 진행\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "def custom_opt(n):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=n)\n",
    "    return opt\n",
    "\n",
    "# dropout, 배치 정규화 추가\n",
    "# 변수 리스트 생성\n",
    "act_func = ['relu', 'tanh', 'sigmoid', 'elu']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "lr_lst = [0.009, 0.006, 0.003, 0.001, 0.0005]\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "batch_lst = [16, 32, 64, 128, 256]\n",
    "\n",
    "# 모델 구현\n",
    "for func in act_func:\n",
    "    for i in lr_lst:\n",
    "        for batch in batch_lst:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(256, activation=func, input_dim=input_dim))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가              \n",
    "            model.add(Dense(64, activation=func))\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=custom_opt(i), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Early stopping 기능 추가\n",
    "            early_stopping = EarlyStopping(patience=10, monitor='val_accuracy')\n",
    "            start_time = time.time()\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            long_time = end_time - start_time\n",
    "            if long_time < best_time:\n",
    "                best_time = long_time\n",
    "                time_hyper = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "\n",
    "            \n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "print(best_time)\n",
    "print(time_hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.2027 - accuracy: 0.7331 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1845 - accuracy: 0.7685 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2533 - accuracy: 0.7556 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2503 - accuracy: 0.7267 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2424 - accuracy: 0.7138 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1969 - accuracy: 0.7428 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1925 - accuracy: 0.7492 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2099 - accuracy: 0.7331 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2149 - accuracy: 0.7395 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2171 - accuracy: 0.7492 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1921 - accuracy: 0.7492 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1805 - accuracy: 0.7621 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2117 - accuracy: 0.7588 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2463 - accuracy: 0.7299 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2033 - accuracy: 0.6945 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1861 - accuracy: 0.7428 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2001 - accuracy: 0.7588 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1984 - accuracy: 0.7653 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1815 - accuracy: 0.7492 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1955 - accuracy: 0.7395 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1886 - accuracy: 0.7556 - 28ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1745 - accuracy: 0.7556 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1695 - accuracy: 0.7717 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1842 - accuracy: 0.7363 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1859 - accuracy: 0.7363 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2206 - accuracy: 0.6688 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1918 - accuracy: 0.7267 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1826 - accuracy: 0.7492 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1935 - accuracy: 0.7460 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1971 - accuracy: 0.7203 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1910 - accuracy: 0.7203 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1686 - accuracy: 0.7749 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1779 - accuracy: 0.7524 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1772 - accuracy: 0.7460 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1968 - accuracy: 0.7363 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1770 - accuracy: 0.7524 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1837 - accuracy: 0.7363 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1859 - accuracy: 0.7428 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1703 - accuracy: 0.7653 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1943 - accuracy: 0.7492 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1748 - accuracy: 0.7235 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1702 - accuracy: 0.7556 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1707 - accuracy: 0.7556 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1689 - accuracy: 0.7653 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1789 - accuracy: 0.7685 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1659 - accuracy: 0.7846 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1676 - accuracy: 0.7588 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2410 - accuracy: 0.6913 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1776 - accuracy: 0.7685 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1935 - accuracy: 0.7749 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1897 - accuracy: 0.7363 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1781 - accuracy: 0.7588 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1739 - accuracy: 0.7653 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1789 - accuracy: 0.7588 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4500 - accuracy: 0.3633 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1719 - accuracy: 0.7717 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1817 - accuracy: 0.7556 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1746 - accuracy: 0.7556 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2181 - accuracy: 0.7042 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4021 - accuracy: 0.3923 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1685 - accuracy: 0.7588 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1721 - accuracy: 0.7395 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1771 - accuracy: 0.7621 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1859 - accuracy: 0.7588 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2219 - accuracy: 0.7235 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1631 - accuracy: 0.7588 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1702 - accuracy: 0.7588 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1833 - accuracy: 0.7460 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1707 - accuracy: 0.7781 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3885 - accuracy: 0.3698 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1604 - accuracy: 0.7492 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1650 - accuracy: 0.7717 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1999 - accuracy: 0.7395 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4835 - accuracy: 0.2026 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4425 - accuracy: 0.3473 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1924 - accuracy: 0.7653 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2032 - accuracy: 0.7460 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2134 - accuracy: 0.7460 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2055 - accuracy: 0.7556 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2127 - accuracy: 0.7299 - 36ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1851 - accuracy: 0.7460 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1909 - accuracy: 0.7556 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2009 - accuracy: 0.7299 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1958 - accuracy: 0.7556 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1944 - accuracy: 0.7460 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1891 - accuracy: 0.7460 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1829 - accuracy: 0.7428 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1978 - accuracy: 0.7428 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1984 - accuracy: 0.7492 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2046 - accuracy: 0.7653 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1903 - accuracy: 0.7395 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1804 - accuracy: 0.7621 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1757 - accuracy: 0.7395 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1803 - accuracy: 0.7492 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1746 - accuracy: 0.7524 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1729 - accuracy: 0.7460 - 29ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1738 - accuracy: 0.7524 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1741 - accuracy: 0.7717 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1831 - accuracy: 0.7588 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1778 - accuracy: 0.7588 - 30ms/epoch - 3ms/step\n",
      "Best hyperparameters: {'activation': 'tanh', 'learning_rate': 0.0005, 'batch': 16}\n",
      "Best validation accuracy: 0.7845659255981445\n",
      "3.0444753170013428\n",
      "{'activation': 'sigmoid', 'learning_rate': 0.0005, 'batch': 256}\n"
     ]
    }
   ],
   "source": [
    "# 복습한 내용으로 추가적인 진행 - 다이아몬드형\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "def custom_opt(n):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=n)\n",
    "    return opt\n",
    "\n",
    "# dropout, 배치 정규화 추가\n",
    "# 변수 리스트 생성\n",
    "act_func = ['relu', 'tanh', 'sigmoid', 'elu']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "lr_lst = [0.009, 0.006, 0.003, 0.001, 0.0005]\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "batch_lst = [16, 32, 64, 128, 256]\n",
    "\n",
    "# 모델 구현\n",
    "for func in act_func:\n",
    "    for i in lr_lst:\n",
    "        for batch in batch_lst:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(256, activation=func, input_dim=input_dim))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(512, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가              \n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가   \n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(32, activation=func))   \n",
    "            model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=custom_opt(i), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Early stopping 기능 추가\n",
    "            early_stopping = EarlyStopping(patience=10, monitor='val_accuracy')\n",
    "            start_time = time.time()\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            long_time = end_time - start_time\n",
    "            if long_time < best_time:\n",
    "                best_time = long_time\n",
    "                time_hyper = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "\n",
    "            \n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "print(best_time)\n",
    "print(time_hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.2118 - accuracy: 0.7331 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2444 - accuracy: 0.7170 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2256 - accuracy: 0.7395 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2691 - accuracy: 0.7235 - 35ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2825 - accuracy: 0.7074 - 37ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.1927 - accuracy: 0.7299 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1999 - accuracy: 0.7170 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2230 - accuracy: 0.7653 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2622 - accuracy: 0.7492 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2916 - accuracy: 0.7460 - 30ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1790 - accuracy: 0.7621 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1923 - accuracy: 0.7395 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1968 - accuracy: 0.7460 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2071 - accuracy: 0.7621 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2549 - accuracy: 0.7685 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1757 - accuracy: 0.7524 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1848 - accuracy: 0.7621 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2258 - accuracy: 0.7235 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2016 - accuracy: 0.7524 - 35ms/epoch - 4ms/step\n",
      "10/10 - 0s - loss: 0.2432 - accuracy: 0.7235 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1835 - accuracy: 0.7428 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1765 - accuracy: 0.7556 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1852 - accuracy: 0.7621 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3758 - accuracy: 0.4309 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.6652 - accuracy: 0.3666 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2565 - accuracy: 0.5820 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2330 - accuracy: 0.6527 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2119 - accuracy: 0.6559 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1926 - accuracy: 0.7074 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2098 - accuracy: 0.7010 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2333 - accuracy: 0.6399 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2111 - accuracy: 0.6720 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2055 - accuracy: 0.6977 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2061 - accuracy: 0.7074 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1880 - accuracy: 0.7138 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2174 - accuracy: 0.6720 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1965 - accuracy: 0.7138 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1982 - accuracy: 0.7235 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1961 - accuracy: 0.7267 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2011 - accuracy: 0.7428 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1785 - accuracy: 0.7621 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1740 - accuracy: 0.7878 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2004 - accuracy: 0.7299 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3197 - accuracy: 0.5820 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3360 - accuracy: 0.6399 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1917 - accuracy: 0.6945 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1867 - accuracy: 0.7460 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2015 - accuracy: 0.7428 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3589 - accuracy: 0.6913 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4369 - accuracy: 0.6206 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2860 - accuracy: 0.5209 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2470 - accuracy: 0.6109 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2060 - accuracy: 0.6977 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2028 - accuracy: 0.6977 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3889 - accuracy: 0.3473 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1991 - accuracy: 0.7203 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2121 - accuracy: 0.6592 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1844 - accuracy: 0.7170 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2008 - accuracy: 0.7042 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2354 - accuracy: 0.6334 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2624 - accuracy: 0.6270 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1935 - accuracy: 0.7203 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2214 - accuracy: 0.6720 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3698 - accuracy: 0.3473 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3601 - accuracy: 0.3473 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2370 - accuracy: 0.5949 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2192 - accuracy: 0.6752 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2545 - accuracy: 0.6206 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.4382 - accuracy: 0.0965 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.5702 - accuracy: 0.0965 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2426 - accuracy: 0.5820 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3299 - accuracy: 0.5884 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2593 - accuracy: 0.5884 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.5110 - accuracy: 0.0804 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.6862 - accuracy: 0.0965 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1789 - accuracy: 0.7492 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1923 - accuracy: 0.7299 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2073 - accuracy: 0.7395 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2710 - accuracy: 0.7235 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2356 - accuracy: 0.7363 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1928 - accuracy: 0.7685 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1855 - accuracy: 0.7717 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2139 - accuracy: 0.7331 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2314 - accuracy: 0.7267 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2256 - accuracy: 0.7621 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1729 - accuracy: 0.7653 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1809 - accuracy: 0.7428 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1945 - accuracy: 0.7556 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2025 - accuracy: 0.7331 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.2064 - accuracy: 0.7331 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1685 - accuracy: 0.7588 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1751 - accuracy: 0.7492 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1828 - accuracy: 0.7395 - 32ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1806 - accuracy: 0.7685 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.3718 - accuracy: 0.5145 - 31ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1779 - accuracy: 0.7653 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1777 - accuracy: 0.7267 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1895 - accuracy: 0.7331 - 34ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1846 - accuracy: 0.7299 - 33ms/epoch - 3ms/step\n",
      "10/10 - 0s - loss: 0.1871 - accuracy: 0.7428 - 32ms/epoch - 3ms/step\n",
      "Best hyperparameters: {'activation': 'tanh', 'learning_rate': 0.001, 'batch': 32}\n",
      "Best validation accuracy: 0.7877813577651978\n",
      "3.727630615234375\n",
      "{'activation': 'relu', 'learning_rate': 0.0005, 'batch': 256}\n"
     ]
    }
   ],
   "source": [
    "# 복습한 내용으로 추가적인 진행 - 다이아몬드형\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "def custom_opt(n):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=n)\n",
    "    return opt\n",
    "\n",
    "# dropout, 배치 정규화 추가\n",
    "# 변수 리스트 생성\n",
    "act_func = ['relu', 'tanh', 'sigmoid', 'elu']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "lr_lst = [0.009, 0.006, 0.003, 0.001, 0.0005]\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "batch_lst = [16, 32, 64, 128, 256]\n",
    "\n",
    "# 모델 구현\n",
    "for func in act_func:\n",
    "    for i in lr_lst:\n",
    "        for batch in batch_lst:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(512, activation=func, input_dim=input_dim))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(256, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가              \n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가   \n",
    "            model.add(Dense(96, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(64, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(12, activation=func)) \n",
    "            model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=custom_opt(i), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Early stopping 기능 추가\n",
    "            early_stopping = EarlyStopping(patience=10, monitor='val_accuracy')\n",
    "            start_time = time.time()\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            long_time = end_time - start_time\n",
    "            if long_time < best_time:\n",
    "                best_time = long_time\n",
    "                time_hyper = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "\n",
    "            \n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'learning_rate': i, 'batch': batch}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "print(best_time)\n",
    "print(time_hyper)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
