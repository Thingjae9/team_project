{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model (Plus)에 있는 기능\n",
    "\n",
    "- binary_load_dataset 메서드\n",
    "\n",
    "데이터 비율 조정을 위한 파라미터 값을 기반으로 데이터를 로드하는 메서드로\n",
    "\n",
    "주어진 binary_classification_data.csv 파일을 열고 데이터를 읽습니다. 데이터의 마지막 열에 종속 변수가 있으며, 해당 열의 값에 따라서 '1'인 pulsar 데이터와 '0'인 star 데이터를 각각 별도의 리스트에 저장합니다.\n",
    "\n",
    "그 후, 실험에 사용될 데이터와 신경망의 입력 및 출력 크기를 전역 변수로 선언합니다. pulsar와 star 데이터는 하나의 변수 data에 그룹화됩니다. pulsar 데이터의 수를 star 데이터의 수에 맞추기 위해 데이터의 수를 조정할 수 있습니다.\n",
    "\n",
    "adjust_ratio 매개변수가 True인 경우, pulsar 데이터의 비율을 증가시킵니다. pulsar 데이터와 star 데이터를 하나의 변수에 할당하고, 데이터의 크기는 star 데이터의 배수로 저장됩니다.\n",
    "\n",
    "adjust_ratio 값이 True인 경우 star 데이터를 data 변수에 할당한 후, pulsar 데이터를 star 데이터의 수만큼 반복하여 추가합니다. 이를 위해 % 연산자를 사용하여 pulsar 데이터의 인덱스를 순차적으로 추출합니다.\n",
    "\n",
    "adjust_ratio 값이 False인 경우, 기존 데이터를 그대로 data 변수에 할당합니다. star 데이터를 먼저 할당하고, 그 다음에 pulsar 데이터를 할당합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dropout\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('binary_classification_data.csv')\n",
    "target = 'target_class'\n",
    "y = df[target]\n",
    "x = df.drop(target, axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불균형 처리\n",
    "- 데이터 처리\n",
    "\n",
    "1. oversampling :\n",
    "\n",
    "   SMOTE, ADASYN\n",
    "\n",
    "2. undersampling\n",
    "\n",
    "- 평가지표 처리\n",
    "\n",
    "1. accurcacy :\n",
    "\n",
    "   대부분의 예측이 다수 클래스에 속하게 되어 별로\n",
    "\n",
    "2. F1-score :\n",
    "\n",
    "   Baseline model에서 사용한 평가지표로 불균형한 데이터에서 평가지표로 사용\n",
    "\n",
    "- 모델 구현시 처리\n",
    "\n",
    "1. 클래스 가중치 설정 :\n",
    "\n",
    "   소수 클래스에 더 큰 가중치 부여\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\n",
      "[안내] 데이터 표준화를 진행했습니다.\n",
      "[안내] 검증 데이터를 추가로 분리했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 유저로 부터 입력을 받아 검증 데이터 셋을 사용할 것인지, 표준화를 사용할 것인지 정함.\n",
    "print(\"[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\")\n",
    "input_1 = input(\"[안내] 데이터를 표준화 하시겠습니까? : \")\n",
    "# 표준화 진행 여부\n",
    "if input_1 == 'y':\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(x)\n",
    "    print(\"[안내] 데이터 표준화를 진행했습니다.\")\n",
    "else:\n",
    "    X = x\n",
    "    print(\"[안내] 데이터 표준화를 진행하지 않습니다.\")\n",
    "    \n",
    "input_2 = input(\"[안내] 검증 데이터셋을 분리할까요? : \")\n",
    "\n",
    "\n",
    "\n",
    "# 검증 데이터 진행 여부\n",
    "if input_2 == 'y':\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    print(\"[안내] 검증 데이터를 추가로 분리했습니다.\")\n",
    "\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"[안내] 검증 데이터를 분리하지 않았습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE로 oversampling 진행\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weight = {0: 1., 1: (len(y_train) / sum(y_train))}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현 - 작업중\n",
    "- 최적의 파라미터를 반복문을 통해 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.6352 - accuracy: 0.8108\n",
      "Epoch 2/10\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.4787 - accuracy: 0.8720\n",
      "Epoch 3/10\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.4357 - accuracy: 0.8868\n",
      "Epoch 4/10\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.4157 - accuracy: 0.8939\n",
      "Epoch 5/10\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.4003 - accuracy: 0.8962\n",
      "Epoch 6/10\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.3899 - accuracy: 0.9004\n",
      "Epoch 7/10\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.3823 - accuracy: 0.9022\n",
      "Epoch 8/10\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.3740 - accuracy: 0.9032\n",
      "Epoch 9/10\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.3650 - accuracy: 0.9045\n",
      "Epoch 10/10\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.3621 - accuracy: 0.9039\n",
      "112/112 [==============================] - 0s 792us/step\n",
      "90/90 - 0s - loss: 0.4099 - accuracy: 0.8282 - 206ms/epoch - 2ms/step\n",
      "F1-score: 0.491283676703645\n",
      "AUC-ROC: 0.9752083614127759\n",
      "Precision: 0.3294367693942614\n",
      "Recall: 0.9657320872274143\n"
     ]
    }
   ],
   "source": [
    "# 모델 구현\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=32, class_weight=class_weight)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "print('F1-score:', f1)\n",
    "print('AUC-ROC:', roc_auc)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
