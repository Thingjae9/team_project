{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model (Plus)에 있는 기능\n",
    "\n",
    "- binary_load_dataset 메서드\n",
    "\n",
    "데이터 비율 조정을 위한 파라미터 값을 기반으로 데이터를 로드하는 메서드로\n",
    "\n",
    "주어진 binary_classification_data.csv 파일을 열고 데이터를 읽습니다. 데이터의 마지막 열에 종속 변수가 있으며, 해당 열의 값에 따라서 '1'인 pulsar 데이터와 '0'인 star 데이터를 각각 별도의 리스트에 저장합니다.\n",
    "\n",
    "그 후, 실험에 사용될 데이터와 신경망의 입력 및 출력 크기를 전역 변수로 선언합니다. pulsar와 star 데이터는 하나의 변수 data에 그룹화됩니다. pulsar 데이터의 수를 star 데이터의 수에 맞추기 위해 데이터의 수를 조정할 수 있습니다.\n",
    "\n",
    "adjust_ratio 매개변수가 True인 경우, pulsar 데이터의 비율을 증가시킵니다. pulsar 데이터와 star 데이터를 하나의 변수에 할당하고, 데이터의 크기는 star 데이터의 배수로 저장됩니다.\n",
    "\n",
    "adjust_ratio 값이 True인 경우 star 데이터를 data 변수에 할당한 후, pulsar 데이터를 star 데이터의 수만큼 반복하여 추가합니다. 이를 위해 % 연산자를 사용하여 pulsar 데이터의 인덱스를 순차적으로 추출합니다.\n",
    "\n",
    "adjust_ratio 값이 False인 경우, 기존 데이터를 그대로 data 변수에 할당합니다. star 데이터를 먼저 할당하고, 그 다음에 pulsar 데이터를 할당합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('binary_classification_data.csv')\n",
    "target = 'target_class'\n",
    "y = df[target]\n",
    "x = df.drop(target, axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불균형 처리\n",
    "- 데이터 처리\n",
    "\n",
    "1. oversampling :\n",
    "\n",
    "   SMOTE, ADASYN\n",
    "\n",
    "2. undersampling\n",
    "\n",
    "- 평가지표 처리\n",
    "\n",
    "1. accurcacy :\n",
    "\n",
    "   대부분의 예측이 다수 클래스에 속하게 되어 별로\n",
    "\n",
    "2. F1-score :\n",
    "\n",
    "   Baseline model에서 사용한 평가지표로 불균형한 데이터에서 평가지표로 사용\n",
    "\n",
    "- 모델 구현시 처리\n",
    "\n",
    "1. 클래스 가중치 설정 :\n",
    "\n",
    "   소수 클래스에 더 큰 가중치 부여\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\n",
      "[안내] 데이터 표준화를 진행했습니다.\n",
      "[안내] 검증 데이터를 추가로 분리했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 유저로 부터 입력을 받아 검증 데이터 셋을 사용할 것인지, 표준화를 사용할 것인지 정함.\n",
    "print(\"[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\")\n",
    "input_1 = input(\"[안내] 데이터를 표준화 하시겠습니까? : \")\n",
    "# 표준화 진행 여부\n",
    "if input_1 == 'y':\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(x)\n",
    "    print(\"[안내] 데이터 표준화를 진행했습니다.\")\n",
    "else:\n",
    "    X = x\n",
    "    print(\"[안내] 데이터 표준화를 진행하지 않습니다.\")\n",
    "    \n",
    "input_2 = input(\"[안내] 검증 데이터셋을 분리할까요? : \")\n",
    "\n",
    "\n",
    "\n",
    "# 검증 데이터 진행 여부\n",
    "if input_2 == 'y':\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    print(\"[안내] 검증 데이터를 추가로 분리했습니다.\")\n",
    "\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"[안내] 검증 데이터를 분리하지 않았습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE로 oversampling 진행\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weight = {0: 1., 1: (len(y_train) / sum(y_train))}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현 \n",
    "- 최적의 파라미터를 반복문을 통해 찾기\n",
    "\n",
    "- 이진 분류 모델에서는 대표적으로 Adam optimizer를 사용하는 것이 일반적입니다. 다른 optimizer로는 SGD, RMSprop 등이 있으며, 이들 중에서도 데이터셋의 크기와 모델의 복잡도에 따라 적합한 optimizer를 선택해야 합니다. 하지만 대체로 Adam optimizer가 다른 optimizer보다 성능이 좋은 편입니다.\n",
    "\n",
    "- 모델에 배치 정규화 레이어를 추가하면 모델이 더 안정적으로 수렴할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 리스트 생성\n",
    "act_func = ['relu', 'tanh', 'sigmoid']\n",
    "batch_lst = [8, 16, 32, 64, 128]\n",
    "opt_lst = ['adam', 'rmsprop', 'sgd']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "# 모델 구현\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(64, activation=func, input_shape=(X_train_resampled.shape[1],)))\n",
    "            model.add(Dense(32, activation=func))              \n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(4, activation=func))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=opti, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Early stopping 기능 추가\n",
    "            early_stopping = EarlyStopping(patience=5, monitor='val_loss')\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train_resampled, y_train_resampled, epochs=1000, batch_size=batch, class_weight=class_weight, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "            # 모델 평가\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "            f1 = f1_score(y_test, y_pred_binary)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred_binary)\n",
    "            recall = recall_score(y_test, y_pred_binary)\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'optimizer': opti, 'dropout': 'no'}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout 추가\n",
    "# 변수 리스트 생성\n",
    "act_func = ['relu', 'tanh', 'sigmoid']\n",
    "batch_lst = [8, 16, 32, 64, 128]\n",
    "opt_lst = ['adam', 'rmsprop', 'sgd']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "# 모델 구현\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(64, activation=func, input_shape=(X_train_resampled.shape[1],)))\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(Dropout(0.2))  # Dropout 추가              \n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(4, activation=func))\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=opti, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Early stopping 기능 추가\n",
    "            early_stopping = EarlyStopping(patience=5, monitor='val_loss')\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train_resampled, y_train_resampled, epochs=1000, batch_size=batch, class_weight=class_weight, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "            # 모델 평가\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "            f1 = f1_score(y_test, y_pred_binary)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred_binary)\n",
    "            recall = recall_score(y_test, y_pred_binary)\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'optimizer': opti, 'dropout': 'yes'}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout, 배치 정규화 추가\n",
    "# 변수 리스트 생성\n",
    "act_func = ['relu', 'tanh', 'sigmoid']\n",
    "batch_lst = [8, 16, 32, 64, 128]\n",
    "opt_lst = ['adam', 'rmsprop', 'sgd']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "# 모델 구현\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(64, activation=func, input_shape=(X_train_resampled.shape[1],)))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가              \n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(4, activation=func))\n",
    "            model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "            model.add(Dropout(0.2))  # Dropout 추가\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer=opti, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Early stopping 기능 추가\n",
    "            early_stopping = EarlyStopping(patience=5, monitor='val_loss')\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train_resampled, y_train_resampled, epochs=1000, batch_size=batch, class_weight=class_weight, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "            # 모델 평가\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "            f1 = f1_score(y_test, y_pred_binary)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred_binary)\n",
    "            recall = recall_score(y_test, y_pred_binary)\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose = 2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'optimizer': opti, 'dropout': 'yes', 'batch_normal': 'yes'}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST MODEL\n",
    "\n",
    "1. 구성 추가 - undersampling or oversampling 여부 \n",
    "\n",
    "2. 최적의 파라미터 적용\n",
    "\n",
    "3. 평가지표 어떤것을 사용할지\n",
    "\n",
    "4. 클래스 가중치를 적용할 것인지.\n",
    "\n",
    "### 추가사항\n",
    "\n",
    "1. 과연 accuracy가 기존 모델보다 낮아진 모델을 사용해도 될까?: \n",
    " accuracy를 기준으로 early stopping하면 모델의 성능은 더 증가할 것.\n",
    "\n",
    "2. 좋은 모델의 파라미터를 사용해서 모델 구조를 변경해보기.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'activation': 'tanh', 'batch_size': 64, 'optimizer': 'sgd', 'dropout': 'yes', 'batch_normal': 'yes'}\n",
      "Best accuracy: 0.8460195660591125\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best accuracy:', best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold를 통해 모델 성능을 평가해보기.\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_resampled):\n",
    "    X_train_fold, X_val_fold = X_train_resampled[train_index], X_train_resampled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_resampled[train_index], y_train_resampled[val_index]\n",
    "    \n",
    "    # 모델 생성 및 학습\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=30, batch_size=32, class_weight=class_weight)\n",
    "    \n",
    "    # 검증 데이터에 대한 예측 수행\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "    y_pred = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "    \n",
    "    # f1 score와 precision 계산\n",
    "    f1_scores.append(f1_score(y_val_fold, y_pred))\n",
    "    recall.append(recall_score(y_val_fold, y_pred))\n",
    "    precision_scores.append(precision_score(y_val_fold, y_pred))\n",
    "    \n",
    "# 교차 검증 결과 출력\n",
    "print('Mean F1 score:', np.mean(f1_scores))\n",
    "print('Mean precision:', np.mean(precision_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold를 통해 모델 성능을 평가해보기. - 실패\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recalls = []\n",
    "accs = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_resampled):\n",
    "    X_train_fold, X_val_fold = X_train_resampled[train_index], X_train_resampled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_resampled[train_index], y_train_resampled[val_index]\n",
    "    \n",
    "    # 판단\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='tanh', input_shape=(X_train_resampled.shape[1],)))\n",
    "    model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "    model.add(Dropout(0.2))  # Dropout 추가\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(BatchNormalization()) # 배치 정규화 추가\n",
    "    model.add(Dropout(0.2))  # Dropout 추가\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping 기능 추가\n",
    "    early_stopping = EarlyStopping(patience=5, monitor='accuracy')\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=30, batch_size=32, class_weight=class_weight, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping])\n",
    "    \n",
    "    # 검증 데이터에 대한 예측 수행\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "    y_pred = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "    \n",
    "    loss, acc = model.evaluate(X_train_fold, y_train_fold, verbose = 2)\n",
    "\n",
    "    # f1 score와 precision 계산\n",
    "    f1_scores.append(f1_score(y_val_fold, y_pred))\n",
    "    recalls.append(recall_score(y_val_fold, y_pred))\n",
    "    precision_scores.append(precision_score(y_val_fold, y_pred))\n",
    "    accs.append(acc)\n",
    "    \n",
    "# 교차 검증 결과 출력\n",
    "print('Mean accuracy:', np.mean(accs))\n",
    "print('Mean F1 score:', np.mean(f1_scores))\n",
    "print('Mean precision:', np.mean(precision_scores))\n",
    "print(\"Mean recall:\", np.mean(recalls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.7656 - accuracy: 0.7796 - val_loss: 0.3330 - val_accuracy: 0.8354\n",
      "Epoch 2/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.5263 - accuracy: 0.8474 - val_loss: 0.3037 - val_accuracy: 0.8592\n",
      "Epoch 3/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4673 - accuracy: 0.8758 - val_loss: 0.2414 - val_accuracy: 0.8993\n",
      "Epoch 4/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4410 - accuracy: 0.8860 - val_loss: 0.2719 - val_accuracy: 0.8784\n",
      "Epoch 5/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4300 - accuracy: 0.8876 - val_loss: 0.2500 - val_accuracy: 0.8916\n",
      "Epoch 6/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4113 - accuracy: 0.8950 - val_loss: 0.2088 - val_accuracy: 0.9094\n",
      "Epoch 7/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4062 - accuracy: 0.8960 - val_loss: 0.2079 - val_accuracy: 0.9176\n",
      "Epoch 8/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3943 - accuracy: 0.9002 - val_loss: 0.2792 - val_accuracy: 0.8815\n",
      "Epoch 9/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3891 - accuracy: 0.9008 - val_loss: 0.2315 - val_accuracy: 0.9015\n",
      "Epoch 10/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3818 - accuracy: 0.9024 - val_loss: 0.2823 - val_accuracy: 0.8774\n",
      "Epoch 11/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3764 - accuracy: 0.9048 - val_loss: 0.2652 - val_accuracy: 0.8940\n",
      "Epoch 12/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3726 - accuracy: 0.9034 - val_loss: 0.2231 - val_accuracy: 0.9068\n",
      "Epoch 13/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3660 - accuracy: 0.9055 - val_loss: 0.2664 - val_accuracy: 0.8815\n",
      "Epoch 14/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3609 - accuracy: 0.9081 - val_loss: 0.2346 - val_accuracy: 0.9068\n",
      "Epoch 15/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3568 - accuracy: 0.9090 - val_loss: 0.2287 - val_accuracy: 0.9132\n",
      "Epoch 16/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3536 - accuracy: 0.9072 - val_loss: 0.2046 - val_accuracy: 0.9195\n",
      "Epoch 17/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3504 - accuracy: 0.9091 - val_loss: 0.2132 - val_accuracy: 0.9135\n",
      "Epoch 18/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3478 - accuracy: 0.9098 - val_loss: 0.2027 - val_accuracy: 0.9188\n",
      "Epoch 19/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3441 - accuracy: 0.9090 - val_loss: 0.2099 - val_accuracy: 0.9171\n",
      "Epoch 20/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3442 - accuracy: 0.9121 - val_loss: 0.2229 - val_accuracy: 0.9116\n",
      "Epoch 21/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3413 - accuracy: 0.9093 - val_loss: 0.1793 - val_accuracy: 0.9339\n",
      "Epoch 22/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3372 - accuracy: 0.9100 - val_loss: 0.2229 - val_accuracy: 0.9075\n",
      "Epoch 23/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3349 - accuracy: 0.9117 - val_loss: 0.2539 - val_accuracy: 0.8969\n",
      "Epoch 24/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3297 - accuracy: 0.9130 - val_loss: 0.1637 - val_accuracy: 0.9356\n",
      "Epoch 25/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3333 - accuracy: 0.9119 - val_loss: 0.2122 - val_accuracy: 0.9132\n",
      "Epoch 26/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3250 - accuracy: 0.9149 - val_loss: 0.2275 - val_accuracy: 0.9092\n",
      "Epoch 27/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.9137 - val_loss: 0.1982 - val_accuracy: 0.9183\n",
      "Epoch 28/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3291 - accuracy: 0.9131 - val_loss: 0.1944 - val_accuracy: 0.9195\n",
      "Epoch 29/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3196 - accuracy: 0.9153 - val_loss: 0.2610 - val_accuracy: 0.8919\n",
      "Epoch 30/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3178 - accuracy: 0.9133 - val_loss: 0.1976 - val_accuracy: 0.9269\n",
      "Epoch 31/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3125 - accuracy: 0.9161 - val_loss: 0.1670 - val_accuracy: 0.9322\n",
      "Epoch 32/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3138 - accuracy: 0.9174 - val_loss: 0.2085 - val_accuracy: 0.9132\n",
      "Epoch 33/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3072 - accuracy: 0.9185 - val_loss: 0.2091 - val_accuracy: 0.9140\n",
      "Epoch 34/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3081 - accuracy: 0.9168 - val_loss: 0.1867 - val_accuracy: 0.9269\n",
      "Epoch 35/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3042 - accuracy: 0.9190 - val_loss: 0.2579 - val_accuracy: 0.8971\n",
      "Epoch 36/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3054 - accuracy: 0.9171 - val_loss: 0.1867 - val_accuracy: 0.9236\n",
      "Epoch 37/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3020 - accuracy: 0.9195 - val_loss: 0.2428 - val_accuracy: 0.8976\n",
      "Epoch 38/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2969 - accuracy: 0.9192 - val_loss: 0.1912 - val_accuracy: 0.9245\n",
      "Epoch 39/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2970 - accuracy: 0.9183 - val_loss: 0.1711 - val_accuracy: 0.9327\n",
      "Epoch 40/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2936 - accuracy: 0.9210 - val_loss: 0.1755 - val_accuracy: 0.9334\n",
      "Epoch 41/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2921 - accuracy: 0.9201 - val_loss: 0.1650 - val_accuracy: 0.9402\n",
      "Epoch 42/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2936 - accuracy: 0.9197 - val_loss: 0.1586 - val_accuracy: 0.9375\n",
      "Epoch 43/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2861 - accuracy: 0.9201 - val_loss: 0.1513 - val_accuracy: 0.9402\n",
      "Epoch 44/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2856 - accuracy: 0.9227 - val_loss: 0.1731 - val_accuracy: 0.9332\n",
      "Epoch 45/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2829 - accuracy: 0.9221 - val_loss: 0.1609 - val_accuracy: 0.9378\n",
      "Epoch 46/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2830 - accuracy: 0.9234 - val_loss: 0.1766 - val_accuracy: 0.9320\n",
      "Epoch 47/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2715 - accuracy: 0.9251 - val_loss: 0.1856 - val_accuracy: 0.9293\n",
      "Epoch 48/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2765 - accuracy: 0.9251 - val_loss: 0.1661 - val_accuracy: 0.9378\n",
      "Epoch 49/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2722 - accuracy: 0.9260 - val_loss: 0.1699 - val_accuracy: 0.9375\n",
      "Epoch 50/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2728 - accuracy: 0.9257 - val_loss: 0.2053 - val_accuracy: 0.9243\n",
      "Epoch 51/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2755 - accuracy: 0.9248 - val_loss: 0.1859 - val_accuracy: 0.9284\n",
      "Epoch 52/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2725 - accuracy: 0.9252 - val_loss: 0.1569 - val_accuracy: 0.9406\n",
      "Epoch 53/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2677 - accuracy: 0.9267 - val_loss: 0.1659 - val_accuracy: 0.9351\n",
      "Epoch 54/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2609 - accuracy: 0.9278 - val_loss: 0.1864 - val_accuracy: 0.9267\n",
      "Epoch 55/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2589 - accuracy: 0.9292 - val_loss: 0.1944 - val_accuracy: 0.9205\n",
      "Epoch 56/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2582 - accuracy: 0.9297 - val_loss: 0.1852 - val_accuracy: 0.9301\n",
      "Epoch 57/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2560 - accuracy: 0.9308 - val_loss: 0.2025 - val_accuracy: 0.9224\n",
      "Epoch 58/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2589 - accuracy: 0.9293 - val_loss: 0.1633 - val_accuracy: 0.9416\n",
      "Epoch 59/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2512 - accuracy: 0.9312 - val_loss: 0.1773 - val_accuracy: 0.9339\n",
      "Epoch 60/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2521 - accuracy: 0.9317 - val_loss: 0.1528 - val_accuracy: 0.9418\n",
      "Epoch 61/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2590 - accuracy: 0.9314 - val_loss: 0.1492 - val_accuracy: 0.9433\n",
      "Epoch 62/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2503 - accuracy: 0.9326 - val_loss: 0.1495 - val_accuracy: 0.9452\n",
      "Epoch 63/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2481 - accuracy: 0.9337 - val_loss: 0.1813 - val_accuracy: 0.9296\n",
      "Epoch 64/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.9355 - val_loss: 0.1568 - val_accuracy: 0.9390\n",
      "Epoch 65/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2416 - accuracy: 0.9330 - val_loss: 0.1575 - val_accuracy: 0.9440\n",
      "Epoch 66/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2393 - accuracy: 0.9341 - val_loss: 0.1673 - val_accuracy: 0.9315\n",
      "Epoch 67/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2478 - accuracy: 0.9337 - val_loss: 0.1846 - val_accuracy: 0.9257\n",
      "Epoch 68/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2375 - accuracy: 0.9356 - val_loss: 0.1623 - val_accuracy: 0.9392\n",
      "Epoch 69/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2354 - accuracy: 0.9370 - val_loss: 0.1666 - val_accuracy: 0.9368\n",
      "Epoch 70/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2322 - accuracy: 0.9374 - val_loss: 0.1477 - val_accuracy: 0.9471\n",
      "Epoch 71/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2356 - accuracy: 0.9360 - val_loss: 0.1681 - val_accuracy: 0.9370\n",
      "Epoch 72/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2298 - accuracy: 0.9369 - val_loss: 0.1526 - val_accuracy: 0.9428\n",
      "Epoch 73/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2313 - accuracy: 0.9381 - val_loss: 0.1742 - val_accuracy: 0.9409\n",
      "Epoch 74/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2226 - accuracy: 0.9389 - val_loss: 0.1805 - val_accuracy: 0.9332\n",
      "Epoch 75/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2262 - accuracy: 0.9390 - val_loss: 0.1618 - val_accuracy: 0.9411\n",
      "Epoch 76/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2271 - accuracy: 0.9386 - val_loss: 0.1746 - val_accuracy: 0.9332\n",
      "Epoch 77/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2283 - accuracy: 0.9387 - val_loss: 0.1182 - val_accuracy: 0.9534\n",
      "Epoch 78/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2263 - accuracy: 0.9389 - val_loss: 0.1626 - val_accuracy: 0.9399\n",
      "Epoch 79/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2200 - accuracy: 0.9423 - val_loss: 0.1577 - val_accuracy: 0.9428\n",
      "Epoch 80/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2213 - accuracy: 0.9406 - val_loss: 0.1360 - val_accuracy: 0.9503\n",
      "Epoch 81/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2190 - accuracy: 0.9429 - val_loss: 0.1934 - val_accuracy: 0.9382\n",
      "Epoch 82/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2188 - accuracy: 0.9426 - val_loss: 0.1718 - val_accuracy: 0.9370\n",
      "Epoch 83/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2201 - accuracy: 0.9410 - val_loss: 0.2192 - val_accuracy: 0.9125\n",
      "Epoch 84/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2180 - accuracy: 0.9418 - val_loss: 0.1945 - val_accuracy: 0.9226\n",
      "Epoch 85/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2165 - accuracy: 0.9424 - val_loss: 0.1542 - val_accuracy: 0.9430\n",
      "Epoch 86/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2145 - accuracy: 0.9426 - val_loss: 0.1807 - val_accuracy: 0.9284\n",
      "521/521 - 0s - loss: 0.1704 - accuracy: 0.9317 - 354ms/epoch - 680us/step\n",
      "131/131 [==============================] - 0s 654us/step\n",
      "Epoch 1/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.7182 - accuracy: 0.8014 - val_loss: 0.3210 - val_accuracy: 0.8520\n",
      "Epoch 2/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4972 - accuracy: 0.8712 - val_loss: 0.2903 - val_accuracy: 0.8707\n",
      "Epoch 3/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4393 - accuracy: 0.8872 - val_loss: 0.2252 - val_accuracy: 0.9084\n",
      "Epoch 4/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4207 - accuracy: 0.8946 - val_loss: 0.3386 - val_accuracy: 0.8616\n",
      "Epoch 5/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4071 - accuracy: 0.8973 - val_loss: 0.3198 - val_accuracy: 0.8666\n",
      "Epoch 6/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3899 - accuracy: 0.9004 - val_loss: 0.2698 - val_accuracy: 0.8890\n",
      "Epoch 7/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3831 - accuracy: 0.9034 - val_loss: 0.2554 - val_accuracy: 0.8995\n",
      "Epoch 8/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3745 - accuracy: 0.9055 - val_loss: 0.2551 - val_accuracy: 0.8928\n",
      "Epoch 9/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3785 - accuracy: 0.9023 - val_loss: 0.2132 - val_accuracy: 0.9147\n",
      "Epoch 10/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3651 - accuracy: 0.9054 - val_loss: 0.2820 - val_accuracy: 0.8919\n",
      "Epoch 11/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3626 - accuracy: 0.9057 - val_loss: 0.2418 - val_accuracy: 0.9065\n",
      "Epoch 12/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3553 - accuracy: 0.9064 - val_loss: 0.2515 - val_accuracy: 0.8983\n",
      "Epoch 13/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3518 - accuracy: 0.9087 - val_loss: 0.2313 - val_accuracy: 0.9082\n",
      "Epoch 14/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3534 - accuracy: 0.9077 - val_loss: 0.2894 - val_accuracy: 0.8782\n",
      "Epoch 15/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3442 - accuracy: 0.9101 - val_loss: 0.2246 - val_accuracy: 0.9096\n",
      "Epoch 16/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3429 - accuracy: 0.9098 - val_loss: 0.2034 - val_accuracy: 0.9190\n",
      "Epoch 17/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3403 - accuracy: 0.9106 - val_loss: 0.2415 - val_accuracy: 0.9015\n",
      "Epoch 18/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3418 - accuracy: 0.9079 - val_loss: 0.2727 - val_accuracy: 0.8899\n",
      "Epoch 19/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3309 - accuracy: 0.9138 - val_loss: 0.2751 - val_accuracy: 0.8919\n",
      "Epoch 20/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3309 - accuracy: 0.9123 - val_loss: 0.2337 - val_accuracy: 0.9060\n",
      "Epoch 21/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3265 - accuracy: 0.9139 - val_loss: 0.1860 - val_accuracy: 0.9274\n",
      "Epoch 22/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3235 - accuracy: 0.9145 - val_loss: 0.2336 - val_accuracy: 0.9065\n",
      "Epoch 23/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3194 - accuracy: 0.9155 - val_loss: 0.2283 - val_accuracy: 0.9120\n",
      "Epoch 24/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3190 - accuracy: 0.9153 - val_loss: 0.2120 - val_accuracy: 0.9156\n",
      "Epoch 25/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3194 - accuracy: 0.9156 - val_loss: 0.1917 - val_accuracy: 0.9229\n",
      "Epoch 26/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3135 - accuracy: 0.9183 - val_loss: 0.2466 - val_accuracy: 0.9036\n",
      "Epoch 27/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3116 - accuracy: 0.9168 - val_loss: 0.2882 - val_accuracy: 0.8866\n",
      "Epoch 28/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3069 - accuracy: 0.9180 - val_loss: 0.2099 - val_accuracy: 0.9176\n",
      "Epoch 29/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3105 - accuracy: 0.9191 - val_loss: 0.1990 - val_accuracy: 0.9224\n",
      "Epoch 30/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3081 - accuracy: 0.9197 - val_loss: 0.2507 - val_accuracy: 0.9034\n",
      "Epoch 31/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3036 - accuracy: 0.9199 - val_loss: 0.2348 - val_accuracy: 0.9036\n",
      "Epoch 32/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2988 - accuracy: 0.9189 - val_loss: 0.2223 - val_accuracy: 0.9156\n",
      "Epoch 33/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2998 - accuracy: 0.9226 - val_loss: 0.2094 - val_accuracy: 0.9173\n",
      "Epoch 34/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2968 - accuracy: 0.9213 - val_loss: 0.2015 - val_accuracy: 0.9221\n",
      "Epoch 35/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2948 - accuracy: 0.9222 - val_loss: 0.2262 - val_accuracy: 0.9101\n",
      "Epoch 36/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2997 - accuracy: 0.9207 - val_loss: 0.2110 - val_accuracy: 0.9149\n",
      "Epoch 37/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2909 - accuracy: 0.9233 - val_loss: 0.2113 - val_accuracy: 0.9140\n",
      "Epoch 38/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2876 - accuracy: 0.9240 - val_loss: 0.1752 - val_accuracy: 0.9289\n",
      "Epoch 39/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2872 - accuracy: 0.9236 - val_loss: 0.1750 - val_accuracy: 0.9301\n",
      "Epoch 40/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2861 - accuracy: 0.9251 - val_loss: 0.2003 - val_accuracy: 0.9238\n",
      "Epoch 41/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2843 - accuracy: 0.9242 - val_loss: 0.1978 - val_accuracy: 0.9226\n",
      "Epoch 42/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2784 - accuracy: 0.9251 - val_loss: 0.2390 - val_accuracy: 0.9125\n",
      "Epoch 43/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2818 - accuracy: 0.9262 - val_loss: 0.2123 - val_accuracy: 0.9176\n",
      "Epoch 44/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2852 - accuracy: 0.9234 - val_loss: 0.1992 - val_accuracy: 0.9217\n",
      "Epoch 45/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2770 - accuracy: 0.9248 - val_loss: 0.2269 - val_accuracy: 0.9084\n",
      "Epoch 46/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2779 - accuracy: 0.9285 - val_loss: 0.2182 - val_accuracy: 0.9161\n",
      "Epoch 47/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2742 - accuracy: 0.9276 - val_loss: 0.2360 - val_accuracy: 0.9082\n",
      "Epoch 48/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2703 - accuracy: 0.9273 - val_loss: 0.1888 - val_accuracy: 0.9250\n",
      "Epoch 49/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2704 - accuracy: 0.9289 - val_loss: 0.1825 - val_accuracy: 0.9363\n",
      "Epoch 50/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2705 - accuracy: 0.9296 - val_loss: 0.2049 - val_accuracy: 0.9190\n",
      "Epoch 51/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2615 - accuracy: 0.9303 - val_loss: 0.2463 - val_accuracy: 0.9017\n",
      "Epoch 52/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2654 - accuracy: 0.9300 - val_loss: 0.2040 - val_accuracy: 0.9238\n",
      "Epoch 53/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2638 - accuracy: 0.9305 - val_loss: 0.2071 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2696 - accuracy: 0.9301 - val_loss: 0.1956 - val_accuracy: 0.9260\n",
      "Epoch 55/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2654 - accuracy: 0.9298 - val_loss: 0.2370 - val_accuracy: 0.9082\n",
      "Epoch 56/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2586 - accuracy: 0.9300 - val_loss: 0.1680 - val_accuracy: 0.9370\n",
      "Epoch 57/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2535 - accuracy: 0.9317 - val_loss: 0.1597 - val_accuracy: 0.9414\n",
      "Epoch 58/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2592 - accuracy: 0.9319 - val_loss: 0.2126 - val_accuracy: 0.9149\n",
      "Epoch 59/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2563 - accuracy: 0.9326 - val_loss: 0.1657 - val_accuracy: 0.9329\n",
      "Epoch 60/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2545 - accuracy: 0.9329 - val_loss: 0.1718 - val_accuracy: 0.9356\n",
      "Epoch 61/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2531 - accuracy: 0.9317 - val_loss: 0.1822 - val_accuracy: 0.9327\n",
      "Epoch 62/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2493 - accuracy: 0.9355 - val_loss: 0.2019 - val_accuracy: 0.9231\n",
      "Epoch 63/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2485 - accuracy: 0.9331 - val_loss: 0.1836 - val_accuracy: 0.9286\n",
      "Epoch 64/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2492 - accuracy: 0.9345 - val_loss: 0.2019 - val_accuracy: 0.9219\n",
      "Epoch 65/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.9361 - val_loss: 0.1902 - val_accuracy: 0.9248\n",
      "Epoch 66/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2401 - accuracy: 0.9361 - val_loss: 0.1957 - val_accuracy: 0.9298\n",
      "Epoch 67/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2416 - accuracy: 0.9370 - val_loss: 0.2023 - val_accuracy: 0.9255\n",
      "Epoch 68/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2392 - accuracy: 0.9370 - val_loss: 0.1958 - val_accuracy: 0.9219\n",
      "Epoch 69/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2413 - accuracy: 0.9351 - val_loss: 0.1536 - val_accuracy: 0.9416\n",
      "Epoch 70/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2408 - accuracy: 0.9366 - val_loss: 0.1807 - val_accuracy: 0.9305\n",
      "Epoch 71/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2385 - accuracy: 0.9372 - val_loss: 0.1645 - val_accuracy: 0.9368\n",
      "Epoch 72/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2376 - accuracy: 0.9377 - val_loss: 0.1527 - val_accuracy: 0.9440\n",
      "Epoch 73/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2339 - accuracy: 0.9382 - val_loss: 0.1776 - val_accuracy: 0.9358\n",
      "Epoch 74/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2286 - accuracy: 0.9386 - val_loss: 0.1603 - val_accuracy: 0.9423\n",
      "Epoch 75/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2321 - accuracy: 0.9385 - val_loss: 0.2126 - val_accuracy: 0.9193\n",
      "Epoch 76/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2283 - accuracy: 0.9394 - val_loss: 0.1580 - val_accuracy: 0.9385\n",
      "Epoch 77/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2313 - accuracy: 0.9389 - val_loss: 0.1382 - val_accuracy: 0.9488\n",
      "Epoch 78/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2271 - accuracy: 0.9402 - val_loss: 0.1622 - val_accuracy: 0.9399\n",
      "Epoch 79/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2296 - accuracy: 0.9400 - val_loss: 0.1678 - val_accuracy: 0.9392\n",
      "Epoch 80/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2246 - accuracy: 0.9417 - val_loss: 0.1814 - val_accuracy: 0.9286\n",
      "Epoch 81/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2262 - accuracy: 0.9402 - val_loss: 0.1522 - val_accuracy: 0.9447\n",
      "Epoch 82/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2234 - accuracy: 0.9412 - val_loss: 0.1644 - val_accuracy: 0.9375\n",
      "Epoch 83/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2216 - accuracy: 0.9424 - val_loss: 0.1882 - val_accuracy: 0.9382\n",
      "Epoch 84/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2216 - accuracy: 0.9416 - val_loss: 0.1723 - val_accuracy: 0.9354\n",
      "Epoch 85/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2148 - accuracy: 0.9423 - val_loss: 0.1826 - val_accuracy: 0.9315\n",
      "Epoch 86/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2279 - accuracy: 0.9397 - val_loss: 0.1742 - val_accuracy: 0.9358\n",
      "Epoch 87/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2197 - accuracy: 0.9434 - val_loss: 0.2334 - val_accuracy: 0.9147\n",
      "Epoch 88/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2427 - accuracy: 0.9367 - val_loss: 0.1798 - val_accuracy: 0.9315\n",
      "Epoch 89/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2130 - accuracy: 0.9427 - val_loss: 0.1364 - val_accuracy: 0.9507\n",
      "Epoch 90/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2106 - accuracy: 0.9453 - val_loss: 0.1830 - val_accuracy: 0.9317\n",
      "Epoch 91/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2167 - accuracy: 0.9448 - val_loss: 0.2149 - val_accuracy: 0.9233\n",
      "Epoch 92/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2119 - accuracy: 0.9431 - val_loss: 0.1393 - val_accuracy: 0.9510\n",
      "Epoch 93/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2091 - accuracy: 0.9441 - val_loss: 0.1580 - val_accuracy: 0.9430\n",
      "Epoch 94/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2099 - accuracy: 0.9454 - val_loss: 0.1554 - val_accuracy: 0.9418\n",
      "Epoch 95/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2098 - accuracy: 0.9453 - val_loss: 0.1734 - val_accuracy: 0.9351\n",
      "Epoch 96/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2151 - accuracy: 0.9444 - val_loss: 0.1641 - val_accuracy: 0.9426\n",
      "Epoch 97/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2081 - accuracy: 0.9445 - val_loss: 0.1396 - val_accuracy: 0.9464\n",
      "Epoch 98/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2080 - accuracy: 0.9463 - val_loss: 0.1508 - val_accuracy: 0.9474\n",
      "Epoch 99/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2099 - accuracy: 0.9447 - val_loss: 0.1850 - val_accuracy: 0.9339\n",
      "Epoch 100/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2065 - accuracy: 0.9468 - val_loss: 0.1806 - val_accuracy: 0.9382\n",
      "Epoch 101/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2049 - accuracy: 0.9464 - val_loss: 0.1850 - val_accuracy: 0.9296\n",
      "Epoch 102/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2012 - accuracy: 0.9471 - val_loss: 0.1911 - val_accuracy: 0.9303\n",
      "Epoch 103/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2013 - accuracy: 0.9475 - val_loss: 0.1592 - val_accuracy: 0.9418\n",
      "Epoch 104/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2046 - accuracy: 0.9454 - val_loss: 0.1430 - val_accuracy: 0.9478\n",
      "Epoch 105/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1965 - accuracy: 0.9487 - val_loss: 0.1720 - val_accuracy: 0.9373\n",
      "Epoch 106/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2042 - accuracy: 0.9459 - val_loss: 0.1393 - val_accuracy: 0.9519\n",
      "Epoch 107/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1979 - accuracy: 0.9486 - val_loss: 0.2001 - val_accuracy: 0.9368\n",
      "Epoch 108/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1966 - accuracy: 0.9495 - val_loss: 0.1655 - val_accuracy: 0.9418\n",
      "Epoch 109/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1920 - accuracy: 0.9501 - val_loss: 0.1595 - val_accuracy: 0.9469\n",
      "Epoch 110/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1969 - accuracy: 0.9490 - val_loss: 0.1602 - val_accuracy: 0.9462\n",
      "Epoch 111/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1999 - accuracy: 0.9487 - val_loss: 0.1771 - val_accuracy: 0.9387\n",
      "Epoch 112/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1917 - accuracy: 0.9500 - val_loss: 0.1452 - val_accuracy: 0.9505\n",
      "Epoch 113/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1941 - accuracy: 0.9505 - val_loss: 0.1798 - val_accuracy: 0.9361\n",
      "Epoch 114/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1979 - accuracy: 0.9482 - val_loss: 0.1468 - val_accuracy: 0.9498\n",
      "Epoch 115/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1921 - accuracy: 0.9496 - val_loss: 0.1708 - val_accuracy: 0.9373\n",
      "Epoch 116/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1927 - accuracy: 0.9501 - val_loss: 0.1784 - val_accuracy: 0.9373\n",
      "Epoch 117/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1835 - accuracy: 0.9528 - val_loss: 0.1549 - val_accuracy: 0.9474\n",
      "Epoch 118/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1906 - accuracy: 0.9501 - val_loss: 0.1261 - val_accuracy: 0.9563\n",
      "Epoch 119/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1865 - accuracy: 0.9523 - val_loss: 0.1624 - val_accuracy: 0.9452\n",
      "Epoch 120/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1859 - accuracy: 0.9519 - val_loss: 0.1827 - val_accuracy: 0.9414\n",
      "Epoch 121/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1840 - accuracy: 0.9523 - val_loss: 0.1601 - val_accuracy: 0.9423\n",
      "Epoch 122/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1914 - accuracy: 0.9503 - val_loss: 0.1414 - val_accuracy: 0.9536\n",
      "521/521 - 0s - loss: 0.1122 - accuracy: 0.9594 - 351ms/epoch - 674us/step\n",
      "131/131 [==============================] - 0s 662us/step\n",
      "Epoch 1/1000\n",
      "521/521 [==============================] - 2s 2ms/step - loss: 0.7596 - accuracy: 0.8040 - val_loss: 0.3690 - val_accuracy: 0.8183\n",
      "Epoch 2/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.5302 - accuracy: 0.8491 - val_loss: 0.2787 - val_accuracy: 0.8671\n",
      "Epoch 3/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4735 - accuracy: 0.8728 - val_loss: 0.3180 - val_accuracy: 0.8490\n",
      "Epoch 4/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4505 - accuracy: 0.8781 - val_loss: 0.2341 - val_accuracy: 0.9010\n",
      "Epoch 5/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4284 - accuracy: 0.8890 - val_loss: 0.2579 - val_accuracy: 0.8885\n",
      "Epoch 6/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4139 - accuracy: 0.8925 - val_loss: 0.2627 - val_accuracy: 0.8868\n",
      "Epoch 7/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3998 - accuracy: 0.8939 - val_loss: 0.2182 - val_accuracy: 0.9087\n",
      "Epoch 8/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3938 - accuracy: 0.8984 - val_loss: 0.2431 - val_accuracy: 0.8971\n",
      "Epoch 9/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3870 - accuracy: 0.8980 - val_loss: 0.1900 - val_accuracy: 0.9228\n",
      "Epoch 10/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3807 - accuracy: 0.9007 - val_loss: 0.2264 - val_accuracy: 0.9062\n",
      "Epoch 11/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3694 - accuracy: 0.9015 - val_loss: 0.2235 - val_accuracy: 0.9101\n",
      "Epoch 12/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3641 - accuracy: 0.9060 - val_loss: 0.2535 - val_accuracy: 0.8930\n",
      "Epoch 13/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3660 - accuracy: 0.9036 - val_loss: 0.2174 - val_accuracy: 0.9099\n",
      "Epoch 14/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3583 - accuracy: 0.9057 - val_loss: 0.2679 - val_accuracy: 0.8916\n",
      "Epoch 15/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3520 - accuracy: 0.9049 - val_loss: 0.2139 - val_accuracy: 0.9123\n",
      "Epoch 16/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3497 - accuracy: 0.9078 - val_loss: 0.2067 - val_accuracy: 0.9147\n",
      "Epoch 17/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3445 - accuracy: 0.9103 - val_loss: 0.2133 - val_accuracy: 0.9123\n",
      "Epoch 18/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3406 - accuracy: 0.9090 - val_loss: 0.1708 - val_accuracy: 0.9317\n",
      "Epoch 19/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.9085 - val_loss: 0.2512 - val_accuracy: 0.8962\n",
      "Epoch 20/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3364 - accuracy: 0.9096 - val_loss: 0.2156 - val_accuracy: 0.9101\n",
      "Epoch 21/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3317 - accuracy: 0.9096 - val_loss: 0.2366 - val_accuracy: 0.9046\n",
      "Epoch 22/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3286 - accuracy: 0.9124 - val_loss: 0.2199 - val_accuracy: 0.9139\n",
      "Epoch 23/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3302 - accuracy: 0.9131 - val_loss: 0.2134 - val_accuracy: 0.9101\n",
      "Epoch 24/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3209 - accuracy: 0.9143 - val_loss: 0.2516 - val_accuracy: 0.9005\n",
      "Epoch 25/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3194 - accuracy: 0.9140 - val_loss: 0.2186 - val_accuracy: 0.9108\n",
      "Epoch 26/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3191 - accuracy: 0.9142 - val_loss: 0.2329 - val_accuracy: 0.9002\n",
      "Epoch 27/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3168 - accuracy: 0.9156 - val_loss: 0.2006 - val_accuracy: 0.9209\n",
      "Epoch 28/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3164 - accuracy: 0.9134 - val_loss: 0.2011 - val_accuracy: 0.9192\n",
      "Epoch 29/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3104 - accuracy: 0.9171 - val_loss: 0.1934 - val_accuracy: 0.9226\n",
      "Epoch 30/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3070 - accuracy: 0.9179 - val_loss: 0.2341 - val_accuracy: 0.9067\n",
      "Epoch 31/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3012 - accuracy: 0.9192 - val_loss: 0.1834 - val_accuracy: 0.9272\n",
      "Epoch 32/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3001 - accuracy: 0.9202 - val_loss: 0.2137 - val_accuracy: 0.9156\n",
      "Epoch 33/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2982 - accuracy: 0.9196 - val_loss: 0.2269 - val_accuracy: 0.9038\n",
      "Epoch 34/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2974 - accuracy: 0.9203 - val_loss: 0.2066 - val_accuracy: 0.9171\n",
      "Epoch 35/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2930 - accuracy: 0.9194 - val_loss: 0.1727 - val_accuracy: 0.9274\n",
      "Epoch 36/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2905 - accuracy: 0.9222 - val_loss: 0.1903 - val_accuracy: 0.9219\n",
      "Epoch 37/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2861 - accuracy: 0.9215 - val_loss: 0.1741 - val_accuracy: 0.9293\n",
      "Epoch 38/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2883 - accuracy: 0.9209 - val_loss: 0.1938 - val_accuracy: 0.9252\n",
      "Epoch 39/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2845 - accuracy: 0.9236 - val_loss: 0.2041 - val_accuracy: 0.9183\n",
      "Epoch 40/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2853 - accuracy: 0.9227 - val_loss: 0.1690 - val_accuracy: 0.9288\n",
      "Epoch 41/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2771 - accuracy: 0.9245 - val_loss: 0.1574 - val_accuracy: 0.9380\n",
      "Epoch 42/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2855 - accuracy: 0.9244 - val_loss: 0.1765 - val_accuracy: 0.9276\n",
      "Epoch 43/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2815 - accuracy: 0.9242 - val_loss: 0.1815 - val_accuracy: 0.9262\n",
      "Epoch 44/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2762 - accuracy: 0.9264 - val_loss: 0.1754 - val_accuracy: 0.9264\n",
      "Epoch 45/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2737 - accuracy: 0.9251 - val_loss: 0.1940 - val_accuracy: 0.9250\n",
      "Epoch 46/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2788 - accuracy: 0.9264 - val_loss: 0.2150 - val_accuracy: 0.9091\n",
      "Epoch 47/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2701 - accuracy: 0.9267 - val_loss: 0.1612 - val_accuracy: 0.9351\n",
      "Epoch 48/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2656 - accuracy: 0.9304 - val_loss: 0.1851 - val_accuracy: 0.9248\n",
      "Epoch 49/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2690 - accuracy: 0.9268 - val_loss: 0.1713 - val_accuracy: 0.9329\n",
      "Epoch 50/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2649 - accuracy: 0.9284 - val_loss: 0.1771 - val_accuracy: 0.9267\n",
      "Epoch 51/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2662 - accuracy: 0.9278 - val_loss: 0.1648 - val_accuracy: 0.9349\n",
      "Epoch 52/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2639 - accuracy: 0.9290 - val_loss: 0.2176 - val_accuracy: 0.9118\n",
      "Epoch 53/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2624 - accuracy: 0.9295 - val_loss: 0.2066 - val_accuracy: 0.9183\n",
      "521/521 - 0s - loss: 0.1899 - accuracy: 0.9249 - 469ms/epoch - 900us/step\n",
      "130/130 [==============================] - 0s 775us/step\n",
      "Epoch 1/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.7947 - accuracy: 0.8123 - val_loss: 0.3090 - val_accuracy: 0.8442\n",
      "Epoch 2/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.5145 - accuracy: 0.8573 - val_loss: 0.2822 - val_accuracy: 0.8608\n",
      "Epoch 3/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8704 - val_loss: 0.2703 - val_accuracy: 0.8762\n",
      "Epoch 4/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4350 - accuracy: 0.8819 - val_loss: 0.2276 - val_accuracy: 0.9000\n",
      "Epoch 5/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4173 - accuracy: 0.8881 - val_loss: 0.2417 - val_accuracy: 0.8928\n",
      "Epoch 6/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4077 - accuracy: 0.8888 - val_loss: 0.2432 - val_accuracy: 0.8863\n",
      "Epoch 7/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3931 - accuracy: 0.8987 - val_loss: 0.2571 - val_accuracy: 0.8897\n",
      "Epoch 8/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8951 - val_loss: 0.2620 - val_accuracy: 0.8928\n",
      "Epoch 9/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3929 - accuracy: 0.8933 - val_loss: 0.1920 - val_accuracy: 0.9214\n",
      "Epoch 10/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3763 - accuracy: 0.9013 - val_loss: 0.2910 - val_accuracy: 0.8721\n",
      "Epoch 11/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3714 - accuracy: 0.9007 - val_loss: 0.1832 - val_accuracy: 0.9293\n",
      "Epoch 12/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3631 - accuracy: 0.9048 - val_loss: 0.2321 - val_accuracy: 0.8986\n",
      "Epoch 13/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3583 - accuracy: 0.9056 - val_loss: 0.2046 - val_accuracy: 0.9120\n",
      "Epoch 14/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3564 - accuracy: 0.9054 - val_loss: 0.2409 - val_accuracy: 0.8904\n",
      "Epoch 15/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3515 - accuracy: 0.9063 - val_loss: 0.3009 - val_accuracy: 0.8572\n",
      "Epoch 16/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3463 - accuracy: 0.9075 - val_loss: 0.2011 - val_accuracy: 0.9137\n",
      "Epoch 17/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3398 - accuracy: 0.9090 - val_loss: 0.2259 - val_accuracy: 0.9046\n",
      "Epoch 18/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3378 - accuracy: 0.9111 - val_loss: 0.1918 - val_accuracy: 0.9221\n",
      "Epoch 19/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3386 - accuracy: 0.9094 - val_loss: 0.1558 - val_accuracy: 0.9346\n",
      "Epoch 20/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9127 - val_loss: 0.1750 - val_accuracy: 0.9240\n",
      "Epoch 21/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3264 - accuracy: 0.9143 - val_loss: 0.2604 - val_accuracy: 0.8880\n",
      "Epoch 22/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3252 - accuracy: 0.9120 - val_loss: 0.1864 - val_accuracy: 0.9240\n",
      "Epoch 23/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3194 - accuracy: 0.9139 - val_loss: 0.2206 - val_accuracy: 0.9048\n",
      "Epoch 24/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3200 - accuracy: 0.9141 - val_loss: 0.2683 - val_accuracy: 0.8827\n",
      "Epoch 25/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3148 - accuracy: 0.9143 - val_loss: 0.2260 - val_accuracy: 0.9026\n",
      "Epoch 26/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3156 - accuracy: 0.9156 - val_loss: 0.2137 - val_accuracy: 0.9079\n",
      "Epoch 27/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3105 - accuracy: 0.9179 - val_loss: 0.2569 - val_accuracy: 0.8897\n",
      "Epoch 28/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3082 - accuracy: 0.9169 - val_loss: 0.2042 - val_accuracy: 0.9144\n",
      "Epoch 29/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3051 - accuracy: 0.9186 - val_loss: 0.2066 - val_accuracy: 0.9075\n",
      "Epoch 30/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3054 - accuracy: 0.9184 - val_loss: 0.2311 - val_accuracy: 0.8962\n",
      "Epoch 31/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3019 - accuracy: 0.9179 - val_loss: 0.2407 - val_accuracy: 0.9029\n",
      "Epoch 32/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3027 - accuracy: 0.9189 - val_loss: 0.2061 - val_accuracy: 0.9135\n",
      "Epoch 33/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2976 - accuracy: 0.9203 - val_loss: 0.1977 - val_accuracy: 0.9168\n",
      "Epoch 34/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2945 - accuracy: 0.9212 - val_loss: 0.1985 - val_accuracy: 0.9190\n",
      "Epoch 35/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2974 - accuracy: 0.9193 - val_loss: 0.1802 - val_accuracy: 0.9260\n",
      "Epoch 36/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2911 - accuracy: 0.9216 - val_loss: 0.2197 - val_accuracy: 0.9118\n",
      "Epoch 37/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2910 - accuracy: 0.9214 - val_loss: 0.2122 - val_accuracy: 0.9087\n",
      "Epoch 38/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2882 - accuracy: 0.9226 - val_loss: 0.1890 - val_accuracy: 0.9173\n",
      "Epoch 39/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2844 - accuracy: 0.9244 - val_loss: 0.1938 - val_accuracy: 0.9159\n",
      "Epoch 40/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2831 - accuracy: 0.9242 - val_loss: 0.1830 - val_accuracy: 0.9204\n",
      "Epoch 41/1000\n",
      "521/521 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.9243 - val_loss: 0.1658 - val_accuracy: 0.9356\n",
      "Epoch 42/1000\n",
      "521/521 [==============================] - 1s 2ms/step - loss: 0.2781 - accuracy: 0.9268 - val_loss: 0.1870 - val_accuracy: 0.9195\n",
      "Epoch 43/1000\n",
      "521/521 [==============================] - 1s 2ms/step - loss: 0.2782 - accuracy: 0.9250 - val_loss: 0.2059 - val_accuracy: 0.9118\n",
      "Epoch 44/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2727 - accuracy: 0.9265 - val_loss: 0.2157 - val_accuracy: 0.9120\n",
      "Epoch 45/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2835 - accuracy: 0.9255 - val_loss: 0.2012 - val_accuracy: 0.9142\n",
      "Epoch 46/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2704 - accuracy: 0.9280 - val_loss: 0.1826 - val_accuracy: 0.9233\n",
      "Epoch 47/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2699 - accuracy: 0.9271 - val_loss: 0.1579 - val_accuracy: 0.9344\n",
      "Epoch 48/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2707 - accuracy: 0.9273 - val_loss: 0.1812 - val_accuracy: 0.9240\n",
      "Epoch 49/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2662 - accuracy: 0.9287 - val_loss: 0.2006 - val_accuracy: 0.9185\n",
      "Epoch 50/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2622 - accuracy: 0.9295 - val_loss: 0.1794 - val_accuracy: 0.9267\n",
      "Epoch 51/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2674 - accuracy: 0.9281 - val_loss: 0.2063 - val_accuracy: 0.9130\n",
      "Epoch 52/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2616 - accuracy: 0.9288 - val_loss: 0.1636 - val_accuracy: 0.9332\n",
      "Epoch 53/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2607 - accuracy: 0.9309 - val_loss: 0.1775 - val_accuracy: 0.9214\n",
      "Epoch 54/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2584 - accuracy: 0.9318 - val_loss: 0.1496 - val_accuracy: 0.9404\n",
      "Epoch 55/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2583 - accuracy: 0.9314 - val_loss: 0.1734 - val_accuracy: 0.9260\n",
      "Epoch 56/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.9322 - val_loss: 0.1883 - val_accuracy: 0.9202\n",
      "Epoch 57/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2517 - accuracy: 0.9336 - val_loss: 0.1816 - val_accuracy: 0.9252\n",
      "Epoch 58/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2519 - accuracy: 0.9332 - val_loss: 0.1490 - val_accuracy: 0.9382\n",
      "Epoch 59/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2520 - accuracy: 0.9334 - val_loss: 0.1806 - val_accuracy: 0.9219\n",
      "Epoch 60/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2475 - accuracy: 0.9349 - val_loss: 0.1692 - val_accuracy: 0.9329\n",
      "Epoch 61/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.9356 - val_loss: 0.1281 - val_accuracy: 0.9466\n",
      "Epoch 62/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.9359 - val_loss: 0.1962 - val_accuracy: 0.9168\n",
      "Epoch 63/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.9343 - val_loss: 0.1496 - val_accuracy: 0.9409\n",
      "Epoch 64/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2377 - accuracy: 0.9385 - val_loss: 0.1808 - val_accuracy: 0.9276\n",
      "Epoch 65/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2365 - accuracy: 0.9371 - val_loss: 0.1803 - val_accuracy: 0.9245\n",
      "Epoch 66/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2336 - accuracy: 0.9388 - val_loss: 0.1576 - val_accuracy: 0.9349\n",
      "Epoch 67/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2389 - accuracy: 0.9365 - val_loss: 0.1871 - val_accuracy: 0.9224\n",
      "Epoch 68/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2386 - accuracy: 0.9359 - val_loss: 0.1654 - val_accuracy: 0.9317\n",
      "Epoch 69/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2281 - accuracy: 0.9389 - val_loss: 0.2084 - val_accuracy: 0.9144\n",
      "Epoch 70/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2312 - accuracy: 0.9385 - val_loss: 0.1631 - val_accuracy: 0.9339\n",
      "Epoch 71/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2272 - accuracy: 0.9395 - val_loss: 0.1298 - val_accuracy: 0.9454\n",
      "Epoch 72/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2307 - accuracy: 0.9389 - val_loss: 0.1406 - val_accuracy: 0.9433\n",
      "Epoch 73/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2241 - accuracy: 0.9414 - val_loss: 0.1586 - val_accuracy: 0.9344\n",
      "Epoch 74/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2256 - accuracy: 0.9401 - val_loss: 0.1721 - val_accuracy: 0.9327\n",
      "Epoch 75/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2250 - accuracy: 0.9404 - val_loss: 0.1235 - val_accuracy: 0.9536\n",
      "Epoch 76/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2187 - accuracy: 0.9424 - val_loss: 0.1574 - val_accuracy: 0.9377\n",
      "Epoch 77/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2188 - accuracy: 0.9436 - val_loss: 0.1571 - val_accuracy: 0.9392\n",
      "Epoch 78/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2156 - accuracy: 0.9441 - val_loss: 0.1607 - val_accuracy: 0.9397\n",
      "Epoch 79/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2203 - accuracy: 0.9415 - val_loss: 0.1562 - val_accuracy: 0.9385\n",
      "Epoch 80/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2127 - accuracy: 0.9443 - val_loss: 0.1969 - val_accuracy: 0.9240\n",
      "Epoch 81/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2181 - accuracy: 0.9442 - val_loss: 0.2540 - val_accuracy: 0.8974\n",
      "Epoch 82/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2166 - accuracy: 0.9424 - val_loss: 0.1537 - val_accuracy: 0.9413\n",
      "Epoch 83/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2167 - accuracy: 0.9436 - val_loss: 0.1452 - val_accuracy: 0.9433\n",
      "Epoch 84/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2132 - accuracy: 0.9434 - val_loss: 0.1366 - val_accuracy: 0.9442\n",
      "Epoch 85/1000\n",
      "521/521 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9426 - val_loss: 0.1372 - val_accuracy: 0.9466\n",
      "521/521 - 0s - loss: 0.1237 - accuracy: 0.9517 - 485ms/epoch - 931us/step\n",
      "130/130 [==============================] - 0s 690us/step\n",
      "Epoch 1/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.7756 - accuracy: 0.8044 - val_loss: 0.3477 - val_accuracy: 0.8257\n",
      "Epoch 2/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.5184 - accuracy: 0.8538 - val_loss: 0.2808 - val_accuracy: 0.8707\n",
      "Epoch 3/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4616 - accuracy: 0.8768 - val_loss: 0.2363 - val_accuracy: 0.9022\n",
      "Epoch 4/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4336 - accuracy: 0.8846 - val_loss: 0.2851 - val_accuracy: 0.8820\n",
      "Epoch 5/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4128 - accuracy: 0.8909 - val_loss: 0.2149 - val_accuracy: 0.9219\n",
      "Epoch 6/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.4007 - accuracy: 0.8945 - val_loss: 0.2251 - val_accuracy: 0.9125\n",
      "Epoch 7/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3933 - accuracy: 0.8977 - val_loss: 0.2270 - val_accuracy: 0.9094\n",
      "Epoch 8/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3801 - accuracy: 0.8994 - val_loss: 0.2505 - val_accuracy: 0.9036\n",
      "Epoch 9/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3800 - accuracy: 0.8991 - val_loss: 0.2363 - val_accuracy: 0.9041\n",
      "Epoch 10/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3721 - accuracy: 0.9028 - val_loss: 0.2562 - val_accuracy: 0.8964\n",
      "Epoch 11/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3678 - accuracy: 0.9029 - val_loss: 0.2232 - val_accuracy: 0.9079\n",
      "Epoch 12/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3634 - accuracy: 0.9042 - val_loss: 0.2868 - val_accuracy: 0.8851\n",
      "Epoch 13/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3584 - accuracy: 0.9049 - val_loss: 0.1988 - val_accuracy: 0.9250\n",
      "Epoch 14/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3535 - accuracy: 0.9074 - val_loss: 0.1895 - val_accuracy: 0.9281\n",
      "Epoch 15/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3486 - accuracy: 0.9072 - val_loss: 0.2353 - val_accuracy: 0.9082\n",
      "Epoch 16/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3476 - accuracy: 0.9069 - val_loss: 0.2419 - val_accuracy: 0.9072\n",
      "Epoch 17/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.9082 - val_loss: 0.2107 - val_accuracy: 0.9197\n",
      "Epoch 18/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3403 - accuracy: 0.9085 - val_loss: 0.2399 - val_accuracy: 0.9029\n",
      "Epoch 19/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3391 - accuracy: 0.9090 - val_loss: 0.2024 - val_accuracy: 0.9187\n",
      "Epoch 20/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3289 - accuracy: 0.9115 - val_loss: 0.2205 - val_accuracy: 0.9113\n",
      "Epoch 21/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3319 - accuracy: 0.9113 - val_loss: 0.1873 - val_accuracy: 0.9276\n",
      "Epoch 22/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3321 - accuracy: 0.9098 - val_loss: 0.1871 - val_accuracy: 0.9250\n",
      "Epoch 23/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3217 - accuracy: 0.9126 - val_loss: 0.1976 - val_accuracy: 0.9180\n",
      "Epoch 24/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3268 - accuracy: 0.9125 - val_loss: 0.2017 - val_accuracy: 0.9200\n",
      "Epoch 25/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3220 - accuracy: 0.9122 - val_loss: 0.2108 - val_accuracy: 0.9149\n",
      "Epoch 26/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3193 - accuracy: 0.9125 - val_loss: 0.2002 - val_accuracy: 0.9187\n",
      "Epoch 27/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3166 - accuracy: 0.9140 - val_loss: 0.2119 - val_accuracy: 0.9166\n",
      "Epoch 28/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3136 - accuracy: 0.9136 - val_loss: 0.1661 - val_accuracy: 0.9358\n",
      "Epoch 29/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3129 - accuracy: 0.9152 - val_loss: 0.2044 - val_accuracy: 0.9144\n",
      "Epoch 30/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3077 - accuracy: 0.9155 - val_loss: 0.1834 - val_accuracy: 0.9281\n",
      "Epoch 31/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3040 - accuracy: 0.9175 - val_loss: 0.2574 - val_accuracy: 0.8995\n",
      "Epoch 32/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3077 - accuracy: 0.9164 - val_loss: 0.1960 - val_accuracy: 0.9233\n",
      "Epoch 33/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2975 - accuracy: 0.9200 - val_loss: 0.2024 - val_accuracy: 0.9168\n",
      "Epoch 34/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2991 - accuracy: 0.9180 - val_loss: 0.2403 - val_accuracy: 0.9060\n",
      "Epoch 35/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.3009 - accuracy: 0.9181 - val_loss: 0.2303 - val_accuracy: 0.9055\n",
      "Epoch 36/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2928 - accuracy: 0.9195 - val_loss: 0.1775 - val_accuracy: 0.9274\n",
      "Epoch 37/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2938 - accuracy: 0.9206 - val_loss: 0.1873 - val_accuracy: 0.9255\n",
      "Epoch 38/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2845 - accuracy: 0.9209 - val_loss: 0.1659 - val_accuracy: 0.9344\n",
      "Epoch 39/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2863 - accuracy: 0.9221 - val_loss: 0.1828 - val_accuracy: 0.9257\n",
      "Epoch 40/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2859 - accuracy: 0.9225 - val_loss: 0.1704 - val_accuracy: 0.9349\n",
      "Epoch 41/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2771 - accuracy: 0.9231 - val_loss: 0.1520 - val_accuracy: 0.9406\n",
      "Epoch 42/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2858 - accuracy: 0.9218 - val_loss: 0.1798 - val_accuracy: 0.9274\n",
      "Epoch 43/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2781 - accuracy: 0.9248 - val_loss: 0.1802 - val_accuracy: 0.9269\n",
      "Epoch 44/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2752 - accuracy: 0.9243 - val_loss: 0.1833 - val_accuracy: 0.9233\n",
      "Epoch 45/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2715 - accuracy: 0.9269 - val_loss: 0.2344 - val_accuracy: 0.9046\n",
      "Epoch 46/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2725 - accuracy: 0.9248 - val_loss: 0.1615 - val_accuracy: 0.9385\n",
      "Epoch 47/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2729 - accuracy: 0.9258 - val_loss: 0.1616 - val_accuracy: 0.9339\n",
      "Epoch 48/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2682 - accuracy: 0.9283 - val_loss: 0.1608 - val_accuracy: 0.9351\n",
      "Epoch 49/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2664 - accuracy: 0.9277 - val_loss: 0.1830 - val_accuracy: 0.9305\n",
      "Epoch 50/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2686 - accuracy: 0.9259 - val_loss: 0.1820 - val_accuracy: 0.9281\n",
      "Epoch 51/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2634 - accuracy: 0.9285 - val_loss: 0.1527 - val_accuracy: 0.9385\n",
      "Epoch 52/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2576 - accuracy: 0.9301 - val_loss: 0.2017 - val_accuracy: 0.9200\n",
      "Epoch 53/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2624 - accuracy: 0.9303 - val_loss: 0.2413 - val_accuracy: 0.9048\n",
      "Epoch 54/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2559 - accuracy: 0.9302 - val_loss: 0.1816 - val_accuracy: 0.9279\n",
      "Epoch 55/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2508 - accuracy: 0.9311 - val_loss: 0.1519 - val_accuracy: 0.9397\n",
      "Epoch 56/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2563 - accuracy: 0.9307 - val_loss: 0.1620 - val_accuracy: 0.9339\n",
      "Epoch 57/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2534 - accuracy: 0.9293 - val_loss: 0.2100 - val_accuracy: 0.9137\n",
      "Epoch 58/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2415 - accuracy: 0.9334 - val_loss: 0.1626 - val_accuracy: 0.9356\n",
      "Epoch 59/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2464 - accuracy: 0.9331 - val_loss: 0.1637 - val_accuracy: 0.9365\n",
      "Epoch 60/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.9336 - val_loss: 0.1887 - val_accuracy: 0.9240\n",
      "Epoch 61/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2428 - accuracy: 0.9350 - val_loss: 0.1702 - val_accuracy: 0.9332\n",
      "Epoch 62/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2424 - accuracy: 0.9355 - val_loss: 0.2168 - val_accuracy: 0.9154\n",
      "Epoch 63/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.9340 - val_loss: 0.2005 - val_accuracy: 0.9248\n",
      "Epoch 64/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2346 - accuracy: 0.9381 - val_loss: 0.1803 - val_accuracy: 0.9303\n",
      "Epoch 65/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2357 - accuracy: 0.9367 - val_loss: 0.1493 - val_accuracy: 0.9397\n",
      "Epoch 66/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2305 - accuracy: 0.9370 - val_loss: 0.1467 - val_accuracy: 0.9440\n",
      "Epoch 67/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2328 - accuracy: 0.9368 - val_loss: 0.2140 - val_accuracy: 0.9180\n",
      "Epoch 68/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2344 - accuracy: 0.9361 - val_loss: 0.1579 - val_accuracy: 0.9413\n",
      "Epoch 69/1000\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2343 - accuracy: 0.9377 - val_loss: 0.1664 - val_accuracy: 0.9327\n",
      "521/521 - 0s - loss: 0.1529 - accuracy: 0.9380 - 465ms/epoch - 893us/step\n",
      "130/130 [==============================] - 0s 721us/step\n",
      "Mean accuracy: 0.9411476016044616\n",
      "Mean F1 score: 0.9397228336939119\n",
      "Mean precision: 0.8902158973861791\n",
      "Mean recall: 0.9953697488048698\n"
     ]
    }
   ],
   "source": [
    "# KFold를 통해 모델 성능을 평가해보기.\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recalls = []\n",
    "accs = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_resampled):\n",
    "    X_train_fold, X_val_fold = X_train_resampled[train_index], X_train_resampled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_resampled[train_index], y_train_resampled[val_index]\n",
    "    \n",
    "    # 모델 생성 및 학습\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Early stopping 기능 추가\n",
    "    early_stopping = EarlyStopping(patience=5, monitor='accuracy')\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=1000, batch_size=32, class_weight=class_weight, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping])\n",
    "    \n",
    "    loss, acc = model.evaluate(X_train_fold, y_train_fold, verbose = 2)\n",
    "\n",
    "    accs.append(acc)\n",
    "    \n",
    "    # 검증 데이터에 대한 예측 수행\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "    y_pred = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "    \n",
    "    # f1 score와 precision 계산\n",
    "    f1_scores.append(f1_score(y_val_fold, y_pred))\n",
    "    recalls.append(recall_score(y_val_fold, y_pred))\n",
    "    precision_scores.append(precision_score(y_val_fold, y_pred))\n",
    "    \n",
    "# 교차 검증 결과 출력\n",
    "print('Mean accuracy:', np.mean(accs))\n",
    "print('Mean F1 score:', np.mean(f1_scores))\n",
    "print('Mean precision:', np.mean(precision_scores))\n",
    "print(\"Mean recall:\", np.mean(recalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
