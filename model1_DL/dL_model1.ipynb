{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcoYVTDsg9h9"
      },
      "source": [
        "### 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADSKsE0Yg9h_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHNc_861g9iA"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Regression_data_preprocessing.csv')\n",
        "target = 'Rings'\n",
        "y = df[target]\n",
        "x = df.drop(target, axis =1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoKu3_A0g9iA"
      },
      "source": [
        "### 1. 배치 정규화 - 사용 X\n",
        "배치 정규화는 일반적으로 분류(classification) 문제에서 성능 향상에 더 많이 사용됩니다. 이는 배치 정규화가 입력 데이터의 분포를 정규화하고, 이를 통해 다음 층으로 전달되는 값을 안정화시키기 때문입니다.\n",
        "\n",
        "### 2. Dropout - 성능에 따라 사용\n",
        "드롭아웃은 분류(classification) 문제에서 주로 사용되는 정규화 방법이지만, 회귀(regression) 문제에서도 일부 경우에 사용될 수 있습니다. 회귀 모델에서 드롭아웃을 사용하면, 모델이 특정 입력값에 과도하게 의존하는 것을 방지하여 일반화 성능을 향상시킬 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jBTreNlg9iA"
      },
      "source": [
        "### 활성화 함수\n",
        "1. Relu:\n",
        " 입력층(input layer)과 은닉층(hidden layer)에서는 일반적으로 ReLU(Rectified Linear Unit) 활성화 함수가 많이 사용됩니다. ReLU 함수는 계산이 간단하고, 학습 속도가 빠르며, 특정 입력값에 대해 미분 가능하기 때문에, 딥러닝 모델에서 가장 많이 사용되는 활성화 함수 중 하나입니다.\n",
        "\n",
        "2. tanh:\n",
        " 입력값의 범위가 -1에서 1 사이인 경우에는 하이퍼볼릭 탄젠트(tanh) 함수를 사용하는 것이 좋습니다. 이는 입력값이 크거나 작을 때 출력값이 포화되는 문제를 해결할 수 있기 때문입니다. 따라서 입력값의 범위에 따라 적절한 활성화 함수를 선택하는 것이 좋습니다.\n",
        "\n",
        "3. sigmoid:\n",
        " 입력값을 0과 1 사이의 값으로 변환하는 함수로, 이진 분류(binary classification) 문제에서 출력층의 활성화 함수로 많이 사용됩니다. 하지만 회귀(regression) 문제에서는 선형 모델과 달리 출력값이 제한되지 않아야 하므로, sigmoid 함수를 활성화 함수로 사용하는 것은 적합하지 않습니다.\n",
        "\n",
        " 4. linear:\n",
        " 회귀 문제에서는 출력층의 활성화 함수로 linear 함수를 사용하는 것이 적합합니다. linear 함수는 입력값과 동일한 값을 출력하므로, 출력값의 범위가 제한되지 않습니다. 따라서 linear 함수를 사용하면 모델이 임의의 값을 예측할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cXmd0Epg9iA",
        "outputId": "042bda35-9418-40dc-a1ca-6eb3312061d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\n",
            "[안내] 데이터 표준화를 진행했습니다.\n",
            "[안내] 검증 데이터를 추가로 분리했습니다.\n"
          ]
        }
      ],
      "source": [
        "# 유저로 부터 입력을 받아 검증 데이터 셋을 사용할 것인지, 표준화를 사용할 것인지 정함.\n",
        "print(\"[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\")\n",
        "input_1 = input(\"[안내] 데이터를 표준화 하시겠습니까? : \")\n",
        "input_2 = input(\"[안내] 검증 데이터셋을 분리할까요? : \")\n",
        "\n",
        "# 표준화 진행 여부\n",
        "if input_1 == 'y':\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(x)\n",
        "    print(\"[안내] 데이터 표준화를 진행했습니다.\")\n",
        "else:\n",
        "    X = x\n",
        "    print(\"[안내] 데이터 표준화를 진행하지 않습니다.\")\n",
        "\n",
        "# 검증 데이터 진행 여부\n",
        "if input_2 == 'y':\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "    print(\"[안내] 검증 데이터를 추가로 분리했습니다.\")\n",
        "\n",
        "else:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    print(\"[안내] 검증 데이터를 분리하지 않았습니다.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc7QlPUPg9iB"
      },
      "source": [
        "### 모델 구현\n",
        "\n",
        "1. SGD (Stochastic Gradient Descent):\n",
        "가장 기본적인 옵티마이저로, 경사 하강법의 확률적인 버전입니다.\n",
        "각 학습 단계에서 미니 배치(mini-batch) 단위로 데이터를 사용하여 가중치를 업데이트합니다.\n",
        "단순하고 직관적인 방법이지만, 수렴 속도가 느리고 지역 최소값(local minimum)에 빠질 가능성이 있습니다.\n",
        "\n",
        "2. Adam (Adaptive Moment Estimation):\n",
        "학습률(learning rate)을 조정하는 방법을 통해 경사 하강법을 개선한 알고리즘입니다.\n",
        "학습 속도를 개선하기 위해 모멘텀(Momentum)과 학습률 스케줄링(learning rate scheduling)을 조합합니다.\n",
        "이동 평균(moving average)을 사용하여 각 가중치의 업데이트 속도를 조절하며, 자동으로 적응적인 학습률을 제공합니다.\n",
        "다양한 유형의 신경망 구조와 데이터에 대해 일반적으로 좋은 성능을 보입니다.\n",
        "\n",
        "3. RMSProp (Root Mean Square Propagation):\n",
        "과거 그래디언트(gradient)의 제곱을 이동 평균하여 학습률을 조정하는 알고리즘입니다.\n",
        "최근 그래디언트에 더 큰 가중치를 부여하여 중요한 그래디언트를 잘 반영합니다.\n",
        "이동 평균을 사용하여 각 가중치의 업데이트 속도를 조절하며, 최적의 학습률을 자동으로 조정합니다.\n",
        "비교적 안정적인 학습을 제공하고, RNN(Recurrent Neural Network)과 같은 모델에서 잘 작동하는 경향이 있습니다.\n",
        "\n",
        "### 정확도 \n",
        "- custom metric 사용 : 절대 비율 오차 (baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtqLXhqig9iC"
      },
      "outputs": [],
      "source": [
        "# method_custom_metric 구현\n",
        "def accuracy(y_true, y_pred):\n",
        "    return 1 - tf.abs((y_true - y_pred) / y_true) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeH1LuxHg9iC"
      },
      "outputs": [],
      "source": [
        "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용)\n",
        "act_func = ['relu', 'tanh']\n",
        "batch_lst = [8, 16, 32, 64, 128]\n",
        "opt_lst = ['adam', 'rmsprop', 'sgd']\n",
        "best_accuracy = 0.0\n",
        "best_hyperparams = {}\n",
        "\n",
        "for func in act_func:\n",
        "    for batch in batch_lst:\n",
        "        for opti in opt_lst:\n",
        "            # 모델 구현\n",
        "            model = Sequential()\n",
        "            model.add(Dense(64, activation=func, input_dim=x.shape[1]))\n",
        "            model.add(Dropout(0.1))  # Dropout 추가\n",
        "            model.add(Dense(32, activation=func))\n",
        "            model.add(Dropout(0.1))  # Dropout 추가               \n",
        "            model.add(Dense(16, activation=func))\n",
        "            model.add(Dropout(0.1))  # Dropout 추가\n",
        "            model.add(Dense(8, activation=func))\n",
        "            model.add(Dropout(0.1))  # Dropout 추가\n",
        "            model.add(Dense(4, activation=func))\n",
        "            model.add(Dropout(0.1))  # Dropout 추가\n",
        "            model.add(Dense(1, activation='linear'))\n",
        "\n",
        "            # 모델 컴파일\n",
        "            model.compile(loss='mse', optimizer=opti, metrics=[accuracy])\n",
        "\n",
        "            # early stopping 구현 - 커스텀 정확도 기준\n",
        "            early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
        "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
        "\n",
        "            if acc > best_accuracy:\n",
        "                best_accuracy = acc\n",
        "                best_hyperparams = {'activation': func, 'batch_size': batch, 'optimizer': opti}\n",
        "\n",
        "print('Best hyperparameters:', best_hyperparams)\n",
        "print('Best validation accuracy:', best_accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJBpUwJIg9iC"
      },
      "outputs": [],
      "source": [
        "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용X)\n",
        "act_func = ['relu', 'tanh']\n",
        "batch_lst = [8, 16, 32, 64, 128]\n",
        "opt_lst = ['adam', 'rmsprop', 'sgd']\n",
        "best_accuracy = 0.0\n",
        "best_hyperparams = {}\n",
        "\n",
        "for func in act_func:\n",
        "    for batch in batch_lst:\n",
        "        for opti in opt_lst:\n",
        "            # 모델 구현\n",
        "            model = Sequential()\n",
        "            model.add(Dense(64, activation=func, input_dim=x.shape[1]))\n",
        "            model.add(Dense(32, activation=func))              \n",
        "            model.add(Dense(16, activation=func))\n",
        "            model.add(Dense(8, activation=func))\n",
        "            model.add(Dense(4, activation=func))\n",
        "            model.add(Dense(1, activation='linear'))\n",
        "\n",
        "            # 모델 컴파일\n",
        "            model.compile(loss='mse', optimizer=opti, metrics=[accuracy])\n",
        "\n",
        "            # early stopping 구현 - 커스텀 정확도 기준\n",
        "            early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
        "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
        "\n",
        "            if acc > best_accuracy:\n",
        "                best_accuracy = acc\n",
        "                best_hyperparams = {'activation': func, 'batch_size': batch, 'optimizer': opti, 'dropout': 'no'}\n",
        "\n",
        "print('Best hyperparameters:', best_hyperparams)\n",
        "print('Best validation accuracy:', best_accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne04G9UKg9iC"
      },
      "source": [
        "### BEST MODEL\n",
        "1. early stopping을 통해 정확도가 높은 모델 선정\n",
        "\n",
        "2. 검증 데이터를 통해 검증 정확도가 높은 모델 선정 - 과적합 방지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFtO5qftg9iD",
        "outputId": "6ea67a52-b3be-492a-bf49-c12e1d989788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'activation': 'tanh', 'batch_size': 32, 'optimizer': 'sgd', 'dropout': 'no'}\n",
            "Best accuracy: 0.8571187257766724\n"
          ]
        }
      ],
      "source": [
        "print('Best hyperparameters:', best_hyperparams)\n",
        "print('Best accuracy:', best_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhkoYDP6g9iD",
        "outputId": "bd5cac3b-ad5b-4dfb-a86c-1dea698a1341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[안내] 모델이 실행됩니다.\n",
            "Epoch 1/1000\n",
            "84/84 [==============================] - 1s 4ms/step - loss: 13.5313 - accuracy: 0.7575 - val_loss: 7.3383 - val_accuracy: 0.7576\n",
            "Epoch 2/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.2903 - accuracy: 0.8226 - val_loss: 6.3149 - val_accuracy: 0.8223\n",
            "Epoch 3/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 5.4810 - accuracy: 0.8344 - val_loss: 4.9085 - val_accuracy: 0.8352\n",
            "Epoch 4/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 5.2057 - accuracy: 0.8381 - val_loss: 5.2294 - val_accuracy: 0.8051\n",
            "Epoch 5/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 5.0363 - accuracy: 0.8402 - val_loss: 4.5126 - val_accuracy: 0.8513\n",
            "Epoch 6/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.8435 - accuracy: 0.8448 - val_loss: 4.9233 - val_accuracy: 0.8417\n",
            "Epoch 7/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.7926 - accuracy: 0.8445 - val_loss: 4.6663 - val_accuracy: 0.8236\n",
            "Epoch 8/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.6748 - accuracy: 0.8466 - val_loss: 4.4445 - val_accuracy: 0.8392\n",
            "Epoch 9/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.7245 - accuracy: 0.8458 - val_loss: 4.4625 - val_accuracy: 0.8362\n",
            "Epoch 10/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.6081 - accuracy: 0.8463 - val_loss: 4.4224 - val_accuracy: 0.8580\n",
            "Epoch 11/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.6589 - accuracy: 0.8471 - val_loss: 4.3952 - val_accuracy: 0.8426\n",
            "Epoch 12/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 4.5481 - accuracy: 0.8503 - val_loss: 4.2798 - val_accuracy: 0.8556\n",
            "Epoch 13/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.5250 - accuracy: 0.8479 - val_loss: 4.7666 - val_accuracy: 0.8437\n",
            "Epoch 14/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.6017 - accuracy: 0.8468 - val_loss: 4.4020 - val_accuracy: 0.8478\n",
            "Epoch 15/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.4885 - accuracy: 0.8475 - val_loss: 5.6330 - val_accuracy: 0.8288\n",
            "Epoch 16/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.5399 - accuracy: 0.8475 - val_loss: 4.5743 - val_accuracy: 0.8357\n",
            "Epoch 17/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.4681 - accuracy: 0.8514 - val_loss: 4.3446 - val_accuracy: 0.8550\n",
            "Epoch 18/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.4849 - accuracy: 0.8515 - val_loss: 4.3708 - val_accuracy: 0.8484\n",
            "Epoch 19/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.3935 - accuracy: 0.8522 - val_loss: 4.2507 - val_accuracy: 0.8546\n",
            "Epoch 20/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.4843 - accuracy: 0.8490 - val_loss: 4.1961 - val_accuracy: 0.8462\n",
            "Epoch 21/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.3963 - accuracy: 0.8500 - val_loss: 4.2363 - val_accuracy: 0.8493\n",
            "Epoch 22/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.3189 - accuracy: 0.8518 - val_loss: 4.7057 - val_accuracy: 0.8297\n",
            "Epoch 23/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.3220 - accuracy: 0.8514 - val_loss: 4.2688 - val_accuracy: 0.8462\n",
            "Epoch 24/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.3753 - accuracy: 0.8517 - val_loss: 4.3364 - val_accuracy: 0.8436\n",
            "131/131 [==============================] - 0s 1ms/step\n",
            "[안내] 최종 모델\n",
            "[안내] train loss, accuracy\n",
            "84/84 - 0s - loss: 4.1426 - accuracy: 0.8550 - 122ms/epoch - 1ms/step\n",
            "[안내] validation loss, accuracy\n",
            "21/21 - 0s - loss: 4.3364 - accuracy: 0.8436 - 45ms/epoch - 2ms/step\n",
            "[안내] 실행 시간 : 6.070 seconds\n",
            "[안내] 샘플 10개의 결과\n",
            "      Rings       pred\n",
            "1437      6   6.981085\n",
            "728      13  12.539680\n",
            "3470     11  12.399845\n",
            "2856     11   9.402239\n",
            "1178      9  11.320084\n",
            "1061      6   5.034081\n",
            "2467     16  11.640235\n",
            "2486     13  14.279268\n",
            "3289     15  11.623315\n",
            "850      10  11.831802\n"
          ]
        }
      ],
      "source": [
        "# 최고 모델 사용자 친화적 구현\n",
        "start_time = time.time()\n",
        "print(\"[안내] 모델이 실행됩니다.\")\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='tanh', input_dim=x.shape[1]))\n",
        "model.add(Dense(32, activation='tanh'))\n",
        "model.add(Dense(16, activation='tanh'))\n",
        "model.add(Dense(8, activation='tanh'))\n",
        "model.add(Dense(4, activation='tanh'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(loss='mse', optimizer='sgd', metrics=[accuracy])\n",
        "early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
        "\n",
        "if input_2 == 'y':\n",
        "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "    y_pred = model.predict(X)\n",
        "else:\n",
        "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "print(\"[안내] 최종 모델\")\n",
        "if input_2 == 'y':\n",
        "    print(\"[안내] train loss, accuracy\")\n",
        "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
        "    print(\"[안내] validation loss, accuracy\")\n",
        "    loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
        "else:\n",
        "    print(\"[안내] train loss, accuracy\")\n",
        "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
        "    print(\"[안내] test loss, accuracy\")\n",
        "    loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "execution_time = end_time - start_time\n",
        "print(\"[안내] 실행 시간 : {:.3f} seconds\".format(execution_time))\n",
        "\n",
        "input_3 = input(\"[안내] 예측 샘플을 확인할까요? : \")\n",
        "if input_3 == 'y':\n",
        "    print(\"[안내] 샘플 10개의 결과\")\n",
        "    new_y = y\n",
        "    stacked_array = np.vstack((y_pred))\n",
        "    new_df = pd.DataFrame(stacked_array)\n",
        "    new_y = pd.DataFrame(new_y)\n",
        "    new_y['pred'] = new_df[0]\n",
        "    print(new_y.sample(10))\n",
        "else:\n",
        "    print(\"[안내] 실행을 종료합니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5p30vCDg9iD"
      },
      "source": [
        "### Best Model Advanced\n",
        "실행 샘플 데이터 - 분포가 많은 값으로 예측한 것으로 추측\n",
        "-> dropout 을 사용한 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1pF8ncRg9iD",
        "outputId": "6b0202ca-0ae5-430d-a5f6-973386450ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[안내] 모델이 실행됩니다.\n",
            "Epoch 1/1000\n",
            "84/84 [==============================] - 2s 4ms/step - loss: 39.9279 - accuracy: 0.4857 - val_loss: 8.6186 - val_accuracy: 0.8031\n",
            "Epoch 2/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 20.1747 - accuracy: 0.6566 - val_loss: 6.0916 - val_accuracy: 0.8434\n",
            "Epoch 3/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 17.6490 - accuracy: 0.6749 - val_loss: 6.9548 - val_accuracy: 0.8296\n",
            "Epoch 4/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 16.1590 - accuracy: 0.6954 - val_loss: 6.1991 - val_accuracy: 0.8353\n",
            "Epoch 5/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 14.0945 - accuracy: 0.7142 - val_loss: 5.5175 - val_accuracy: 0.8501\n",
            "Epoch 6/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 13.4944 - accuracy: 0.7231 - val_loss: 5.3725 - val_accuracy: 0.8489\n",
            "Epoch 7/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 13.3775 - accuracy: 0.7276 - val_loss: 4.9858 - val_accuracy: 0.8444\n",
            "Epoch 8/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 12.6834 - accuracy: 0.7342 - val_loss: 5.4584 - val_accuracy: 0.8511\n",
            "Epoch 9/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 11.5178 - accuracy: 0.7424 - val_loss: 5.7562 - val_accuracy: 0.8473\n",
            "Epoch 10/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 11.4888 - accuracy: 0.7435 - val_loss: 5.5588 - val_accuracy: 0.8508\n",
            "Epoch 11/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 10.5177 - accuracy: 0.7576 - val_loss: 4.8759 - val_accuracy: 0.8488\n",
            "Epoch 12/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 10.1149 - accuracy: 0.7544 - val_loss: 4.8450 - val_accuracy: 0.8576\n",
            "Epoch 13/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 10.8062 - accuracy: 0.7565 - val_loss: 4.4886 - val_accuracy: 0.8519\n",
            "Epoch 14/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 10.0953 - accuracy: 0.7615 - val_loss: 4.5862 - val_accuracy: 0.8542\n",
            "Epoch 15/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 10.3795 - accuracy: 0.7593 - val_loss: 5.2512 - val_accuracy: 0.8560\n",
            "Epoch 16/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 9.4866 - accuracy: 0.7667 - val_loss: 4.8480 - val_accuracy: 0.8583\n",
            "Epoch 17/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 9.7910 - accuracy: 0.7643 - val_loss: 4.4812 - val_accuracy: 0.8543\n",
            "Epoch 18/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 9.5229 - accuracy: 0.7696 - val_loss: 4.8556 - val_accuracy: 0.8571\n",
            "Epoch 19/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 9.7444 - accuracy: 0.7647 - val_loss: 4.6316 - val_accuracy: 0.8570\n",
            "Epoch 20/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 9.4380 - accuracy: 0.7761 - val_loss: 4.6377 - val_accuracy: 0.8544\n",
            "Epoch 21/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 10.0565 - accuracy: 0.7705 - val_loss: 4.5018 - val_accuracy: 0.8510\n",
            "Epoch 22/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 9.0488 - accuracy: 0.7778 - val_loss: 4.5816 - val_accuracy: 0.8517\n",
            "Epoch 23/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.8714 - accuracy: 0.7757 - val_loss: 4.6215 - val_accuracy: 0.8584\n",
            "Epoch 24/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 9.1445 - accuracy: 0.7747 - val_loss: 5.2088 - val_accuracy: 0.8516\n",
            "Epoch 25/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 9.2436 - accuracy: 0.7786 - val_loss: 4.4895 - val_accuracy: 0.8555\n",
            "Epoch 26/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 9.2391 - accuracy: 0.7768 - val_loss: 4.8947 - val_accuracy: 0.8556\n",
            "Epoch 27/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 9.1836 - accuracy: 0.7784 - val_loss: 4.8641 - val_accuracy: 0.8545\n",
            "Epoch 28/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 9.0100 - accuracy: 0.7786 - val_loss: 4.7892 - val_accuracy: 0.8539\n",
            "Epoch 29/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.4178 - accuracy: 0.7806 - val_loss: 4.8472 - val_accuracy: 0.8517\n",
            "Epoch 30/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.7472 - accuracy: 0.7787 - val_loss: 4.7063 - val_accuracy: 0.8546\n",
            "Epoch 31/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.5463 - accuracy: 0.7822 - val_loss: 4.4561 - val_accuracy: 0.8577\n",
            "Epoch 32/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.8055 - accuracy: 0.7808 - val_loss: 4.4568 - val_accuracy: 0.8535\n",
            "Epoch 33/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.6386 - accuracy: 0.7822 - val_loss: 4.5633 - val_accuracy: 0.8575\n",
            "Epoch 34/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.4872 - accuracy: 0.7836 - val_loss: 4.4552 - val_accuracy: 0.8575\n",
            "Epoch 35/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.2146 - accuracy: 0.7859 - val_loss: 4.6959 - val_accuracy: 0.8585\n",
            "Epoch 36/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.7069 - accuracy: 0.7855 - val_loss: 4.6098 - val_accuracy: 0.8571\n",
            "Epoch 37/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.4483 - accuracy: 0.7877 - val_loss: 4.5887 - val_accuracy: 0.8533\n",
            "Epoch 38/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.3307 - accuracy: 0.7882 - val_loss: 4.4735 - val_accuracy: 0.8562\n",
            "Epoch 39/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.0840 - accuracy: 0.7926 - val_loss: 4.4850 - val_accuracy: 0.8541\n",
            "Epoch 40/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.9249 - accuracy: 0.7928 - val_loss: 4.4458 - val_accuracy: 0.8505\n",
            "Epoch 41/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.8769 - accuracy: 0.7918 - val_loss: 4.5169 - val_accuracy: 0.8540\n",
            "Epoch 42/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.0534 - accuracy: 0.7890 - val_loss: 4.8471 - val_accuracy: 0.8563\n",
            "Epoch 43/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.9671 - accuracy: 0.7933 - val_loss: 4.5205 - val_accuracy: 0.8532\n",
            "Epoch 44/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.6005 - accuracy: 0.7944 - val_loss: 4.8622 - val_accuracy: 0.8571\n",
            "Epoch 45/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.0278 - accuracy: 0.7931 - val_loss: 4.5445 - val_accuracy: 0.8558\n",
            "Epoch 46/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.6723 - accuracy: 0.7959 - val_loss: 4.6080 - val_accuracy: 0.8549\n",
            "Epoch 47/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.7742 - accuracy: 0.7964 - val_loss: 4.4834 - val_accuracy: 0.8537\n",
            "Epoch 48/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.9700 - accuracy: 0.7929 - val_loss: 4.4830 - val_accuracy: 0.8559\n",
            "Epoch 49/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.6440 - accuracy: 0.7956 - val_loss: 4.4421 - val_accuracy: 0.8549\n",
            "Epoch 50/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.1991 - accuracy: 0.7998 - val_loss: 4.4663 - val_accuracy: 0.8458\n",
            "Epoch 51/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 8.1652 - accuracy: 0.7936 - val_loss: 4.3798 - val_accuracy: 0.8534\n",
            "Epoch 52/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 7.3027 - accuracy: 0.8017 - val_loss: 4.6045 - val_accuracy: 0.8554\n",
            "Epoch 53/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 7.2316 - accuracy: 0.8006 - val_loss: 4.4725 - val_accuracy: 0.8542\n",
            "Epoch 54/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.6984 - accuracy: 0.7982 - val_loss: 4.5271 - val_accuracy: 0.8526\n",
            "Epoch 55/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.1169 - accuracy: 0.8036 - val_loss: 4.4601 - val_accuracy: 0.8561\n",
            "Epoch 56/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.1679 - accuracy: 0.8049 - val_loss: 4.3654 - val_accuracy: 0.8538\n",
            "Epoch 57/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.3688 - accuracy: 0.8014 - val_loss: 4.4303 - val_accuracy: 0.8514\n",
            "Epoch 58/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.0960 - accuracy: 0.8039 - val_loss: 4.6401 - val_accuracy: 0.8549\n",
            "Epoch 59/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.0917 - accuracy: 0.8002 - val_loss: 4.5175 - val_accuracy: 0.8543\n",
            "Epoch 60/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.7652 - accuracy: 0.8070 - val_loss: 4.5803 - val_accuracy: 0.8569\n",
            "Epoch 61/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.4458 - accuracy: 0.8012 - val_loss: 4.5434 - val_accuracy: 0.8565\n",
            "Epoch 62/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.9221 - accuracy: 0.8064 - val_loss: 4.4815 - val_accuracy: 0.8475\n",
            "Epoch 63/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.8650 - accuracy: 0.8089 - val_loss: 4.3782 - val_accuracy: 0.8531\n",
            "Epoch 64/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.3848 - accuracy: 0.8033 - val_loss: 4.4291 - val_accuracy: 0.8535\n",
            "Epoch 65/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.0464 - accuracy: 0.8053 - val_loss: 4.5372 - val_accuracy: 0.8565\n",
            "Epoch 66/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.8615 - accuracy: 0.8106 - val_loss: 4.3668 - val_accuracy: 0.8531\n",
            "Epoch 67/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.0829 - accuracy: 0.8084 - val_loss: 4.4676 - val_accuracy: 0.8526\n",
            "Epoch 68/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.6813 - accuracy: 0.8088 - val_loss: 4.7473 - val_accuracy: 0.8551\n",
            "Epoch 69/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.6875 - accuracy: 0.8090 - val_loss: 4.5200 - val_accuracy: 0.8555\n",
            "Epoch 70/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.6861 - accuracy: 0.8131 - val_loss: 4.5730 - val_accuracy: 0.8558\n",
            "Epoch 71/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 6.5822 - accuracy: 0.8127 - val_loss: 4.5358 - val_accuracy: 0.8564\n",
            "Epoch 72/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 6.6742 - accuracy: 0.8112 - val_loss: 4.3864 - val_accuracy: 0.8448\n",
            "Epoch 73/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.4608 - accuracy: 0.8136 - val_loss: 4.3269 - val_accuracy: 0.8526\n",
            "Epoch 74/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.7052 - accuracy: 0.8097 - val_loss: 4.4375 - val_accuracy: 0.8445\n",
            "Epoch 75/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.6639 - accuracy: 0.8121 - val_loss: 4.5474 - val_accuracy: 0.8523\n",
            "Epoch 76/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 7.0832 - accuracy: 0.8084 - val_loss: 4.3439 - val_accuracy: 0.8498\n",
            "Epoch 77/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.4022 - accuracy: 0.8141 - val_loss: 4.2696 - val_accuracy: 0.8559\n",
            "Epoch 78/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.4580 - accuracy: 0.8113 - val_loss: 4.4619 - val_accuracy: 0.8530\n",
            "Epoch 79/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.3734 - accuracy: 0.8165 - val_loss: 4.3176 - val_accuracy: 0.8486\n",
            "Epoch 80/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 6.0675 - accuracy: 0.8202 - val_loss: 4.2993 - val_accuracy: 0.8508\n",
            "Epoch 81/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 6.4367 - accuracy: 0.8158 - val_loss: 4.3873 - val_accuracy: 0.8460\n",
            "Epoch 82/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 6.1866 - accuracy: 0.8192 - val_loss: 4.3710 - val_accuracy: 0.8517\n",
            "Epoch 83/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 6.7897 - accuracy: 0.8113 - val_loss: 4.5201 - val_accuracy: 0.8511\n",
            "Epoch 84/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 6.0256 - accuracy: 0.8175 - val_loss: 4.3808 - val_accuracy: 0.8478\n",
            "Epoch 85/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 6.3108 - accuracy: 0.8174 - val_loss: 4.3463 - val_accuracy: 0.8468\n",
            "131/131 [==============================] - 0s 1ms/step\n",
            "[안내] 최종 모델\n",
            "[안내] train loss, accuracy\n",
            "84/84 - 0s - loss: 3.7997 - accuracy: 0.8607 - 125ms/epoch - 1ms/step\n",
            "[안내] validation loss, accuracy\n",
            "21/21 - 0s - loss: 4.3463 - accuracy: 0.8468 - 52ms/epoch - 2ms/step\n",
            "[안내] 실행 시간 : 19.306 seconds\n",
            "[안내] 샘플 10개의 결과\n",
            "      Rings       pred\n",
            "41       14  11.026981\n",
            "2398     14   9.980166\n",
            "534      10   9.393583\n",
            "4063     11  11.600614\n",
            "2330      9   8.405786\n",
            "2369     12  14.531243\n",
            "1855      9   7.935930\n",
            "2974     12  10.983240\n",
            "679       8   8.640882\n",
            "1218      5   6.573978\n"
          ]
        }
      ],
      "source": [
        "# 최고 모델 사용자 친화적 구현\n",
        "start_time = time.time()\n",
        "print(\"[안내] 모델이 실행됩니다.\")\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=x.shape[1]))\n",
        "model.add(Dropout(0.1))  # Dropout 추가\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.1))  # Dropout 추가\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.1))  # Dropout 추가\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.1))  # Dropout 추가\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dropout(0.1))  # Dropout 추가\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=[accuracy])\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
        "\n",
        "if input_2 == 'y':\n",
        "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "    y_pred = model.predict(X)\n",
        "else:\n",
        "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "    y_pred = model.predict(X)\n",
        "    \n",
        "print(\"[안내] 최종 모델\")\n",
        "if input_2 == 'y':\n",
        "    print(\"[안내] train loss, accuracy\")\n",
        "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
        "    print(\"[안내] validation loss, accuracy\")\n",
        "    loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
        "else:\n",
        "    print(\"[안내] train loss, accuracy\")\n",
        "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
        "    print(\"[안내] test loss, accuracy\")\n",
        "    loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "execution_time = end_time - start_time\n",
        "print(\"[안내] 실행 시간 : {:.3f} seconds\".format(execution_time))\n",
        "\n",
        "input_3 = input(\"[안내] 예측 샘플을 확인할까요? : \")\n",
        "if input_3 == 'y':\n",
        "    print(\"[안내] 샘플 10개의 결과\")\n",
        "    new_y = y\n",
        "    stacked_array = np.vstack((y_pred))\n",
        "    new_df = pd.DataFrame(stacked_array)\n",
        "    new_y = pd.DataFrame(new_y)\n",
        "    new_y['pred'] = new_df[0]\n",
        "    print(new_y.sample(10))\n",
        "else:\n",
        "    print(\"[안내] 실행을 종료합니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI53abxlg9iE"
      },
      "source": [
        "### 최종 model 구현\n",
        "* 고려사항\n",
        "\n",
        "1. 실행시간이 짧은 Best Model 1번 사용\n",
        "\n",
        "2. 사용자 친화적 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlVvkzngg9iE"
      },
      "outputs": [],
      "source": [
        "# 유저로 부터 입력을 받아 검증 데이터 셋을 사용할 것인지, 표준화를 사용할 것인지 정함.\n",
        "def create_best():\n",
        "    print(\"[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\")\n",
        "    input_1 = input(\"[안내] 데이터를 표준화 하시겠습니까? : \")\n",
        "    input_2 = input(\"[안내] 검증 데이터셋을 분리할까요? : \")\n",
        "\n",
        "    # 표준화 진행 여부\n",
        "    if input_1 == 'y':\n",
        "        scaler = StandardScaler()\n",
        "        X = scaler.fit_transform(x)\n",
        "        print(\"[안내] 데이터 표준화를 진행했습니다.\")\n",
        "    else:\n",
        "        X = x\n",
        "        print(\"[안내] 데이터 표준화를 진행하지 않습니다.\")\n",
        "\n",
        "    # 검증 데이터 진행 여부\n",
        "    if input_2 == 'y':\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "        print(\"[안내] 검증 데이터를 추가로 분리했습니다.\")\n",
        "\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        print(\"[안내] 검증 데이터를 분리하지 않았습니다.\")\n",
        "\n",
        "    # 최고 모델 사용자 친화적 구현\n",
        "    start_time = time.time()\n",
        "    print(\"[안내] 모델이 실행됩니다.\")\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation='tanh', input_dim=x.shape[1]))\n",
        "    model.add(Dense(32, activation='tanh'))\n",
        "    model.add(Dense(16, activation='tanh'))\n",
        "    model.add(Dense(8, activation='tanh'))\n",
        "    model.add(Dense(4, activation='tanh'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(loss='mse', optimizer='sgd', metrics=[accuracy])\n",
        "    early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
        "\n",
        "    if input_2 == 'y':\n",
        "        model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "        y_pred = model.predict(X)\n",
        "    else:\n",
        "        model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "        y_pred = model.predict(X)\n",
        "\n",
        "    print(\"[안내] 최종 모델\")\n",
        "    if input_2 == 'y':\n",
        "        print(\"[안내] train loss, accuracy\")\n",
        "        train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
        "        print(\"[안내] validation loss, accuracy\")\n",
        "        loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
        "    else:\n",
        "        print(\"[안내] train loss, accuracy\")\n",
        "        train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
        "        print(\"[안내] test loss, accuracy\")\n",
        "        loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    execution_time = end_time - start_time\n",
        "    print(\"[안내] 실행 시간 : {:.3f} seconds\".format(execution_time))\n",
        "\n",
        "    input_3 = input(\"[안내] 예측 샘플을 확인할까요? : \")\n",
        "    if input_3 == 'y':\n",
        "        print(\"[안내] 샘플 10개의 결과\")\n",
        "        new_y = y\n",
        "        stacked_array = np.vstack((y_pred))\n",
        "        new_df = pd.DataFrame(stacked_array)\n",
        "        new_y = pd.DataFrame(new_y)\n",
        "        new_y['pred'] = new_df[0]\n",
        "        print(new_y.sample(10))\n",
        "        print(\"[안내] 실행을 종료합니다.\")\n",
        "\n",
        "    else:\n",
        "        print(\"[안내] 실행을 종료합니다.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmGcKmFzg9iE"
      },
      "source": [
        "### 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIyUYGp6g9iE",
        "outputId": "a6c15a7f-4d56-41f2-9181-966528c6910c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\n",
            "[안내] 데이터 표준화를 진행했습니다.\n",
            "[안내] 검증 데이터를 추가로 분리했습니다.\n",
            "[안내] 모델이 실행됩니다.\n",
            "Epoch 1/1000\n",
            "84/84 [==============================] - 1s 4ms/step - loss: 14.8807 - accuracy: 0.7425 - val_loss: 6.8556 - val_accuracy: 0.7796\n",
            "Epoch 2/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 6.4742 - accuracy: 0.8189 - val_loss: 6.0546 - val_accuracy: 0.8004\n",
            "Epoch 3/1000\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 5.4681 - accuracy: 0.8347 - val_loss: 5.6419 - val_accuracy: 0.7908\n",
            "Epoch 4/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 5.1346 - accuracy: 0.8383 - val_loss: 5.2808 - val_accuracy: 0.8156\n",
            "Epoch 5/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 5.0836 - accuracy: 0.8383 - val_loss: 4.9870 - val_accuracy: 0.8370\n",
            "Epoch 6/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.8500 - accuracy: 0.8452 - val_loss: 5.0930 - val_accuracy: 0.8229\n",
            "Epoch 7/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.7599 - accuracy: 0.8456 - val_loss: 4.6503 - val_accuracy: 0.8341\n",
            "Epoch 8/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.7465 - accuracy: 0.8449 - val_loss: 4.7282 - val_accuracy: 0.8400\n",
            "Epoch 9/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.6223 - accuracy: 0.8487 - val_loss: 4.6614 - val_accuracy: 0.8440\n",
            "Epoch 10/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.5859 - accuracy: 0.8476 - val_loss: 4.9642 - val_accuracy: 0.8084\n",
            "Epoch 11/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.5688 - accuracy: 0.8473 - val_loss: 5.5856 - val_accuracy: 0.8205\n",
            "Epoch 12/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.4998 - accuracy: 0.8502 - val_loss: 5.2856 - val_accuracy: 0.7932\n",
            "Epoch 13/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.4561 - accuracy: 0.8516 - val_loss: 4.5705 - val_accuracy: 0.8486\n",
            "Epoch 14/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.5058 - accuracy: 0.8495 - val_loss: 4.3193 - val_accuracy: 0.8497\n",
            "Epoch 15/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.4128 - accuracy: 0.8515 - val_loss: 4.8551 - val_accuracy: 0.8252\n",
            "Epoch 16/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.4178 - accuracy: 0.8514 - val_loss: 5.9671 - val_accuracy: 0.7804\n",
            "Epoch 17/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.5043 - accuracy: 0.8480 - val_loss: 4.3322 - val_accuracy: 0.8435\n",
            "Epoch 18/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.3307 - accuracy: 0.8522 - val_loss: 4.4643 - val_accuracy: 0.8449\n",
            "Epoch 19/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.3723 - accuracy: 0.8514 - val_loss: 4.3455 - val_accuracy: 0.8463\n",
            "Epoch 20/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.3511 - accuracy: 0.8510 - val_loss: 4.3745 - val_accuracy: 0.8514\n",
            "Epoch 21/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.3122 - accuracy: 0.8520 - val_loss: 4.3747 - val_accuracy: 0.8416\n",
            "Epoch 22/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.2808 - accuracy: 0.8533 - val_loss: 4.5865 - val_accuracy: 0.8427\n",
            "Epoch 23/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.3376 - accuracy: 0.8512 - val_loss: 4.9135 - val_accuracy: 0.8107\n",
            "Epoch 24/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.2942 - accuracy: 0.8518 - val_loss: 4.4367 - val_accuracy: 0.8389\n",
            "Epoch 25/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.2715 - accuracy: 0.8525 - val_loss: 4.4740 - val_accuracy: 0.8354\n",
            "Epoch 26/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.2872 - accuracy: 0.8529 - val_loss: 4.7518 - val_accuracy: 0.8339\n",
            "Epoch 27/1000\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 4.2789 - accuracy: 0.8531 - val_loss: 4.5857 - val_accuracy: 0.8274\n",
            "131/131 [==============================] - 0s 943us/step\n",
            "[안내] 최종 모델\n",
            "[안내] train loss, accuracy\n",
            "84/84 - 0s - loss: 4.2456 - accuracy: 0.8389 - 96ms/epoch - 1ms/step\n",
            "[안내] validation loss, accuracy\n",
            "21/21 - 0s - loss: 4.5857 - accuracy: 0.8274 - 43ms/epoch - 2ms/step\n",
            "[안내] 실행 시간 : 5.841 seconds\n",
            "[안내] 샘플 10개의 결과\n",
            "      Rings       pred\n",
            "2183      6  15.308678\n",
            "1033     10  13.749382\n",
            "1779      9   7.927064\n",
            "2590      8  10.104479\n",
            "248       7   6.621666\n",
            "2931      9  10.401048\n",
            "3664      9  10.256289\n",
            "2276     14  14.942583\n",
            "1082      7   7.944169\n",
            "3249      6   7.652831\n",
            "[안내] 실행을 종료합니다.\n"
          ]
        }
      ],
      "source": [
        "create_best()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "assign",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
