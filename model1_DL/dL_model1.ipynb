{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Regression_data_preprocessing.csv')\n",
    "target = 'Rings'\n",
    "y = df[target]\n",
    "x = df.drop(target, axis =1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 배치 정규화 - 사용 X\n",
    "배치 정규화는 일반적으로 분류(classification) 문제에서 성능 향상에 더 많이 사용됩니다. 이는 배치 정규화가 입력 데이터의 분포를 정규화하고, 이를 통해 다음 층으로 전달되는 값을 안정화시키기 때문입니다.\n",
    "\n",
    "### 2. Dropout - 성능에 따라 사용\n",
    "드롭아웃은 분류(classification) 문제에서 주로 사용되는 정규화 방법이지만, 회귀(regression) 문제에서도 일부 경우에 사용될 수 있습니다. 회귀 모델에서 드롭아웃을 사용하면, 모델이 특정 입력값에 과도하게 의존하는 것을 방지하여 일반화 성능을 향상시킬 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 활성화 함수\n",
    "1. Relu:\n",
    " 입력층(input layer)과 은닉층(hidden layer)에서는 일반적으로 ReLU(Rectified Linear Unit) 활성화 함수가 많이 사용됩니다. ReLU 함수는 계산이 간단하고, 학습 속도가 빠르며, 특정 입력값에 대해 미분 가능하기 때문에, 딥러닝 모델에서 가장 많이 사용되는 활성화 함수 중 하나입니다.\n",
    "\n",
    "2. tanh:\n",
    " 입력값의 범위가 -1에서 1 사이인 경우에는 하이퍼볼릭 탄젠트(tanh) 함수를 사용하는 것이 좋습니다. 이는 입력값이 크거나 작을 때 출력값이 포화되는 문제를 해결할 수 있기 때문입니다. 따라서 입력값의 범위에 따라 적절한 활성화 함수를 선택하는 것이 좋습니다.\n",
    "\n",
    "3. sigmoid:\n",
    " 입력값을 0과 1 사이의 값으로 변환하는 함수로, 이진 분류(binary classification) 문제에서 출력층의 활성화 함수로 많이 사용됩니다. 하지만 회귀(regression) 문제에서는 선형 모델과 달리 출력값이 제한되지 않아야 하므로, sigmoid 함수를 활성화 함수로 사용하는 것은 적합하지 않습니다.\n",
    "\n",
    " 4. linear:\n",
    " 회귀 문제에서는 출력층의 활성화 함수로 linear 함수를 사용하는 것이 적합합니다. linear 함수는 입력값과 동일한 값을 출력하므로, 출력값의 범위가 제한되지 않습니다. 따라서 linear 함수를 사용하면 모델이 임의의 값을 예측할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\n",
      "[안내] 데이터 표준화를 진행했습니다.\n",
      "[안내] 검증 데이터를 추가로 분리했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 유저로 부터 입력을 받아 검증 데이터 셋을 사용할 것인지, 표준화를 사용할 것인지 정함.\n",
    "print(\"[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\")\n",
    "input_1 = input(\"[안내] 데이터를 표준화 하시겠습니까? : \")\n",
    "input_2 = input(\"[안내] 검증 데이터셋을 분리할까요? : \")\n",
    "\n",
    "# 표준화 진행 여부\n",
    "if input_1 == 'y':\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(x)\n",
    "    print(\"[안내] 데이터 표준화를 진행했습니다.\")\n",
    "else:\n",
    "    X = x\n",
    "    print(\"[안내] 데이터 표준화를 진행하지 않습니다.\")\n",
    "\n",
    "# 검증 데이터 진행 여부\n",
    "if input_2 == 'y':\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    print(\"[안내] 검증 데이터를 추가로 분리했습니다.\")\n",
    "\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"[안내] 검증 데이터를 분리하지 않았습니다.\")\n",
    "\n"
   ]
  },
  <details>
<summary>더보기</summary>

<!--summary 아래 빈칸 공백 두고 내용을 적는공간-->
자세한 내용은 더보기 버튼으로 가려둘 수 있음

</details>
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현\n",
    "\n",
    "1. SGD (Stochastic Gradient Descent):\n",
    "가장 기본적인 옵티마이저로, 경사 하강법의 확률적인 버전입니다.\n",
    "각 학습 단계에서 미니 배치(mini-batch) 단위로 데이터를 사용하여 가중치를 업데이트합니다.\n",
    "단순하고 직관적인 방법이지만, 수렴 속도가 느리고 지역 최소값(local minimum)에 빠질 가능성이 있습니다.\n",
    "\n",
    "2. Adam (Adaptive Moment Estimation):\n",
    "학습률(learning rate)을 조정하는 방법을 통해 경사 하강법을 개선한 알고리즘입니다.\n",
    "학습 속도를 개선하기 위해 모멘텀(Momentum)과 학습률 스케줄링(learning rate scheduling)을 조합합니다.\n",
    "이동 평균(moving average)을 사용하여 각 가중치의 업데이트 속도를 조절하며, 자동으로 적응적인 학습률을 제공합니다.\n",
    "다양한 유형의 신경망 구조와 데이터에 대해 일반적으로 좋은 성능을 보입니다.\n",
    "\n",
    "3. RMSProp (Root Mean Square Propagation):\n",
    "과거 그래디언트(gradient)의 제곱을 이동 평균하여 학습률을 조정하는 알고리즘입니다.\n",
    "최근 그래디언트에 더 큰 가중치를 부여하여 중요한 그래디언트를 잘 반영합니다.\n",
    "이동 평균을 사용하여 각 가중치의 업데이트 속도를 조절하며, 최적의 학습률을 자동으로 조정합니다.\n",
    "비교적 안정적인 학습을 제공하고, RNN(Recurrent Neural Network)과 같은 모델에서 잘 작동하는 경향이 있습니다.\n",
    "\n",
    "### 정확도 \n",
    "- custom metric 사용 : 절대 비율 오차 (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method_custom_metric 구현\n",
    "def accuracy(y_true, y_pred):\n",
    "    return 1 - tf.abs((y_true - y_pred) / y_true) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "334/334 [==============================] - 2s 2ms/step - loss: 34.1855 - accuracy: 0.5364 - val_loss: 6.4455 - val_accuracy: 0.8264\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 15.3500 - accuracy: 0.6982 - val_loss: 7.7909 - val_accuracy: 0.8238\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 14.9085 - accuracy: 0.7181 - val_loss: 6.2106 - val_accuracy: 0.8427\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 13.2400 - accuracy: 0.7317 - val_loss: 6.6437 - val_accuracy: 0.8348\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 13.7753 - accuracy: 0.7288 - val_loss: 6.8828 - val_accuracy: 0.8363\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.4530 - accuracy: 0.7388 - val_loss: 6.5517 - val_accuracy: 0.8403\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.8804 - accuracy: 0.7411 - val_loss: 6.8249 - val_accuracy: 0.8317\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.9752 - accuracy: 0.7589 - val_loss: 7.4683 - val_accuracy: 0.8282\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 11.3056 - accuracy: 0.7548 - val_loss: 5.3705 - val_accuracy: 0.8539\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 11.5131 - accuracy: 0.7592 - val_loss: 6.8310 - val_accuracy: 0.8291\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.9507 - accuracy: 0.7723 - val_loss: 6.0314 - val_accuracy: 0.8461\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.6887 - accuracy: 0.7646 - val_loss: 4.9398 - val_accuracy: 0.8566\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.7250 - accuracy: 0.7647 - val_loss: 5.2630 - val_accuracy: 0.8564\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.6690 - accuracy: 0.7790 - val_loss: 5.4572 - val_accuracy: 0.8542\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.0782 - accuracy: 0.7729 - val_loss: 6.0358 - val_accuracy: 0.8465\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.6801 - accuracy: 0.7811 - val_loss: 6.1508 - val_accuracy: 0.8440\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.5149 - accuracy: 0.7796 - val_loss: 6.2980 - val_accuracy: 0.8418\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.1214 - accuracy: 0.7847 - val_loss: 5.9367 - val_accuracy: 0.8477\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.3530 - accuracy: 0.7866 - val_loss: 5.1721 - val_accuracy: 0.8522\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.4348 - accuracy: 0.7892 - val_loss: 5.8755 - val_accuracy: 0.8492\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.5909 - accuracy: 0.7869 - val_loss: 4.9659 - val_accuracy: 0.8572\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.7037 - accuracy: 0.7924 - val_loss: 5.3772 - val_accuracy: 0.8525\n",
      "Epoch 23/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.0538 - accuracy: 0.7975 - val_loss: 5.6685 - val_accuracy: 0.8489\n",
      "Epoch 24/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.2716 - accuracy: 0.7980 - val_loss: 5.1612 - val_accuracy: 0.8555\n",
      "Epoch 25/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.9265 - accuracy: 0.8024 - val_loss: 5.0739 - val_accuracy: 0.8539\n",
      "Epoch 26/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.8503 - accuracy: 0.7998 - val_loss: 5.2586 - val_accuracy: 0.8538\n",
      "Epoch 27/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.2329 - accuracy: 0.8066 - val_loss: 5.1840 - val_accuracy: 0.8526\n",
      "Epoch 28/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.5544 - accuracy: 0.8051 - val_loss: 5.0523 - val_accuracy: 0.8561\n",
      "Epoch 29/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.6334 - accuracy: 0.8041 - val_loss: 5.0955 - val_accuracy: 0.8492\n",
      "Epoch 30/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.3727 - accuracy: 0.8037 - val_loss: 4.6509 - val_accuracy: 0.8576\n",
      "Epoch 31/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.3906 - accuracy: 0.8062 - val_loss: 5.2339 - val_accuracy: 0.8525\n",
      "Epoch 32/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.0808 - accuracy: 0.8129 - val_loss: 4.6819 - val_accuracy: 0.8539\n",
      "Epoch 33/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.6871 - accuracy: 0.8133 - val_loss: 5.2813 - val_accuracy: 0.8474\n",
      "Epoch 34/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.8622 - accuracy: 0.8135 - val_loss: 5.4888 - val_accuracy: 0.8454\n",
      "Epoch 35/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.7978 - accuracy: 0.8120 - val_loss: 5.2541 - val_accuracy: 0.8501\n",
      "Epoch 36/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.2422 - accuracy: 0.8153 - val_loss: 4.7800 - val_accuracy: 0.8541\n",
      "Epoch 37/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.6484 - accuracy: 0.8125 - val_loss: 5.8032 - val_accuracy: 0.8453\n",
      "Epoch 38/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.4054 - accuracy: 0.8164 - val_loss: 5.1719 - val_accuracy: 0.8493\n",
      "Epoch 39/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.4276 - accuracy: 0.8138 - val_loss: 5.4148 - val_accuracy: 0.8455\n",
      "Epoch 40/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.3767 - accuracy: 0.8185 - val_loss: 5.6300 - val_accuracy: 0.8459\n",
      "Epoch 41/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.1821 - accuracy: 0.8172 - val_loss: 5.2744 - val_accuracy: 0.8460\n",
      "Epoch 42/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.2713 - accuracy: 0.8219 - val_loss: 5.4167 - val_accuracy: 0.8463\n",
      "Epoch 43/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.2690 - accuracy: 0.8161 - val_loss: 5.0910 - val_accuracy: 0.8470\n",
      "Epoch 44/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0833 - accuracy: 0.8161 - val_loss: 5.2045 - val_accuracy: 0.8460\n",
      "Epoch 45/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.2858 - accuracy: 0.8168 - val_loss: 5.1035 - val_accuracy: 0.8456\n",
      "Epoch 46/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.7945 - accuracy: 0.8229 - val_loss: 4.7807 - val_accuracy: 0.8475\n",
      "Epoch 47/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8706 - accuracy: 0.8214 - val_loss: 4.8759 - val_accuracy: 0.8449\n",
      "Epoch 48/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8365 - accuracy: 0.8223 - val_loss: 4.6623 - val_accuracy: 0.8453\n",
      "Epoch 49/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5833 - accuracy: 0.8252 - val_loss: 4.5051 - val_accuracy: 0.8432\n",
      "Epoch 50/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.7147 - accuracy: 0.8263 - val_loss: 5.2168 - val_accuracy: 0.8464\n",
      "Epoch 51/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.7017 - accuracy: 0.8249 - val_loss: 4.7188 - val_accuracy: 0.8453\n",
      "Epoch 52/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8280 - accuracy: 0.8235 - val_loss: 4.6494 - val_accuracy: 0.8441\n",
      "Epoch 53/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5394 - accuracy: 0.8241 - val_loss: 5.0270 - val_accuracy: 0.8429\n",
      "Epoch 54/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5416 - accuracy: 0.8271 - val_loss: 4.5556 - val_accuracy: 0.8435\n",
      "Epoch 55/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6201 - accuracy: 0.8253 - val_loss: 4.5206 - val_accuracy: 0.8419\n",
      "Epoch 56/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5718 - accuracy: 0.8275 - val_loss: 4.7930 - val_accuracy: 0.8469\n",
      "Epoch 57/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6661 - accuracy: 0.8250 - val_loss: 4.6548 - val_accuracy: 0.8421\n",
      "Epoch 58/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.7060 - accuracy: 0.8237 - val_loss: 5.3755 - val_accuracy: 0.8435\n",
      "Epoch 59/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6811 - accuracy: 0.8227 - val_loss: 4.6986 - val_accuracy: 0.8408\n",
      "Epoch 60/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.7749 - accuracy: 0.8258 - val_loss: 4.7815 - val_accuracy: 0.8447\n",
      "Epoch 61/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2976 - accuracy: 0.8279 - val_loss: 4.6410 - val_accuracy: 0.8433\n",
      "Epoch 62/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3572 - accuracy: 0.8294 - val_loss: 4.6674 - val_accuracy: 0.8424\n",
      "Epoch 63/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3711 - accuracy: 0.8275 - val_loss: 4.5911 - val_accuracy: 0.8424\n",
      "Epoch 64/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2377 - accuracy: 0.8296 - val_loss: 4.5279 - val_accuracy: 0.8406\n",
      "Epoch 65/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5059 - accuracy: 0.8267 - val_loss: 4.6609 - val_accuracy: 0.8402\n",
      "Epoch 66/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5342 - accuracy: 0.8270 - val_loss: 4.5177 - val_accuracy: 0.8416\n",
      "Epoch 67/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3372 - accuracy: 0.8280 - val_loss: 4.7149 - val_accuracy: 0.8422\n",
      "Epoch 68/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.4013 - accuracy: 0.8287 - val_loss: 4.8465 - val_accuracy: 0.8439\n",
      "Epoch 69/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2499 - accuracy: 0.8291 - val_loss: 4.5802 - val_accuracy: 0.8424\n",
      "21/21 - 0s - loss: 4.5802 - accuracy: 0.8424 - 41ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 2s 2ms/step - loss: 24.9731 - accuracy: 0.6100 - val_loss: 6.3294 - val_accuracy: 0.8360\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 15.0112 - accuracy: 0.7096 - val_loss: 5.7826 - val_accuracy: 0.8480\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 13.6510 - accuracy: 0.7264 - val_loss: 5.2063 - val_accuracy: 0.8449\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.6095 - accuracy: 0.7403 - val_loss: 5.1542 - val_accuracy: 0.8555\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.2084 - accuracy: 0.7443 - val_loss: 5.3105 - val_accuracy: 0.8504\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.5114 - accuracy: 0.7523 - val_loss: 6.2450 - val_accuracy: 0.8438\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.8663 - accuracy: 0.7706 - val_loss: 4.9091 - val_accuracy: 0.8572\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.8345 - accuracy: 0.7679 - val_loss: 4.9993 - val_accuracy: 0.8569\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.1543 - accuracy: 0.7732 - val_loss: 4.9171 - val_accuracy: 0.8562\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.3671 - accuracy: 0.7827 - val_loss: 4.6673 - val_accuracy: 0.8435\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.8503 - accuracy: 0.7798 - val_loss: 4.8830 - val_accuracy: 0.8561\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.5772 - accuracy: 0.7883 - val_loss: 4.7829 - val_accuracy: 0.8511\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.9465 - accuracy: 0.7920 - val_loss: 4.8087 - val_accuracy: 0.8541\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.9792 - accuracy: 0.7929 - val_loss: 4.4882 - val_accuracy: 0.8477\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.0369 - accuracy: 0.7987 - val_loss: 4.8528 - val_accuracy: 0.8534\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.5741 - accuracy: 0.7981 - val_loss: 4.4598 - val_accuracy: 0.8490\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.9618 - accuracy: 0.7939 - val_loss: 5.1072 - val_accuracy: 0.8553\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.3278 - accuracy: 0.7993 - val_loss: 4.7180 - val_accuracy: 0.8555\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.4831 - accuracy: 0.8012 - val_loss: 4.5932 - val_accuracy: 0.8556\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.5539 - accuracy: 0.8002 - val_loss: 4.5168 - val_accuracy: 0.8569\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.1137 - accuracy: 0.8035 - val_loss: 4.4585 - val_accuracy: 0.8517\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.2870 - accuracy: 0.7995 - val_loss: 4.5832 - val_accuracy: 0.8537\n",
      "Epoch 23/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.0337 - accuracy: 0.8026 - val_loss: 4.6260 - val_accuracy: 0.8524\n",
      "Epoch 24/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.9142 - accuracy: 0.8070 - val_loss: 4.3569 - val_accuracy: 0.8480\n",
      "Epoch 25/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.9843 - accuracy: 0.8048 - val_loss: 4.7475 - val_accuracy: 0.8564\n",
      "Epoch 26/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.4292 - accuracy: 0.8034 - val_loss: 4.6984 - val_accuracy: 0.8525\n",
      "Epoch 27/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.7098 - accuracy: 0.8099 - val_loss: 4.3628 - val_accuracy: 0.8514\n",
      "Epoch 28/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.4583 - accuracy: 0.8096 - val_loss: 4.3087 - val_accuracy: 0.8471\n",
      "Epoch 29/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.5558 - accuracy: 0.8105 - val_loss: 4.5770 - val_accuracy: 0.8509\n",
      "Epoch 30/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.7464 - accuracy: 0.8102 - val_loss: 4.7121 - val_accuracy: 0.8502\n",
      "Epoch 31/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.7184 - accuracy: 0.8078 - val_loss: 4.3589 - val_accuracy: 0.8441\n",
      "Epoch 32/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.4873 - accuracy: 0.8119 - val_loss: 4.4415 - val_accuracy: 0.8385\n",
      "Epoch 33/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.6868 - accuracy: 0.8069 - val_loss: 4.7042 - val_accuracy: 0.8445\n",
      "Epoch 34/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.4966 - accuracy: 0.8090 - val_loss: 4.4368 - val_accuracy: 0.8437\n",
      "Epoch 35/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.3157 - accuracy: 0.8112 - val_loss: 4.3833 - val_accuracy: 0.8402\n",
      "Epoch 36/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.3684 - accuracy: 0.8145 - val_loss: 4.4707 - val_accuracy: 0.8429\n",
      "Epoch 37/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0997 - accuracy: 0.8130 - val_loss: 4.6107 - val_accuracy: 0.8442\n",
      "Epoch 38/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.4238 - accuracy: 0.8142 - val_loss: 4.5719 - val_accuracy: 0.8444\n",
      "Epoch 39/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0674 - accuracy: 0.8160 - val_loss: 4.5887 - val_accuracy: 0.8306\n",
      "Epoch 40/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.2446 - accuracy: 0.8135 - val_loss: 4.4377 - val_accuracy: 0.8419\n",
      "Epoch 41/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.1925 - accuracy: 0.8143 - val_loss: 4.6011 - val_accuracy: 0.8435\n",
      "Epoch 42/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0440 - accuracy: 0.8172 - val_loss: 4.5198 - val_accuracy: 0.8350\n",
      "Epoch 43/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.1201 - accuracy: 0.8176 - val_loss: 4.4132 - val_accuracy: 0.8407\n",
      "Epoch 44/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.2506 - accuracy: 0.8137 - val_loss: 4.4960 - val_accuracy: 0.8412\n",
      "Epoch 45/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.9269 - accuracy: 0.8172 - val_loss: 4.4573 - val_accuracy: 0.8377\n",
      "Epoch 46/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0453 - accuracy: 0.8164 - val_loss: 4.4528 - val_accuracy: 0.8352\n",
      "Epoch 47/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.7849 - accuracy: 0.8184 - val_loss: 4.4222 - val_accuracy: 0.8396\n",
      "Epoch 48/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.7701 - accuracy: 0.8186 - val_loss: 4.4501 - val_accuracy: 0.8365\n",
      "Epoch 49/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0268 - accuracy: 0.8195 - val_loss: 4.4381 - val_accuracy: 0.8364\n",
      "Epoch 50/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8846 - accuracy: 0.8185 - val_loss: 4.3991 - val_accuracy: 0.8394\n",
      "Epoch 51/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0029 - accuracy: 0.8184 - val_loss: 4.4556 - val_accuracy: 0.8412\n",
      "Epoch 52/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0497 - accuracy: 0.8171 - val_loss: 4.4581 - val_accuracy: 0.8398\n",
      "Epoch 53/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.1094 - accuracy: 0.8166 - val_loss: 4.3665 - val_accuracy: 0.8406\n",
      "Epoch 54/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6254 - accuracy: 0.8205 - val_loss: 4.4107 - val_accuracy: 0.8386\n",
      "Epoch 55/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8393 - accuracy: 0.8197 - val_loss: 4.4027 - val_accuracy: 0.8401\n",
      "Epoch 56/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8243 - accuracy: 0.8214 - val_loss: 4.4140 - val_accuracy: 0.8422\n",
      "Epoch 57/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6722 - accuracy: 0.8199 - val_loss: 4.5153 - val_accuracy: 0.8413\n",
      "Epoch 58/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.4868 - accuracy: 0.8225 - val_loss: 4.3444 - val_accuracy: 0.8404\n",
      "Epoch 59/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5374 - accuracy: 0.8229 - val_loss: 4.4146 - val_accuracy: 0.8382\n",
      "Epoch 60/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.9499 - accuracy: 0.8203 - val_loss: 4.3839 - val_accuracy: 0.8361\n",
      "Epoch 61/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8128 - accuracy: 0.8191 - val_loss: 4.3778 - val_accuracy: 0.8386\n",
      "Epoch 62/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.4180 - accuracy: 0.8239 - val_loss: 4.4799 - val_accuracy: 0.8389\n",
      "Epoch 63/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6588 - accuracy: 0.8221 - val_loss: 4.3703 - val_accuracy: 0.8365\n",
      "Epoch 64/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6625 - accuracy: 0.8236 - val_loss: 4.5258 - val_accuracy: 0.8306\n",
      "Epoch 65/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.7384 - accuracy: 0.8221 - val_loss: 4.6159 - val_accuracy: 0.8401\n",
      "Epoch 66/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.4789 - accuracy: 0.8245 - val_loss: 4.4460 - val_accuracy: 0.8361\n",
      "Epoch 67/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2421 - accuracy: 0.8261 - val_loss: 4.3316 - val_accuracy: 0.8398\n",
      "Epoch 68/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3548 - accuracy: 0.8261 - val_loss: 4.4751 - val_accuracy: 0.8271\n",
      "Epoch 69/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3469 - accuracy: 0.8248 - val_loss: 4.4718 - val_accuracy: 0.8386\n",
      "Epoch 70/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6319 - accuracy: 0.8238 - val_loss: 4.4263 - val_accuracy: 0.8339\n",
      "Epoch 71/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5411 - accuracy: 0.8245 - val_loss: 4.5192 - val_accuracy: 0.8411\n",
      "Epoch 72/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2623 - accuracy: 0.8250 - val_loss: 4.4546 - val_accuracy: 0.8410\n",
      "Epoch 73/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5333 - accuracy: 0.8255 - val_loss: 4.4713 - val_accuracy: 0.8402\n",
      "21/21 - 0s - loss: 4.4713 - accuracy: 0.8402 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 17.1644 - accuracy: 0.7091 - val_loss: 6.8380 - val_accuracy: 0.7922\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.6909 - accuracy: 0.7866 - val_loss: 6.2168 - val_accuracy: 0.8217\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.3643 - accuracy: 0.7865 - val_loss: 7.3688 - val_accuracy: 0.7588\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.7948 - accuracy: 0.8034 - val_loss: 5.8427 - val_accuracy: 0.8013\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.5316 - accuracy: 0.8053 - val_loss: 5.2240 - val_accuracy: 0.8376\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.6003 - accuracy: 0.8015 - val_loss: 6.1231 - val_accuracy: 0.7882\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.6091 - accuracy: 0.8035 - val_loss: 6.4652 - val_accuracy: 0.7692\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.2700 - accuracy: 0.8061 - val_loss: 5.0242 - val_accuracy: 0.8376\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.4167 - accuracy: 0.8040 - val_loss: 5.3517 - val_accuracy: 0.8192\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.1262 - accuracy: 0.8081 - val_loss: 4.9165 - val_accuracy: 0.8394\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.1346 - accuracy: 0.8092 - val_loss: 5.0419 - val_accuracy: 0.8416\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.2250 - accuracy: 0.8084 - val_loss: 4.8339 - val_accuracy: 0.8474\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.3041 - accuracy: 0.8070 - val_loss: 5.4190 - val_accuracy: 0.8112\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0534 - accuracy: 0.8133 - val_loss: 5.8476 - val_accuracy: 0.7858\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0271 - accuracy: 0.8113 - val_loss: 4.9301 - val_accuracy: 0.8435\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.1139 - accuracy: 0.8056 - val_loss: 5.4098 - val_accuracy: 0.8022\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8789 - accuracy: 0.8155 - val_loss: 5.1216 - val_accuracy: 0.8203\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.2284 - accuracy: 0.8055 - val_loss: 5.6623 - val_accuracy: 0.7934\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0915 - accuracy: 0.8129 - val_loss: 4.8783 - val_accuracy: 0.8490\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.9330 - accuracy: 0.8149 - val_loss: 4.8021 - val_accuracy: 0.8379\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.9960 - accuracy: 0.8089 - val_loss: 4.8708 - val_accuracy: 0.8426\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.7931 - accuracy: 0.8178 - val_loss: 4.7344 - val_accuracy: 0.8493\n",
      "Epoch 23/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8711 - accuracy: 0.8143 - val_loss: 6.0292 - val_accuracy: 0.7737\n",
      "Epoch 24/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.9736 - accuracy: 0.8159 - val_loss: 5.2597 - val_accuracy: 0.8084\n",
      "Epoch 25/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8990 - accuracy: 0.8140 - val_loss: 4.8670 - val_accuracy: 0.8331\n",
      "Epoch 26/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8306 - accuracy: 0.8163 - val_loss: 4.7359 - val_accuracy: 0.8393\n",
      "Epoch 27/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8854 - accuracy: 0.8146 - val_loss: 4.6472 - val_accuracy: 0.8465\n",
      "21/21 - 0s - loss: 4.6472 - accuracy: 0.8465 - 44ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 2s 3ms/step - loss: 55.7330 - accuracy: 0.3828 - val_loss: 8.6009 - val_accuracy: 0.8138\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 19.2750 - accuracy: 0.6722 - val_loss: 6.9760 - val_accuracy: 0.8328\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 16.1392 - accuracy: 0.7046 - val_loss: 7.3938 - val_accuracy: 0.8279\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 15.4946 - accuracy: 0.7079 - val_loss: 5.8572 - val_accuracy: 0.8504\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 14.4481 - accuracy: 0.7147 - val_loss: 6.7019 - val_accuracy: 0.8396\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 13.2499 - accuracy: 0.7258 - val_loss: 5.1245 - val_accuracy: 0.8546\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 12.5631 - accuracy: 0.7318 - val_loss: 5.3550 - val_accuracy: 0.8544\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.7695 - accuracy: 0.7368 - val_loss: 6.9701 - val_accuracy: 0.8350\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.5143 - accuracy: 0.7473 - val_loss: 7.3249 - val_accuracy: 0.8312\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.2036 - accuracy: 0.7499 - val_loss: 5.8467 - val_accuracy: 0.8502\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.0573 - accuracy: 0.7519 - val_loss: 5.3995 - val_accuracy: 0.8582\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.6368 - accuracy: 0.7562 - val_loss: 5.9515 - val_accuracy: 0.8505\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.3578 - accuracy: 0.7651 - val_loss: 6.7022 - val_accuracy: 0.8402\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.5633 - accuracy: 0.7652 - val_loss: 5.9754 - val_accuracy: 0.8497\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.4683 - accuracy: 0.7735 - val_loss: 4.8917 - val_accuracy: 0.8573\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.3343 - accuracy: 0.7664 - val_loss: 6.1668 - val_accuracy: 0.8455\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.7089 - accuracy: 0.7686 - val_loss: 5.3973 - val_accuracy: 0.8532\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.1148 - accuracy: 0.7757 - val_loss: 5.8113 - val_accuracy: 0.8521\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.7357 - accuracy: 0.7707 - val_loss: 4.9143 - val_accuracy: 0.8588\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.2150 - accuracy: 0.7797 - val_loss: 4.6602 - val_accuracy: 0.8573\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.7215 - accuracy: 0.7850 - val_loss: 4.7112 - val_accuracy: 0.8562\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.8391 - accuracy: 0.7803 - val_loss: 4.8137 - val_accuracy: 0.8530\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.6076 - accuracy: 0.7826 - val_loss: 4.9190 - val_accuracy: 0.8549\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.7872 - val_loss: 4.5562 - val_accuracy: 0.8578\n",
      "Epoch 25/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.2690 - accuracy: 0.7913 - val_loss: 4.9676 - val_accuracy: 0.8581\n",
      "Epoch 26/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.9778 - accuracy: 0.7925 - val_loss: 4.4181 - val_accuracy: 0.8562\n",
      "Epoch 27/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.9196 - accuracy: 0.7950 - val_loss: 4.4510 - val_accuracy: 0.8538\n",
      "Epoch 28/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.8916 - accuracy: 0.7945 - val_loss: 4.3267 - val_accuracy: 0.8533\n",
      "Epoch 29/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.7944 - accuracy: 0.7960 - val_loss: 4.4994 - val_accuracy: 0.8551\n",
      "Epoch 30/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.3844 - accuracy: 0.8026 - val_loss: 4.3701 - val_accuracy: 0.8528\n",
      "Epoch 31/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.5690 - accuracy: 0.7981 - val_loss: 4.5041 - val_accuracy: 0.8578\n",
      "Epoch 32/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.6601 - accuracy: 0.7993 - val_loss: 4.4116 - val_accuracy: 0.8593\n",
      "Epoch 33/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.1059 - accuracy: 0.8033 - val_loss: 4.3979 - val_accuracy: 0.8535\n",
      "Epoch 34/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.2594 - accuracy: 0.8026 - val_loss: 4.6881 - val_accuracy: 0.8582\n",
      "Epoch 35/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.3448 - accuracy: 0.8017 - val_loss: 4.3450 - val_accuracy: 0.8543\n",
      "Epoch 36/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.0121 - accuracy: 0.8054 - val_loss: 4.3260 - val_accuracy: 0.8515\n",
      "Epoch 37/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.2555 - accuracy: 0.8046 - val_loss: 4.3287 - val_accuracy: 0.8517\n",
      "Epoch 38/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.1166 - accuracy: 0.8068 - val_loss: 4.3704 - val_accuracy: 0.8498\n",
      "Epoch 39/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.8799 - accuracy: 0.8078 - val_loss: 4.3398 - val_accuracy: 0.8486\n",
      "Epoch 40/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.7668 - accuracy: 0.8062 - val_loss: 4.5695 - val_accuracy: 0.8567\n",
      "Epoch 41/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.7082 - accuracy: 0.8086 - val_loss: 4.3802 - val_accuracy: 0.8455\n",
      "Epoch 42/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.0996 - accuracy: 0.8069 - val_loss: 4.4539 - val_accuracy: 0.8545\n",
      "Epoch 43/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.9509 - accuracy: 0.8077 - val_loss: 4.4417 - val_accuracy: 0.8528\n",
      "Epoch 44/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.8096 - accuracy: 0.8079 - val_loss: 4.3473 - val_accuracy: 0.8485\n",
      "Epoch 45/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.6145 - accuracy: 0.8097 - val_loss: 4.3211 - val_accuracy: 0.8537\n",
      "Epoch 46/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.7177 - accuracy: 0.8088 - val_loss: 4.2712 - val_accuracy: 0.8465\n",
      "Epoch 47/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.4456 - accuracy: 0.8117 - val_loss: 4.5943 - val_accuracy: 0.8458\n",
      "Epoch 48/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.7264 - accuracy: 0.8147 - val_loss: 4.4491 - val_accuracy: 0.8533\n",
      "Epoch 49/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.6136 - accuracy: 0.8137 - val_loss: 4.2881 - val_accuracy: 0.8463\n",
      "Epoch 50/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.6755 - accuracy: 0.8099 - val_loss: 4.3106 - val_accuracy: 0.8463\n",
      "Epoch 51/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.5060 - accuracy: 0.8121 - val_loss: 4.4295 - val_accuracy: 0.8541\n",
      "Epoch 52/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.8525 - accuracy: 0.8131 - val_loss: 4.3315 - val_accuracy: 0.8442\n",
      "Epoch 53/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.6712 - accuracy: 0.8121 - val_loss: 4.3696 - val_accuracy: 0.8526\n",
      "21/21 - 0s - loss: 4.3696 - accuracy: 0.8526 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 34.9341 - accuracy: 0.5382 - val_loss: 6.6519 - val_accuracy: 0.8382\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 17.3813 - accuracy: 0.6820 - val_loss: 6.6683 - val_accuracy: 0.8402\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 15.5818 - accuracy: 0.6961 - val_loss: 5.7876 - val_accuracy: 0.8434\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 13.6824 - accuracy: 0.7183 - val_loss: 5.3641 - val_accuracy: 0.8518\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 12.7712 - accuracy: 0.7327 - val_loss: 5.3122 - val_accuracy: 0.8527\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.6124 - accuracy: 0.7441 - val_loss: 5.2039 - val_accuracy: 0.8537\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.9819 - accuracy: 0.7522 - val_loss: 5.3055 - val_accuracy: 0.8564\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4071 - accuracy: 0.7599 - val_loss: 4.7545 - val_accuracy: 0.8514\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.1045 - accuracy: 0.7626 - val_loss: 4.7595 - val_accuracy: 0.8593\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.5305 - accuracy: 0.7760 - val_loss: 4.6073 - val_accuracy: 0.8520\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.8000 - accuracy: 0.7731 - val_loss: 4.7589 - val_accuracy: 0.8558\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.7302 - accuracy: 0.7820 - val_loss: 5.2357 - val_accuracy: 0.8537\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.6491 - accuracy: 0.7845 - val_loss: 5.7064 - val_accuracy: 0.8492\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.7083 - accuracy: 0.7865 - val_loss: 4.7008 - val_accuracy: 0.8456\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.6385 - accuracy: 0.7889 - val_loss: 5.1324 - val_accuracy: 0.8510\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.3048 - accuracy: 0.7915 - val_loss: 5.4646 - val_accuracy: 0.8522\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.4845 - accuracy: 0.7969 - val_loss: 5.1204 - val_accuracy: 0.8571\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.6528 - accuracy: 0.7956 - val_loss: 4.8475 - val_accuracy: 0.8557\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.6951 - accuracy: 0.7977 - val_loss: 4.7744 - val_accuracy: 0.8582\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.4997 - accuracy: 0.7963 - val_loss: 4.5401 - val_accuracy: 0.8562\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.4593 - accuracy: 0.7992 - val_loss: 5.1246 - val_accuracy: 0.8556\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.1967 - accuracy: 0.8044 - val_loss: 4.6037 - val_accuracy: 0.8484\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.2952 - accuracy: 0.7994 - val_loss: 5.0707 - val_accuracy: 0.8546\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.5093 - accuracy: 0.8048 - val_loss: 4.8377 - val_accuracy: 0.8513\n",
      "Epoch 25/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.2117 - accuracy: 0.8011 - val_loss: 4.5243 - val_accuracy: 0.8551\n",
      "Epoch 26/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.2237 - accuracy: 0.8044 - val_loss: 4.4281 - val_accuracy: 0.8568\n",
      "Epoch 27/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.0859 - accuracy: 0.8074 - val_loss: 4.4531 - val_accuracy: 0.8538\n",
      "Epoch 28/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.9345 - accuracy: 0.8111 - val_loss: 4.5171 - val_accuracy: 0.8577\n",
      "Epoch 29/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.8848 - accuracy: 0.8091 - val_loss: 4.9695 - val_accuracy: 0.8575\n",
      "Epoch 30/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.8645 - accuracy: 0.8103 - val_loss: 4.3133 - val_accuracy: 0.8565\n",
      "Epoch 31/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.9199 - accuracy: 0.8094 - val_loss: 4.3467 - val_accuracy: 0.8526\n",
      "Epoch 32/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.8222 - accuracy: 0.8113 - val_loss: 4.6733 - val_accuracy: 0.8515\n",
      "Epoch 33/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.5762 - accuracy: 0.8117 - val_loss: 4.7490 - val_accuracy: 0.8572\n",
      "Epoch 34/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.6617 - accuracy: 0.8108 - val_loss: 4.8475 - val_accuracy: 0.8565\n",
      "Epoch 35/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.4676 - accuracy: 0.8188 - val_loss: 4.6935 - val_accuracy: 0.8611\n",
      "Epoch 36/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.6737 - accuracy: 0.8103 - val_loss: 4.4513 - val_accuracy: 0.8540\n",
      "Epoch 37/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.5904 - accuracy: 0.8137 - val_loss: 4.5759 - val_accuracy: 0.8568\n",
      "Epoch 38/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.4925 - accuracy: 0.8147 - val_loss: 4.7875 - val_accuracy: 0.8596\n",
      "Epoch 39/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.9112 - accuracy: 0.8243 - val_loss: 4.4711 - val_accuracy: 0.8518\n",
      "Epoch 40/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.5073 - accuracy: 0.8187 - val_loss: 4.5202 - val_accuracy: 0.8561\n",
      "Epoch 41/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.9854 - accuracy: 0.8195 - val_loss: 4.5289 - val_accuracy: 0.8579\n",
      "Epoch 42/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.4204 - accuracy: 0.8188 - val_loss: 4.4245 - val_accuracy: 0.8510\n",
      "Epoch 43/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.3387 - accuracy: 0.8209 - val_loss: 4.3976 - val_accuracy: 0.8484\n",
      "Epoch 44/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.2294 - accuracy: 0.8174 - val_loss: 4.4497 - val_accuracy: 0.8566\n",
      "21/21 - 0s - loss: 4.4497 - accuracy: 0.8566 - 38ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 14.6237 - accuracy: 0.7067 - val_loss: 6.3553 - val_accuracy: 0.8388\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.6093 - accuracy: 0.7813 - val_loss: 5.2336 - val_accuracy: 0.8491\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.8259 - accuracy: 0.7942 - val_loss: 4.8106 - val_accuracy: 0.8448\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.1445 - accuracy: 0.8054 - val_loss: 5.0800 - val_accuracy: 0.8296\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.4548 - accuracy: 0.8117 - val_loss: 4.6672 - val_accuracy: 0.8417\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.2313 - accuracy: 0.8150 - val_loss: 4.8355 - val_accuracy: 0.8213\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.0135 - accuracy: 0.8136 - val_loss: 4.7330 - val_accuracy: 0.8350\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.1404 - accuracy: 0.8135 - val_loss: 5.0488 - val_accuracy: 0.8343\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.7359 - accuracy: 0.8240 - val_loss: 4.8640 - val_accuracy: 0.8275\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.8298 - accuracy: 0.8242 - val_loss: 4.5476 - val_accuracy: 0.8286\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.6450 - accuracy: 0.8235 - val_loss: 4.6810 - val_accuracy: 0.8406\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3514 - accuracy: 0.8277 - val_loss: 4.6138 - val_accuracy: 0.8375\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3493 - accuracy: 0.8270 - val_loss: 4.4812 - val_accuracy: 0.8374\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.2263 - accuracy: 0.8291 - val_loss: 4.5248 - val_accuracy: 0.8414\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3985 - accuracy: 0.8298 - val_loss: 4.4576 - val_accuracy: 0.8415\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3286 - accuracy: 0.8284 - val_loss: 4.4754 - val_accuracy: 0.8330\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3916 - accuracy: 0.8301 - val_loss: 4.8405 - val_accuracy: 0.8162\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.1535 - accuracy: 0.8338 - val_loss: 4.5154 - val_accuracy: 0.8412\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0179 - accuracy: 0.8356 - val_loss: 4.6200 - val_accuracy: 0.8436\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3719 - accuracy: 0.8303 - val_loss: 4.5132 - val_accuracy: 0.8415\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.1818 - accuracy: 0.8291 - val_loss: 4.7981 - val_accuracy: 0.8212\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.9954 - accuracy: 0.8372 - val_loss: 5.0987 - val_accuracy: 0.8064\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0811 - accuracy: 0.8325 - val_loss: 4.5935 - val_accuracy: 0.8296\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.1920 - accuracy: 0.8315 - val_loss: 4.4431 - val_accuracy: 0.8482\n",
      "Epoch 25/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0390 - accuracy: 0.8308 - val_loss: 4.4517 - val_accuracy: 0.8346\n",
      "Epoch 26/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.1617 - accuracy: 0.8289 - val_loss: 4.3641 - val_accuracy: 0.8418\n",
      "Epoch 27/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0459 - accuracy: 0.8292 - val_loss: 4.6448 - val_accuracy: 0.8355\n",
      "21/21 - 0s - loss: 4.6448 - accuracy: 0.8355 - 41ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 2s 4ms/step - loss: 109.5584 - accuracy: 0.0031 - val_loss: 103.4874 - val_accuracy: 0.0109\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 106.2938 - accuracy: 0.0216 - val_loss: 95.4711 - val_accuracy: 0.0587\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 52.7721 - accuracy: 0.3969 - val_loss: 13.1854 - val_accuracy: 0.7461\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 26.9121 - accuracy: 0.6185 - val_loss: 8.1735 - val_accuracy: 0.8226\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 22.8553 - accuracy: 0.6469 - val_loss: 6.7053 - val_accuracy: 0.8369\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 22.9987 - accuracy: 0.6506 - val_loss: 6.4928 - val_accuracy: 0.8363\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 22.0296 - accuracy: 0.6579 - val_loss: 6.7183 - val_accuracy: 0.8354\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 21.6769 - accuracy: 0.6574 - val_loss: 7.0436 - val_accuracy: 0.8303\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 21.2517 - accuracy: 0.6660 - val_loss: 7.4966 - val_accuracy: 0.8248\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 20.1451 - accuracy: 0.6780 - val_loss: 6.9574 - val_accuracy: 0.8337\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 19.8480 - accuracy: 0.6741 - val_loss: 7.4858 - val_accuracy: 0.8204\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 19.8107 - accuracy: 0.6828 - val_loss: 6.6455 - val_accuracy: 0.8344\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 19.7197 - accuracy: 0.6868 - val_loss: 6.0181 - val_accuracy: 0.8395\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 18.8921 - accuracy: 0.6979 - val_loss: 6.6334 - val_accuracy: 0.8350\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.0901 - accuracy: 0.7062 - val_loss: 6.7340 - val_accuracy: 0.8333\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 18.0144 - accuracy: 0.7108 - val_loss: 8.3647 - val_accuracy: 0.8101\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 17.2203 - accuracy: 0.7150 - val_loss: 5.9323 - val_accuracy: 0.8483\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 16.2762 - accuracy: 0.7182 - val_loss: 6.7518 - val_accuracy: 0.8363\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 15.9708 - accuracy: 0.7279 - val_loss: 7.9845 - val_accuracy: 0.8176\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.6052 - accuracy: 0.7383 - val_loss: 7.2160 - val_accuracy: 0.8252\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 15.7721 - accuracy: 0.7254 - val_loss: 7.2699 - val_accuracy: 0.8282\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.3983 - accuracy: 0.7403 - val_loss: 9.1931 - val_accuracy: 0.7959\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.8817 - accuracy: 0.7325 - val_loss: 6.1145 - val_accuracy: 0.8440\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.7022 - accuracy: 0.7291 - val_loss: 6.6525 - val_accuracy: 0.8377\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.4624 - accuracy: 0.7246 - val_loss: 6.9457 - val_accuracy: 0.8310\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.2538 - accuracy: 0.7298 - val_loss: 7.4483 - val_accuracy: 0.8267\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.2380 - accuracy: 0.7348 - val_loss: 5.8359 - val_accuracy: 0.8486\n",
      "21/21 - 0s - loss: 5.8359 - accuracy: 0.8486 - 38ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 55.9169 - accuracy: 0.3744 - val_loss: 13.9803 - val_accuracy: 0.7321\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 19.2928 - accuracy: 0.6654 - val_loss: 7.1879 - val_accuracy: 0.8401\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 15.0596 - accuracy: 0.7100 - val_loss: 5.7135 - val_accuracy: 0.8457\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.4080 - accuracy: 0.7145 - val_loss: 5.0706 - val_accuracy: 0.8468\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.2914 - accuracy: 0.7240 - val_loss: 6.3243 - val_accuracy: 0.8432\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.2980 - accuracy: 0.7307 - val_loss: 5.1718 - val_accuracy: 0.8540\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.3342 - accuracy: 0.7409 - val_loss: 6.4179 - val_accuracy: 0.8436\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.4964 - accuracy: 0.7405 - val_loss: 4.8599 - val_accuracy: 0.8516\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.9436 - accuracy: 0.7510 - val_loss: 6.7664 - val_accuracy: 0.8324\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.1282 - accuracy: 0.7561 - val_loss: 5.8621 - val_accuracy: 0.8467\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.6213 - accuracy: 0.7562 - val_loss: 5.2619 - val_accuracy: 0.8509\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.5540 - accuracy: 0.7605 - val_loss: 5.3556 - val_accuracy: 0.8519\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.9382 - accuracy: 0.7599 - val_loss: 6.7478 - val_accuracy: 0.8381\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.4642 - accuracy: 0.7627 - val_loss: 5.7191 - val_accuracy: 0.8509\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.3540 - accuracy: 0.7721 - val_loss: 5.1486 - val_accuracy: 0.8566\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.4456 - accuracy: 0.7637 - val_loss: 6.2978 - val_accuracy: 0.8441\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.7621 - accuracy: 0.7697 - val_loss: 6.0107 - val_accuracy: 0.8465\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.9364 - accuracy: 0.7715 - val_loss: 5.0047 - val_accuracy: 0.8587\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.2627 - accuracy: 0.7781 - val_loss: 5.2030 - val_accuracy: 0.8577\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6255 - accuracy: 0.7752 - val_loss: 5.9429 - val_accuracy: 0.8484\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.7217 - accuracy: 0.7811 - val_loss: 6.6051 - val_accuracy: 0.8397\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.2173 - accuracy: 0.7781 - val_loss: 5.9299 - val_accuracy: 0.8487\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.2177 - accuracy: 0.7765 - val_loss: 6.0327 - val_accuracy: 0.8459\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.8418 - accuracy: 0.7849 - val_loss: 5.6698 - val_accuracy: 0.8511\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.8498 - accuracy: 0.7857 - val_loss: 6.6822 - val_accuracy: 0.8383\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.6510 - accuracy: 0.7869 - val_loss: 5.3497 - val_accuracy: 0.8520\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.4379 - accuracy: 0.7882 - val_loss: 5.2739 - val_accuracy: 0.8560\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.7618 - accuracy: 0.7878 - val_loss: 5.3151 - val_accuracy: 0.8547\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.0219 - accuracy: 0.7923 - val_loss: 5.4610 - val_accuracy: 0.8526\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.7733 - accuracy: 0.7868 - val_loss: 4.8565 - val_accuracy: 0.8589\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.4521 - accuracy: 0.7908 - val_loss: 5.1449 - val_accuracy: 0.8579\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0114 - accuracy: 0.7961 - val_loss: 5.7139 - val_accuracy: 0.8511\n",
      "Epoch 33/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.9528 - accuracy: 0.7949 - val_loss: 4.5724 - val_accuracy: 0.8525\n",
      "Epoch 34/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.7105 - accuracy: 0.7978 - val_loss: 4.9517 - val_accuracy: 0.8558\n",
      "Epoch 35/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.2176 - accuracy: 0.7933 - val_loss: 4.9683 - val_accuracy: 0.8529\n",
      "Epoch 36/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.9775 - accuracy: 0.7943 - val_loss: 6.2092 - val_accuracy: 0.8467\n",
      "Epoch 37/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6986 - accuracy: 0.7990 - val_loss: 4.8013 - val_accuracy: 0.8564\n",
      "Epoch 38/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6166 - accuracy: 0.7988 - val_loss: 5.4714 - val_accuracy: 0.8523\n",
      "Epoch 39/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.5928 - accuracy: 0.8008 - val_loss: 5.7250 - val_accuracy: 0.8491\n",
      "Epoch 40/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3895 - accuracy: 0.8024 - val_loss: 5.7701 - val_accuracy: 0.8492\n",
      "Epoch 41/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.9448 - accuracy: 0.7999 - val_loss: 4.9515 - val_accuracy: 0.8556\n",
      "Epoch 42/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.5919 - accuracy: 0.8036 - val_loss: 4.9688 - val_accuracy: 0.8547\n",
      "Epoch 43/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.8054 - val_loss: 5.4744 - val_accuracy: 0.8527\n",
      "Epoch 44/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3991 - accuracy: 0.8011 - val_loss: 4.7757 - val_accuracy: 0.8549\n",
      "Epoch 45/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.2326 - accuracy: 0.8096 - val_loss: 4.7019 - val_accuracy: 0.8587\n",
      "Epoch 46/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0943 - accuracy: 0.8059 - val_loss: 4.9414 - val_accuracy: 0.8567\n",
      "Epoch 47/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.5277 - accuracy: 0.8013 - val_loss: 5.2950 - val_accuracy: 0.8556\n",
      "Epoch 48/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.4494 - accuracy: 0.8030 - val_loss: 5.3910 - val_accuracy: 0.8520\n",
      "Epoch 49/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1295 - accuracy: 0.8053 - val_loss: 5.2697 - val_accuracy: 0.8526\n",
      "Epoch 50/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3812 - accuracy: 0.8067 - val_loss: 5.0475 - val_accuracy: 0.8565\n",
      "21/21 - 0s - loss: 5.0475 - accuracy: 0.8565 - 40ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 18.3348 - accuracy: 0.6845 - val_loss: 6.6737 - val_accuracy: 0.8446\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.8881 - accuracy: 0.7751 - val_loss: 9.6145 - val_accuracy: 0.8086\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.1767 - accuracy: 0.7881 - val_loss: 5.3298 - val_accuracy: 0.8539\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7454 - accuracy: 0.7946 - val_loss: 4.8917 - val_accuracy: 0.8246\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1369 - accuracy: 0.8003 - val_loss: 4.6443 - val_accuracy: 0.8478\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5882 - accuracy: 0.8036 - val_loss: 4.9122 - val_accuracy: 0.8142\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.1482 - accuracy: 0.8136 - val_loss: 4.7891 - val_accuracy: 0.8555\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.1594 - accuracy: 0.8137 - val_loss: 4.6805 - val_accuracy: 0.8558\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.2293 - accuracy: 0.8177 - val_loss: 4.4975 - val_accuracy: 0.8366\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.7492 - accuracy: 0.8237 - val_loss: 4.4670 - val_accuracy: 0.8522\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6123 - accuracy: 0.8240 - val_loss: 5.2464 - val_accuracy: 0.8510\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.8308 - accuracy: 0.8209 - val_loss: 4.5433 - val_accuracy: 0.8360\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4447 - accuracy: 0.8257 - val_loss: 4.4933 - val_accuracy: 0.8362\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6324 - accuracy: 0.8256 - val_loss: 4.6228 - val_accuracy: 0.8311\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5320 - accuracy: 0.8246 - val_loss: 5.2086 - val_accuracy: 0.8449\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6247 - accuracy: 0.8245 - val_loss: 5.6025 - val_accuracy: 0.7984\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6550 - accuracy: 0.8200 - val_loss: 4.8114 - val_accuracy: 0.8235\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5245 - accuracy: 0.8232 - val_loss: 4.9004 - val_accuracy: 0.8422\n",
      "21/21 - 0s - loss: 4.9004 - accuracy: 0.8422 - 39ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 2s 18ms/step - loss: 81.6215 - accuracy: 0.1845 - val_loss: 37.5848 - val_accuracy: 0.4976\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 33.9100 - accuracy: 0.5394 - val_loss: 12.5102 - val_accuracy: 0.7547\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 20.4082 - accuracy: 0.6550 - val_loss: 6.6425 - val_accuracy: 0.8385\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 16.8081 - accuracy: 0.6846 - val_loss: 5.4940 - val_accuracy: 0.8478\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 15.3777 - accuracy: 0.6962 - val_loss: 5.5566 - val_accuracy: 0.8489\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.5950 - accuracy: 0.7155 - val_loss: 5.2708 - val_accuracy: 0.8521\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.3799 - accuracy: 0.7232 - val_loss: 4.9883 - val_accuracy: 0.8526\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.0541 - accuracy: 0.7285 - val_loss: 4.8193 - val_accuracy: 0.8494\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.9135 - accuracy: 0.7311 - val_loss: 5.4344 - val_accuracy: 0.8510\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.7314 - accuracy: 0.7270 - val_loss: 5.1780 - val_accuracy: 0.8532\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.8374 - accuracy: 0.7325 - val_loss: 5.4925 - val_accuracy: 0.8527\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.4406 - accuracy: 0.7350 - val_loss: 5.7505 - val_accuracy: 0.8494\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.2214 - accuracy: 0.7369 - val_loss: 5.7129 - val_accuracy: 0.8515\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.4480 - accuracy: 0.7451 - val_loss: 4.9867 - val_accuracy: 0.8562\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.3080 - accuracy: 0.7506 - val_loss: 5.7540 - val_accuracy: 0.8501\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.8172 - accuracy: 0.7417 - val_loss: 5.2403 - val_accuracy: 0.8526\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.1999 - accuracy: 0.7500 - val_loss: 5.2943 - val_accuracy: 0.8543\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.5424 - accuracy: 0.7497 - val_loss: 5.2795 - val_accuracy: 0.8552\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.9133 - accuracy: 0.7490 - val_loss: 4.9368 - val_accuracy: 0.8555\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.5593 - accuracy: 0.7547 - val_loss: 5.5879 - val_accuracy: 0.8500\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.6996 - accuracy: 0.7535 - val_loss: 4.8895 - val_accuracy: 0.8569\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.9575 - accuracy: 0.7565 - val_loss: 5.4316 - val_accuracy: 0.8543\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.6068 - accuracy: 0.7553 - val_loss: 4.9884 - val_accuracy: 0.8573\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 10.9161 - accuracy: 0.7534 - val_loss: 5.1079 - val_accuracy: 0.8566\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.1905 - accuracy: 0.7607 - val_loss: 5.2465 - val_accuracy: 0.8544\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 9.8661 - accuracy: 0.7646 - val_loss: 5.0621 - val_accuracy: 0.8551\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.4909 - accuracy: 0.7566 - val_loss: 5.3037 - val_accuracy: 0.8538\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.0201 - accuracy: 0.7646 - val_loss: 5.3758 - val_accuracy: 0.8555\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.5876 - accuracy: 0.7585 - val_loss: 5.2497 - val_accuracy: 0.8531\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 9.9951 - accuracy: 0.7639 - val_loss: 5.3991 - val_accuracy: 0.8566\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.2718 - accuracy: 0.7580 - val_loss: 4.8154 - val_accuracy: 0.8559\n",
      "21/21 - 0s - loss: 4.8154 - accuracy: 0.8559 - 38ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 109.8518 - accuracy: 0.0013 - val_loss: 104.3842 - val_accuracy: 0.0058\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 108.7239 - accuracy: 0.0079 - val_loss: 103.5705 - val_accuracy: 0.0105\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 107.8834 - accuracy: 0.0126 - val_loss: 102.7621 - val_accuracy: 0.0152\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 107.0551 - accuracy: 0.0172 - val_loss: 101.9537 - val_accuracy: 0.0199\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 106.2311 - accuracy: 0.0219 - val_loss: 101.1504 - val_accuracy: 0.0247\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 105.4127 - accuracy: 0.0265 - val_loss: 100.3504 - val_accuracy: 0.0294\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 104.5973 - accuracy: 0.0312 - val_loss: 99.5544 - val_accuracy: 0.0341\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 103.7849 - accuracy: 0.0359 - val_loss: 98.7605 - val_accuracy: 0.0388\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 102.9761 - accuracy: 0.0405 - val_loss: 97.9718 - val_accuracy: 0.0436\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 102.1706 - accuracy: 0.0452 - val_loss: 97.1865 - val_accuracy: 0.0483\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 101.3693 - accuracy: 0.0498 - val_loss: 96.4030 - val_accuracy: 0.0530\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 100.5716 - accuracy: 0.0545 - val_loss: 95.6266 - val_accuracy: 0.0577\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 99.7769 - accuracy: 0.0591 - val_loss: 94.8485 - val_accuracy: 0.0625\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 98.9859 - accuracy: 0.0638 - val_loss: 94.0794 - val_accuracy: 0.0672\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 98.2009 - accuracy: 0.0685 - val_loss: 93.3120 - val_accuracy: 0.0719\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 97.4162 - accuracy: 0.0731 - val_loss: 92.5467 - val_accuracy: 0.0766\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 96.6371 - accuracy: 0.0778 - val_loss: 91.7867 - val_accuracy: 0.0814\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 95.8602 - accuracy: 0.0824 - val_loss: 91.0287 - val_accuracy: 0.0861\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 95.0869 - accuracy: 0.0871 - val_loss: 90.2739 - val_accuracy: 0.0908\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 94.3159 - accuracy: 0.0917 - val_loss: 89.5236 - val_accuracy: 0.0955\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 93.5510 - accuracy: 0.0964 - val_loss: 88.7775 - val_accuracy: 0.1002\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 92.7901 - accuracy: 0.1011 - val_loss: 88.0340 - val_accuracy: 0.1050\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 92.0276 - accuracy: 0.1057 - val_loss: 87.2939 - val_accuracy: 0.1097\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 91.2741 - accuracy: 0.1104 - val_loss: 86.5578 - val_accuracy: 0.1144\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 90.5220 - accuracy: 0.1150 - val_loss: 85.8245 - val_accuracy: 0.1191\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 89.7724 - accuracy: 0.1196 - val_loss: 85.0950 - val_accuracy: 0.1239\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 89.0268 - accuracy: 0.1243 - val_loss: 84.3680 - val_accuracy: 0.1286\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 88.2854 - accuracy: 0.1289 - val_loss: 83.6456 - val_accuracy: 0.1333\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 87.5474 - accuracy: 0.1335 - val_loss: 82.9264 - val_accuracy: 0.1381\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 86.8137 - accuracy: 0.1381 - val_loss: 82.2126 - val_accuracy: 0.1428\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 86.0829 - accuracy: 0.1428 - val_loss: 81.5018 - val_accuracy: 0.1475\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 85.3520 - accuracy: 0.1474 - val_loss: 80.7913 - val_accuracy: 0.1522\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 84.6309 - accuracy: 0.1520 - val_loss: 80.0885 - val_accuracy: 0.1569\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 83.9120 - accuracy: 0.1566 - val_loss: 79.3878 - val_accuracy: 0.1617\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 83.1959 - accuracy: 0.1613 - val_loss: 78.6908 - val_accuracy: 0.1664\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 82.4811 - accuracy: 0.1659 - val_loss: 77.9944 - val_accuracy: 0.1711\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 81.7708 - accuracy: 0.1705 - val_loss: 77.3040 - val_accuracy: 0.1758\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 81.0650 - accuracy: 0.1751 - val_loss: 76.6182 - val_accuracy: 0.1806\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 80.3632 - accuracy: 0.1798 - val_loss: 75.9356 - val_accuracy: 0.1853\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 79.6622 - accuracy: 0.1844 - val_loss: 75.2528 - val_accuracy: 0.1900\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 78.9677 - accuracy: 0.1890 - val_loss: 74.5773 - val_accuracy: 0.1947\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 78.2751 - accuracy: 0.1936 - val_loss: 73.9045 - val_accuracy: 0.1995\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 77.5865 - accuracy: 0.1983 - val_loss: 73.2367 - val_accuracy: 0.2042\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 76.9024 - accuracy: 0.2029 - val_loss: 72.5691 - val_accuracy: 0.2089\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 76.2208 - accuracy: 0.2075 - val_loss: 71.9095 - val_accuracy: 0.2136\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 75.5423 - accuracy: 0.2121 - val_loss: 71.2489 - val_accuracy: 0.2183\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 74.8675 - accuracy: 0.2167 - val_loss: 70.5917 - val_accuracy: 0.2231\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 74.1977 - accuracy: 0.2214 - val_loss: 69.9423 - val_accuracy: 0.2278\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 73.5281 - accuracy: 0.2260 - val_loss: 69.2902 - val_accuracy: 0.2325\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 72.8615 - accuracy: 0.2306 - val_loss: 68.6460 - val_accuracy: 0.2372\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 72.2039 - accuracy: 0.2352 - val_loss: 68.0061 - val_accuracy: 0.2420\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 71.5450 - accuracy: 0.2398 - val_loss: 67.3666 - val_accuracy: 0.2467\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 70.8920 - accuracy: 0.2444 - val_loss: 66.7346 - val_accuracy: 0.2514\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 70.2456 - accuracy: 0.2490 - val_loss: 66.1060 - val_accuracy: 0.2561\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 69.5998 - accuracy: 0.2536 - val_loss: 65.4775 - val_accuracy: 0.2608\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 68.9580 - accuracy: 0.2582 - val_loss: 64.8551 - val_accuracy: 0.2655\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 68.3177 - accuracy: 0.2628 - val_loss: 64.2343 - val_accuracy: 0.2703\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 67.6784 - accuracy: 0.2674 - val_loss: 63.6156 - val_accuracy: 0.2750\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 67.0502 - accuracy: 0.2721 - val_loss: 63.0061 - val_accuracy: 0.2797\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 66.4187 - accuracy: 0.2766 - val_loss: 62.3941 - val_accuracy: 0.2844\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 65.7932 - accuracy: 0.2812 - val_loss: 61.7867 - val_accuracy: 0.2892\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 65.1746 - accuracy: 0.2858 - val_loss: 61.1869 - val_accuracy: 0.2939\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 64.5545 - accuracy: 0.2904 - val_loss: 60.5866 - val_accuracy: 0.2986\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 63.9388 - accuracy: 0.2950 - val_loss: 59.9905 - val_accuracy: 0.3033\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 63.3302 - accuracy: 0.2997 - val_loss: 59.4010 - val_accuracy: 0.3080\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 62.7190 - accuracy: 0.3042 - val_loss: 58.8097 - val_accuracy: 0.3128\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 62.1159 - accuracy: 0.3089 - val_loss: 58.2256 - val_accuracy: 0.3175\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 61.5174 - accuracy: 0.3135 - val_loss: 57.6461 - val_accuracy: 0.3222\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 60.9219 - accuracy: 0.3181 - val_loss: 57.0682 - val_accuracy: 0.3269\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 60.3272 - accuracy: 0.3227 - val_loss: 56.4923 - val_accuracy: 0.3317\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 59.7367 - accuracy: 0.3273 - val_loss: 55.9224 - val_accuracy: 0.3364\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 59.1490 - accuracy: 0.3319 - val_loss: 55.3543 - val_accuracy: 0.3411\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 58.5655 - accuracy: 0.3363 - val_loss: 54.7903 - val_accuracy: 0.3457\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 57.9879 - accuracy: 0.3409 - val_loss: 54.2309 - val_accuracy: 0.3504\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 57.4146 - accuracy: 0.3453 - val_loss: 53.6766 - val_accuracy: 0.3551\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 56.8390 - accuracy: 0.3498 - val_loss: 53.1196 - val_accuracy: 0.3598\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 56.2703 - accuracy: 0.3543 - val_loss: 52.5719 - val_accuracy: 0.3644\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 55.7052 - accuracy: 0.3588 - val_loss: 52.0260 - val_accuracy: 0.3691\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 55.1434 - accuracy: 0.3633 - val_loss: 51.4830 - val_accuracy: 0.3738\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 54.5846 - accuracy: 0.3678 - val_loss: 50.9424 - val_accuracy: 0.3785\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 54.0312 - accuracy: 0.3723 - val_loss: 50.4098 - val_accuracy: 0.3831\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 53.4808 - accuracy: 0.3768 - val_loss: 49.8764 - val_accuracy: 0.3878\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 52.9327 - accuracy: 0.3813 - val_loss: 49.3488 - val_accuracy: 0.3925\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 52.3896 - accuracy: 0.3858 - val_loss: 48.8251 - val_accuracy: 0.3972\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 51.8469 - accuracy: 0.3902 - val_loss: 48.3028 - val_accuracy: 0.4018\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 51.3120 - accuracy: 0.3947 - val_loss: 47.7844 - val_accuracy: 0.4065\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 50.7795 - accuracy: 0.3992 - val_loss: 47.2723 - val_accuracy: 0.4112\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 50.2483 - accuracy: 0.4037 - val_loss: 46.7575 - val_accuracy: 0.4159\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 49.7193 - accuracy: 0.4082 - val_loss: 46.2505 - val_accuracy: 0.4206\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 49.1975 - accuracy: 0.4127 - val_loss: 45.7488 - val_accuracy: 0.4252\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 48.6787 - accuracy: 0.4172 - val_loss: 45.2472 - val_accuracy: 0.4299\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 48.1609 - accuracy: 0.4216 - val_loss: 44.7503 - val_accuracy: 0.4346\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 47.6479 - accuracy: 0.4261 - val_loss: 44.2554 - val_accuracy: 0.4393\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 47.1412 - accuracy: 0.4306 - val_loss: 43.7675 - val_accuracy: 0.4439\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 46.6369 - accuracy: 0.4351 - val_loss: 43.2829 - val_accuracy: 0.4486\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 46.1336 - accuracy: 0.4395 - val_loss: 42.7976 - val_accuracy: 0.4531\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 45.6321 - accuracy: 0.4437 - val_loss: 42.3168 - val_accuracy: 0.4574\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 45.1393 - accuracy: 0.4480 - val_loss: 41.8430 - val_accuracy: 0.4618\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 44.6483 - accuracy: 0.4522 - val_loss: 41.3705 - val_accuracy: 0.4661\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 44.1597 - accuracy: 0.4564 - val_loss: 40.9015 - val_accuracy: 0.4705\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 43.6773 - accuracy: 0.4606 - val_loss: 40.4382 - val_accuracy: 0.4748\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 43.1974 - accuracy: 0.4648 - val_loss: 39.9764 - val_accuracy: 0.4792\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 42.7192 - accuracy: 0.4691 - val_loss: 39.5180 - val_accuracy: 0.4836\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 42.2435 - accuracy: 0.4733 - val_loss: 39.0619 - val_accuracy: 0.4879\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 41.7769 - accuracy: 0.4775 - val_loss: 38.6127 - val_accuracy: 0.4923\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 41.3070 - accuracy: 0.4817 - val_loss: 38.1634 - val_accuracy: 0.4967\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 40.8444 - accuracy: 0.4860 - val_loss: 37.7199 - val_accuracy: 0.5010\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 40.3865 - accuracy: 0.4901 - val_loss: 37.2803 - val_accuracy: 0.5054\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 39.9293 - accuracy: 0.4944 - val_loss: 36.8424 - val_accuracy: 0.5097\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 39.4773 - accuracy: 0.4986 - val_loss: 36.4102 - val_accuracy: 0.5141\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 39.0261 - accuracy: 0.5028 - val_loss: 35.9778 - val_accuracy: 0.5185\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 38.5792 - accuracy: 0.5070 - val_loss: 35.5511 - val_accuracy: 0.5228\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 38.1363 - accuracy: 0.5113 - val_loss: 35.1272 - val_accuracy: 0.5272\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 37.6975 - accuracy: 0.5155 - val_loss: 34.7082 - val_accuracy: 0.5315\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 37.2648 - accuracy: 0.5197 - val_loss: 34.2954 - val_accuracy: 0.5359\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 36.8315 - accuracy: 0.5239 - val_loss: 33.8785 - val_accuracy: 0.5403\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 36.4035 - accuracy: 0.5281 - val_loss: 33.4722 - val_accuracy: 0.5446\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 35.9811 - accuracy: 0.5323 - val_loss: 33.0672 - val_accuracy: 0.5490\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 35.5607 - accuracy: 0.5365 - val_loss: 32.6640 - val_accuracy: 0.5533\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 35.1405 - accuracy: 0.5407 - val_loss: 32.2679 - val_accuracy: 0.5573\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 34.7292 - accuracy: 0.5445 - val_loss: 31.8722 - val_accuracy: 0.5612\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 34.3179 - accuracy: 0.5483 - val_loss: 31.4823 - val_accuracy: 0.5650\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 33.9128 - accuracy: 0.5521 - val_loss: 31.0944 - val_accuracy: 0.5689\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 33.5088 - accuracy: 0.5559 - val_loss: 30.7107 - val_accuracy: 0.5728\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 33.1081 - accuracy: 0.5597 - val_loss: 30.3281 - val_accuracy: 0.5767\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 32.7103 - accuracy: 0.5635 - val_loss: 29.9512 - val_accuracy: 0.5806\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 32.3199 - accuracy: 0.5673 - val_loss: 29.5803 - val_accuracy: 0.5844\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 31.9323 - accuracy: 0.5711 - val_loss: 29.2094 - val_accuracy: 0.5883\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 31.5460 - accuracy: 0.5749 - val_loss: 28.8420 - val_accuracy: 0.5922\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 31.1624 - accuracy: 0.5788 - val_loss: 28.4787 - val_accuracy: 0.5961\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 30.7843 - accuracy: 0.5826 - val_loss: 28.1187 - val_accuracy: 0.6000\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 30.4091 - accuracy: 0.5864 - val_loss: 27.7645 - val_accuracy: 0.6038\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 30.0398 - accuracy: 0.5902 - val_loss: 27.4121 - val_accuracy: 0.6077\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 29.6710 - accuracy: 0.5940 - val_loss: 27.0637 - val_accuracy: 0.6116\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 29.3066 - accuracy: 0.5978 - val_loss: 26.7176 - val_accuracy: 0.6154\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 28.9454 - accuracy: 0.6016 - val_loss: 26.3757 - val_accuracy: 0.6193\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 28.5860 - accuracy: 0.6054 - val_loss: 26.0355 - val_accuracy: 0.6232\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 28.2325 - accuracy: 0.6092 - val_loss: 25.7018 - val_accuracy: 0.6271\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 27.8841 - accuracy: 0.6130 - val_loss: 25.3734 - val_accuracy: 0.6309\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 27.5366 - accuracy: 0.6168 - val_loss: 25.0428 - val_accuracy: 0.6348\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 27.1923 - accuracy: 0.6206 - val_loss: 24.7182 - val_accuracy: 0.6387\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 26.8506 - accuracy: 0.6244 - val_loss: 24.3969 - val_accuracy: 0.6426\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 26.5199 - accuracy: 0.6282 - val_loss: 24.0845 - val_accuracy: 0.6464\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 26.1827 - accuracy: 0.6318 - val_loss: 23.7657 - val_accuracy: 0.6493\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 25.8547 - accuracy: 0.6347 - val_loss: 23.4568 - val_accuracy: 0.6521\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 25.5281 - accuracy: 0.6378 - val_loss: 23.1520 - val_accuracy: 0.6548\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 25.2104 - accuracy: 0.6407 - val_loss: 22.8523 - val_accuracy: 0.6575\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 24.8888 - accuracy: 0.6437 - val_loss: 22.5478 - val_accuracy: 0.6602\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 24.5716 - accuracy: 0.6467 - val_loss: 22.2510 - val_accuracy: 0.6630\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 24.2611 - accuracy: 0.6497 - val_loss: 21.9605 - val_accuracy: 0.6657\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 23.9538 - accuracy: 0.6527 - val_loss: 21.6716 - val_accuracy: 0.6684\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 23.6497 - accuracy: 0.6557 - val_loss: 21.3859 - val_accuracy: 0.6711\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 23.3482 - accuracy: 0.6587 - val_loss: 21.1044 - val_accuracy: 0.6738\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 23.0512 - accuracy: 0.6617 - val_loss: 20.8255 - val_accuracy: 0.6766\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 22.7562 - accuracy: 0.6647 - val_loss: 20.5500 - val_accuracy: 0.6793\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 22.4668 - accuracy: 0.6676 - val_loss: 20.2803 - val_accuracy: 0.6820\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 22.1790 - accuracy: 0.6706 - val_loss: 20.0103 - val_accuracy: 0.6847\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 21.8968 - accuracy: 0.6736 - val_loss: 19.7459 - val_accuracy: 0.6875\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 21.6163 - accuracy: 0.6766 - val_loss: 19.4853 - val_accuracy: 0.6902\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 21.3399 - accuracy: 0.6795 - val_loss: 19.2286 - val_accuracy: 0.6929\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 21.0685 - accuracy: 0.6826 - val_loss: 18.9763 - val_accuracy: 0.6956\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 20.7988 - accuracy: 0.6856 - val_loss: 18.7246 - val_accuracy: 0.6983\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 20.5309 - accuracy: 0.6885 - val_loss: 18.4757 - val_accuracy: 0.7011\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 20.2673 - accuracy: 0.6915 - val_loss: 18.2336 - val_accuracy: 0.7038\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 20.0110 - accuracy: 0.6945 - val_loss: 17.9940 - val_accuracy: 0.7065\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 19.7544 - accuracy: 0.6975 - val_loss: 17.7569 - val_accuracy: 0.7092\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 19.5024 - accuracy: 0.7004 - val_loss: 17.5238 - val_accuracy: 0.7119\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 19.2537 - accuracy: 0.7031 - val_loss: 17.2942 - val_accuracy: 0.7138\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 19.0103 - accuracy: 0.7050 - val_loss: 17.0713 - val_accuracy: 0.7155\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 18.7690 - accuracy: 0.7068 - val_loss: 16.8476 - val_accuracy: 0.7171\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 18.5325 - accuracy: 0.7087 - val_loss: 16.6305 - val_accuracy: 0.7188\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 18.2962 - accuracy: 0.7106 - val_loss: 16.4127 - val_accuracy: 0.7205\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 18.0628 - accuracy: 0.7125 - val_loss: 16.1986 - val_accuracy: 0.7222\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.8354 - accuracy: 0.7143 - val_loss: 15.9917 - val_accuracy: 0.7238\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.6142 - accuracy: 0.7162 - val_loss: 15.7870 - val_accuracy: 0.7255\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.3929 - accuracy: 0.7181 - val_loss: 15.5863 - val_accuracy: 0.7271\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.1759 - accuracy: 0.7200 - val_loss: 15.3878 - val_accuracy: 0.7288\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 16.9652 - accuracy: 0.7218 - val_loss: 15.1949 - val_accuracy: 0.7305\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 16.7549 - accuracy: 0.7237 - val_loss: 15.0029 - val_accuracy: 0.7321\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 16.5456 - accuracy: 0.7256 - val_loss: 14.8147 - val_accuracy: 0.7338\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 16.3439 - accuracy: 0.7275 - val_loss: 14.6313 - val_accuracy: 0.7355\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 16.1472 - accuracy: 0.7293 - val_loss: 14.4521 - val_accuracy: 0.7371\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 15.9493 - accuracy: 0.7312 - val_loss: 14.2742 - val_accuracy: 0.7388\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 15.7581 - accuracy: 0.7330 - val_loss: 14.1013 - val_accuracy: 0.7404\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 15.5680 - accuracy: 0.7349 - val_loss: 13.9310 - val_accuracy: 0.7421\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 15.3801 - accuracy: 0.7368 - val_loss: 13.7623 - val_accuracy: 0.7438\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 15.2010 - accuracy: 0.7387 - val_loss: 13.6032 - val_accuracy: 0.7454\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 15.0227 - accuracy: 0.7405 - val_loss: 13.4412 - val_accuracy: 0.7471\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.8445 - accuracy: 0.7424 - val_loss: 13.2842 - val_accuracy: 0.7487\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.6755 - accuracy: 0.7442 - val_loss: 13.1336 - val_accuracy: 0.7504\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.5082 - accuracy: 0.7461 - val_loss: 12.9835 - val_accuracy: 0.7520\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.3430 - accuracy: 0.7477 - val_loss: 12.8391 - val_accuracy: 0.7530\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 14.1818 - accuracy: 0.7482 - val_loss: 12.6953 - val_accuracy: 0.7533\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.0240 - accuracy: 0.7486 - val_loss: 12.5563 - val_accuracy: 0.7537\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.8697 - accuracy: 0.7490 - val_loss: 12.4207 - val_accuracy: 0.7541\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.7195 - accuracy: 0.7494 - val_loss: 12.2891 - val_accuracy: 0.7545\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.5718 - accuracy: 0.7498 - val_loss: 12.1606 - val_accuracy: 0.7549\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.4272 - accuracy: 0.7502 - val_loss: 12.0353 - val_accuracy: 0.7552\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.2918 - accuracy: 0.7505 - val_loss: 11.9181 - val_accuracy: 0.7556\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.1557 - accuracy: 0.7509 - val_loss: 11.8007 - val_accuracy: 0.7560\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.0221 - accuracy: 0.7512 - val_loss: 11.6863 - val_accuracy: 0.7564\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.8960 - accuracy: 0.7516 - val_loss: 11.5755 - val_accuracy: 0.7567\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.7709 - accuracy: 0.7520 - val_loss: 11.4711 - val_accuracy: 0.7571\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.6497 - accuracy: 0.7523 - val_loss: 11.3679 - val_accuracy: 0.7575\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.5265 - accuracy: 0.7527 - val_loss: 11.2635 - val_accuracy: 0.7579\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 12.4116 - accuracy: 0.7531 - val_loss: 11.1689 - val_accuracy: 0.7582\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.3019 - accuracy: 0.7534 - val_loss: 11.0756 - val_accuracy: 0.7586\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.1938 - accuracy: 0.7538 - val_loss: 10.9859 - val_accuracy: 0.7590\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.0858 - accuracy: 0.7542 - val_loss: 10.8963 - val_accuracy: 0.7593\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.9837 - accuracy: 0.7546 - val_loss: 10.8129 - val_accuracy: 0.7597\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.8880 - accuracy: 0.7549 - val_loss: 10.7359 - val_accuracy: 0.7601\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 11.7900 - accuracy: 0.7553 - val_loss: 10.6557 - val_accuracy: 0.7604\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.7004 - accuracy: 0.7556 - val_loss: 10.5839 - val_accuracy: 0.7608\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.6106 - accuracy: 0.7560 - val_loss: 10.5136 - val_accuracy: 0.7612\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.5282 - accuracy: 0.7564 - val_loss: 10.4477 - val_accuracy: 0.7615\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.4480 - accuracy: 0.7567 - val_loss: 10.3859 - val_accuracy: 0.7619\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.3694 - accuracy: 0.7568 - val_loss: 10.3260 - val_accuracy: 0.7613\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.2999 - accuracy: 0.7559 - val_loss: 10.2711 - val_accuracy: 0.7602\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.2281 - accuracy: 0.7549 - val_loss: 10.2176 - val_accuracy: 0.7590\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.1612 - accuracy: 0.7539 - val_loss: 10.1694 - val_accuracy: 0.7579\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.0985 - accuracy: 0.7530 - val_loss: 10.1230 - val_accuracy: 0.7568\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 11.0394 - accuracy: 0.7520 - val_loss: 10.0796 - val_accuracy: 0.7556\n",
      "21/21 - 0s - loss: 10.0796 - accuracy: 0.7556 - 43ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 7ms/step - loss: 37.3494 - accuracy: 0.5348 - val_loss: 7.4599 - val_accuracy: 0.8446\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.6160 - accuracy: 0.7555 - val_loss: 5.9490 - val_accuracy: 0.8512\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.7939 - accuracy: 0.7743 - val_loss: 5.1371 - val_accuracy: 0.8484\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 10.1881 - accuracy: 0.7826 - val_loss: 4.9666 - val_accuracy: 0.8480\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 8.4562 - accuracy: 0.7949 - val_loss: 4.7738 - val_accuracy: 0.8282\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.5030 - accuracy: 0.7994 - val_loss: 4.7279 - val_accuracy: 0.8418\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.6435 - accuracy: 0.8046 - val_loss: 4.9113 - val_accuracy: 0.8504\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.1634 - accuracy: 0.8087 - val_loss: 4.8606 - val_accuracy: 0.8464\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.4959 - accuracy: 0.8080 - val_loss: 4.6194 - val_accuracy: 0.8434\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.6532 - accuracy: 0.8160 - val_loss: 4.5836 - val_accuracy: 0.8394\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 6.6552 - accuracy: 0.8161 - val_loss: 4.7982 - val_accuracy: 0.8468\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 6.2778 - accuracy: 0.8172 - val_loss: 4.6881 - val_accuracy: 0.8479\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 6.1656 - accuracy: 0.8229 - val_loss: 4.6510 - val_accuracy: 0.8403\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 6.5616 - accuracy: 0.8211 - val_loss: 4.6230 - val_accuracy: 0.8435\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.8956 - accuracy: 0.8255 - val_loss: 4.7388 - val_accuracy: 0.8450\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.9585 - accuracy: 0.8262 - val_loss: 4.5403 - val_accuracy: 0.8390\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.7168 - accuracy: 0.8272 - val_loss: 4.7010 - val_accuracy: 0.8449\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.5353 - accuracy: 0.8290 - val_loss: 4.9111 - val_accuracy: 0.8451\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 5.7060 - accuracy: 0.8300 - val_loss: 4.5037 - val_accuracy: 0.8348\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.6509 - accuracy: 0.8295 - val_loss: 4.4746 - val_accuracy: 0.8418\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.3579 - accuracy: 0.8348 - val_loss: 4.5344 - val_accuracy: 0.8471\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 5.3694 - accuracy: 0.8306 - val_loss: 4.5773 - val_accuracy: 0.8449\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.4850 - accuracy: 0.8320 - val_loss: 4.4502 - val_accuracy: 0.8421\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.3573 - accuracy: 0.8359 - val_loss: 4.5101 - val_accuracy: 0.8454\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.3083 - accuracy: 0.8344 - val_loss: 4.4398 - val_accuracy: 0.8433\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.1943 - accuracy: 0.8368 - val_loss: 4.4770 - val_accuracy: 0.8482\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.2972 - accuracy: 0.8337 - val_loss: 4.5552 - val_accuracy: 0.8374\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.2539 - accuracy: 0.8379 - val_loss: 4.5067 - val_accuracy: 0.8384\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.1238 - accuracy: 0.8360 - val_loss: 4.5197 - val_accuracy: 0.8351\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9024 - accuracy: 0.8398 - val_loss: 4.3856 - val_accuracy: 0.8447\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.1497 - accuracy: 0.8351 - val_loss: 4.5620 - val_accuracy: 0.8478\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 5.1451 - accuracy: 0.8358 - val_loss: 4.4701 - val_accuracy: 0.8412\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9823 - accuracy: 0.8404 - val_loss: 4.6524 - val_accuracy: 0.8275\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 5.0790 - accuracy: 0.8375 - val_loss: 4.5917 - val_accuracy: 0.8346\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.1486 - accuracy: 0.8360 - val_loss: 4.8119 - val_accuracy: 0.8245\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.2007 - accuracy: 0.8349 - val_loss: 4.5126 - val_accuracy: 0.8397\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 5.0361 - accuracy: 0.8359 - val_loss: 4.5558 - val_accuracy: 0.8316\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9468 - accuracy: 0.8371 - val_loss: 4.5867 - val_accuracy: 0.8304\n",
      "21/21 - 0s - loss: 4.5867 - accuracy: 0.8304 - 47ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 2s 11ms/step - loss: 108.3678 - accuracy: 0.0109 - val_loss: 98.4015 - val_accuracy: 0.0427\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 95.2625 - accuracy: 0.0903 - val_loss: 76.9520 - val_accuracy: 0.1789\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 63.5912 - accuracy: 0.3052 - val_loss: 33.0140 - val_accuracy: 0.5313\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.2263 - accuracy: 0.4747 - val_loss: 18.4568 - val_accuracy: 0.6660\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 33.7873 - accuracy: 0.5472 - val_loss: 14.3972 - val_accuracy: 0.7254\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.7473 - accuracy: 0.6076 - val_loss: 9.6675 - val_accuracy: 0.7903\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.3613 - accuracy: 0.6246 - val_loss: 8.4154 - val_accuracy: 0.8147\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 23.2127 - accuracy: 0.6450 - val_loss: 7.4740 - val_accuracy: 0.8300\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 24.3646 - accuracy: 0.6428 - val_loss: 8.3661 - val_accuracy: 0.8181\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.4912 - accuracy: 0.6511 - val_loss: 7.5329 - val_accuracy: 0.8268\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 22.5290 - accuracy: 0.6611 - val_loss: 7.4378 - val_accuracy: 0.8289\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.4932 - accuracy: 0.6688 - val_loss: 7.0492 - val_accuracy: 0.8341\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.9919 - accuracy: 0.6663 - val_loss: 7.3394 - val_accuracy: 0.8255\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.3792 - accuracy: 0.6675 - val_loss: 6.2487 - val_accuracy: 0.8444\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.6447 - accuracy: 0.6795 - val_loss: 6.2781 - val_accuracy: 0.8409\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.3913 - accuracy: 0.6858 - val_loss: 6.6536 - val_accuracy: 0.8372\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8679 - accuracy: 0.6773 - val_loss: 6.5575 - val_accuracy: 0.8370\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.6151 - accuracy: 0.6805 - val_loss: 6.0588 - val_accuracy: 0.8455\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.6815 - accuracy: 0.6859 - val_loss: 5.8240 - val_accuracy: 0.8466\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.7059 - accuracy: 0.6843 - val_loss: 6.1361 - val_accuracy: 0.8431\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.7828 - accuracy: 0.6865 - val_loss: 6.2069 - val_accuracy: 0.8413\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.8139 - accuracy: 0.6945 - val_loss: 6.3127 - val_accuracy: 0.8416\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 16.3796 - accuracy: 0.6976 - val_loss: 6.1563 - val_accuracy: 0.8422\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 16.5949 - accuracy: 0.6952 - val_loss: 6.0481 - val_accuracy: 0.8456\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.5309 - accuracy: 0.7017 - val_loss: 6.1832 - val_accuracy: 0.8448\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.7877 - accuracy: 0.7018 - val_loss: 7.0254 - val_accuracy: 0.8291\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.6566 - accuracy: 0.7046 - val_loss: 6.6038 - val_accuracy: 0.8380\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1491 - accuracy: 0.7003 - val_loss: 7.0448 - val_accuracy: 0.8322\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 15.4620 - accuracy: 0.7153 - val_loss: 6.1091 - val_accuracy: 0.8414\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 15.4993 - accuracy: 0.7128 - val_loss: 7.0284 - val_accuracy: 0.8284\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.0991 - accuracy: 0.7126 - val_loss: 7.3082 - val_accuracy: 0.8274\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.7657 - accuracy: 0.7165 - val_loss: 6.6647 - val_accuracy: 0.8334\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.6852 - accuracy: 0.7224 - val_loss: 6.2369 - val_accuracy: 0.8442\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.8851 - accuracy: 0.7198 - val_loss: 6.5218 - val_accuracy: 0.8385\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.5941 - accuracy: 0.7184 - val_loss: 6.3536 - val_accuracy: 0.8400\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 15.0024 - accuracy: 0.7176 - val_loss: 6.4309 - val_accuracy: 0.8416\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.0407 - accuracy: 0.7265 - val_loss: 5.9955 - val_accuracy: 0.8462\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.5659 - accuracy: 0.7351 - val_loss: 5.7452 - val_accuracy: 0.8503\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.6235 - accuracy: 0.7275 - val_loss: 5.7708 - val_accuracy: 0.8493\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.9931 - accuracy: 0.7281 - val_loss: 6.2113 - val_accuracy: 0.8444\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.8634 - accuracy: 0.7320 - val_loss: 5.4679 - val_accuracy: 0.8519\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 13.0692 - accuracy: 0.7300 - val_loss: 5.4599 - val_accuracy: 0.8528\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 12.4498 - accuracy: 0.7408 - val_loss: 5.6261 - val_accuracy: 0.8506\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.8396 - accuracy: 0.7445 - val_loss: 5.6784 - val_accuracy: 0.8503\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.0618 - accuracy: 0.7454 - val_loss: 5.8868 - val_accuracy: 0.8485\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.6928 - accuracy: 0.7468 - val_loss: 5.4756 - val_accuracy: 0.8501\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.8796 - accuracy: 0.7452 - val_loss: 5.1369 - val_accuracy: 0.8568\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.7269 - accuracy: 0.7480 - val_loss: 5.3607 - val_accuracy: 0.8538\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.4214 - accuracy: 0.7430 - val_loss: 5.1455 - val_accuracy: 0.8566\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 11.5290 - accuracy: 0.7446 - val_loss: 5.7411 - val_accuracy: 0.8494\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 11.4565 - accuracy: 0.7476 - val_loss: 5.0649 - val_accuracy: 0.8572\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.3926 - accuracy: 0.7506 - val_loss: 5.4054 - val_accuracy: 0.8528\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.2715 - accuracy: 0.7543 - val_loss: 5.5266 - val_accuracy: 0.8509\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.5127 - accuracy: 0.7491 - val_loss: 4.9971 - val_accuracy: 0.8576\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.3126 - accuracy: 0.7535 - val_loss: 5.4389 - val_accuracy: 0.8533\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 11.7329 - accuracy: 0.7470 - val_loss: 5.6852 - val_accuracy: 0.8514\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.2154 - accuracy: 0.7592 - val_loss: 5.3856 - val_accuracy: 0.8540\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.4079 - accuracy: 0.7519 - val_loss: 5.0817 - val_accuracy: 0.8573\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.9646 - accuracy: 0.7529 - val_loss: 4.6564 - val_accuracy: 0.8598\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.0391 - accuracy: 0.7564 - val_loss: 5.0069 - val_accuracy: 0.8567\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4573 - accuracy: 0.7632 - val_loss: 5.3789 - val_accuracy: 0.8546\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.2932 - accuracy: 0.7623 - val_loss: 4.9332 - val_accuracy: 0.8590\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 10.4715 - accuracy: 0.7599 - val_loss: 5.1356 - val_accuracy: 0.8575\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.9575 - accuracy: 0.7659 - val_loss: 4.6604 - val_accuracy: 0.8587\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.5373 - accuracy: 0.7603 - val_loss: 4.7506 - val_accuracy: 0.8579\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4715 - accuracy: 0.7713 - val_loss: 5.3143 - val_accuracy: 0.8544\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.1800 - accuracy: 0.7604 - val_loss: 4.9905 - val_accuracy: 0.8587\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7896 - accuracy: 0.7691 - val_loss: 5.1943 - val_accuracy: 0.8548\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 9.5469 - accuracy: 0.7719 - val_loss: 5.4620 - val_accuracy: 0.8542\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.7651 - accuracy: 0.7692 - val_loss: 5.0915 - val_accuracy: 0.8582\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.9711 - accuracy: 0.7665 - val_loss: 4.6899 - val_accuracy: 0.8595\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.2988 - accuracy: 0.7676 - val_loss: 4.8450 - val_accuracy: 0.8567\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5439 - accuracy: 0.7720 - val_loss: 4.7002 - val_accuracy: 0.8578\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2821 - accuracy: 0.7752 - val_loss: 5.0232 - val_accuracy: 0.8562\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6214 - accuracy: 0.7732 - val_loss: 5.1082 - val_accuracy: 0.8568\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.2636 - accuracy: 0.7744 - val_loss: 4.8495 - val_accuracy: 0.8556\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8356 - accuracy: 0.7676 - val_loss: 4.8099 - val_accuracy: 0.8579\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3374 - accuracy: 0.7716 - val_loss: 5.1299 - val_accuracy: 0.8568\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4786 - accuracy: 0.7745 - val_loss: 4.5313 - val_accuracy: 0.8581\n",
      "21/21 - 0s - loss: 4.5313 - accuracy: 0.8581 - 39ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 110.7873 - accuracy: -0.0053 - val_loss: 101.9508 - val_accuracy: 0.0206\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 103.0817 - accuracy: 0.0434 - val_loss: 88.6140 - val_accuracy: 0.1067\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 84.5534 - accuracy: 0.1688 - val_loss: 59.1504 - val_accuracy: 0.3298\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56.3430 - accuracy: 0.3692 - val_loss: 27.5798 - val_accuracy: 0.5834\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40.7325 - accuracy: 0.4854 - val_loss: 17.1191 - val_accuracy: 0.6945\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 33.9417 - accuracy: 0.5576 - val_loss: 13.0200 - val_accuracy: 0.7589\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.7697 - accuracy: 0.5967 - val_loss: 9.3459 - val_accuracy: 0.8103\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 28.6527 - accuracy: 0.6068 - val_loss: 8.3738 - val_accuracy: 0.8226\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.4008 - accuracy: 0.6318 - val_loss: 9.6726 - val_accuracy: 0.7971\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 24.6571 - accuracy: 0.6440 - val_loss: 6.6599 - val_accuracy: 0.8412\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.4706 - accuracy: 0.6292 - val_loss: 8.1263 - val_accuracy: 0.8172\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 23.2887 - accuracy: 0.6513 - val_loss: 7.8507 - val_accuracy: 0.8181\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.6659 - accuracy: 0.6604 - val_loss: 7.9740 - val_accuracy: 0.8178\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.6082 - accuracy: 0.6695 - val_loss: 7.5826 - val_accuracy: 0.8225\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.1390 - accuracy: 0.6707 - val_loss: 7.2223 - val_accuracy: 0.8217\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.2017 - accuracy: 0.6737 - val_loss: 8.0277 - val_accuracy: 0.8130\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.7378 - accuracy: 0.6718 - val_loss: 7.6726 - val_accuracy: 0.8204\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.1739 - accuracy: 0.6683 - val_loss: 6.7206 - val_accuracy: 0.8365\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.4124 - accuracy: 0.6796 - val_loss: 5.5606 - val_accuracy: 0.8514\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.4633 - accuracy: 0.6919 - val_loss: 5.7329 - val_accuracy: 0.8457\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.2127 - accuracy: 0.6947 - val_loss: 5.6339 - val_accuracy: 0.8501\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.0625 - accuracy: 0.7032 - val_loss: 6.8563 - val_accuracy: 0.8326\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.2851 - accuracy: 0.7078 - val_loss: 5.9775 - val_accuracy: 0.8450\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.0200 - accuracy: 0.7148 - val_loss: 6.3200 - val_accuracy: 0.8428\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.5883 - accuracy: 0.7115 - val_loss: 6.9924 - val_accuracy: 0.8299\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 13.5351 - accuracy: 0.7268 - val_loss: 5.8676 - val_accuracy: 0.8486\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 14.1979 - accuracy: 0.7188 - val_loss: 4.5593 - val_accuracy: 0.8531\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 13.8995 - accuracy: 0.7171 - val_loss: 5.2098 - val_accuracy: 0.8552\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.2721 - accuracy: 0.7216 - val_loss: 5.2671 - val_accuracy: 0.8548\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 12.7302 - accuracy: 0.7275 - val_loss: 4.9115 - val_accuracy: 0.8566\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 14.0371 - accuracy: 0.7197 - val_loss: 6.2227 - val_accuracy: 0.8423\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.7527 - accuracy: 0.7296 - val_loss: 4.8045 - val_accuracy: 0.8566\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.4783 - accuracy: 0.7266 - val_loss: 5.8204 - val_accuracy: 0.8481\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.1153 - accuracy: 0.7308 - val_loss: 4.8725 - val_accuracy: 0.8567\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.7479 - accuracy: 0.7271 - val_loss: 5.0574 - val_accuracy: 0.8560\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.2114 - accuracy: 0.7339 - val_loss: 4.8871 - val_accuracy: 0.8563\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 12.8044 - accuracy: 0.7314 - val_loss: 4.8912 - val_accuracy: 0.8587\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.8772 - accuracy: 0.7327 - val_loss: 5.0456 - val_accuracy: 0.8550\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.9788 - accuracy: 0.7425 - val_loss: 5.2364 - val_accuracy: 0.8535\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.3786 - accuracy: 0.7396 - val_loss: 5.2439 - val_accuracy: 0.8555\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.3252 - accuracy: 0.7322 - val_loss: 5.4328 - val_accuracy: 0.8531\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.6918 - accuracy: 0.7419 - val_loss: 4.8244 - val_accuracy: 0.8586\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 12.6309 - accuracy: 0.7355 - val_loss: 5.8478 - val_accuracy: 0.8489\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 12.6221 - accuracy: 0.7395 - val_loss: 5.4929 - val_accuracy: 0.8511\n",
      "21/21 - 0s - loss: 5.4929 - accuracy: 0.8511 - 43ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 75.8840 - accuracy: 0.2263 - val_loss: 8.6978 - val_accuracy: 0.7875\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.4122 - accuracy: 0.7275 - val_loss: 6.0001 - val_accuracy: 0.8456\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.9590 - accuracy: 0.7733 - val_loss: 5.7236 - val_accuracy: 0.8528\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.7249 - accuracy: 0.7843 - val_loss: 4.8141 - val_accuracy: 0.8416\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1627 - accuracy: 0.7954 - val_loss: 4.9642 - val_accuracy: 0.8536\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6467 - accuracy: 0.8011 - val_loss: 4.7017 - val_accuracy: 0.8485\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9960 - accuracy: 0.7956 - val_loss: 4.8782 - val_accuracy: 0.8556\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6890 - accuracy: 0.8042 - val_loss: 4.6119 - val_accuracy: 0.8414\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2144 - accuracy: 0.8050 - val_loss: 5.0823 - val_accuracy: 0.8504\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7094 - accuracy: 0.8145 - val_loss: 4.6345 - val_accuracy: 0.8467\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.9127 - accuracy: 0.8113 - val_loss: 4.5814 - val_accuracy: 0.8444\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3528 - accuracy: 0.8180 - val_loss: 4.5373 - val_accuracy: 0.8536\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6093 - accuracy: 0.8170 - val_loss: 4.6183 - val_accuracy: 0.8510\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5134 - accuracy: 0.8152 - val_loss: 4.6086 - val_accuracy: 0.8383\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6134 - accuracy: 0.8172 - val_loss: 4.8482 - val_accuracy: 0.8553\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5205 - accuracy: 0.8186 - val_loss: 4.5554 - val_accuracy: 0.8367\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.3087 - accuracy: 0.8195 - val_loss: 4.5167 - val_accuracy: 0.8538\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8906 - accuracy: 0.8260 - val_loss: 4.3994 - val_accuracy: 0.8467\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2500 - accuracy: 0.8218 - val_loss: 4.5192 - val_accuracy: 0.8515\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.1032 - accuracy: 0.8215 - val_loss: 4.4605 - val_accuracy: 0.8497\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9777 - accuracy: 0.8239 - val_loss: 4.8528 - val_accuracy: 0.8528\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8913 - accuracy: 0.8255 - val_loss: 4.5330 - val_accuracy: 0.8494\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.8538 - accuracy: 0.8279 - val_loss: 4.4002 - val_accuracy: 0.8468\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7859 - accuracy: 0.8277 - val_loss: 4.5144 - val_accuracy: 0.8538\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8766 - accuracy: 0.8291 - val_loss: 4.5190 - val_accuracy: 0.8422\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9837 - accuracy: 0.8269 - val_loss: 4.4371 - val_accuracy: 0.8440\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.7921 - accuracy: 0.8262 - val_loss: 4.4216 - val_accuracy: 0.8521\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.4933 - accuracy: 0.8306 - val_loss: 4.4212 - val_accuracy: 0.8449\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6659 - accuracy: 0.8288 - val_loss: 4.3397 - val_accuracy: 0.8493\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.3726 - accuracy: 0.8333 - val_loss: 4.4262 - val_accuracy: 0.8372\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6685 - accuracy: 0.8292 - val_loss: 4.4434 - val_accuracy: 0.8451\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.5555 - accuracy: 0.8322 - val_loss: 4.4309 - val_accuracy: 0.8441\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.3727 - accuracy: 0.8359 - val_loss: 4.4353 - val_accuracy: 0.8419\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.3998 - accuracy: 0.8332 - val_loss: 4.3336 - val_accuracy: 0.8448\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.6260 - accuracy: 0.8326 - val_loss: 4.4218 - val_accuracy: 0.8484\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.3307 - accuracy: 0.8368 - val_loss: 4.3649 - val_accuracy: 0.8421\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.2861 - accuracy: 0.8359 - val_loss: 4.3499 - val_accuracy: 0.8430\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.5106 - accuracy: 0.8318 - val_loss: 4.4307 - val_accuracy: 0.8425\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.5509 - accuracy: 0.8324 - val_loss: 4.3588 - val_accuracy: 0.8441\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.4975 - accuracy: 0.8341 - val_loss: 4.3460 - val_accuracy: 0.8459\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.2587 - accuracy: 0.8348 - val_loss: 4.3651 - val_accuracy: 0.8501\n",
      "21/21 - 0s - loss: 4.3651 - accuracy: 0.8501 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 2s 2ms/step - loss: 74.7042 - accuracy: 0.2247 - val_loss: 51.1508 - val_accuracy: 0.3766\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 45.4070 - accuracy: 0.4489 - val_loss: 33.8270 - val_accuracy: 0.5408\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 31.1812 - accuracy: 0.5815 - val_loss: 23.0940 - val_accuracy: 0.6553\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 22.6914 - accuracy: 0.6665 - val_loss: 16.5503 - val_accuracy: 0.7194\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 17.4875 - accuracy: 0.7136 - val_loss: 12.8987 - val_accuracy: 0.7530\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 14.5524 - accuracy: 0.7264 - val_loss: 11.0228 - val_accuracy: 0.7589\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 13.1756 - accuracy: 0.7288 - val_loss: 10.1531 - val_accuracy: 0.7575\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.4453 - accuracy: 0.7208 - val_loss: 9.8613 - val_accuracy: 0.7482\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.2245 - accuracy: 0.7165 - val_loss: 9.7838 - val_accuracy: 0.7435\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.3636 - accuracy: 0.7095 - val_loss: 9.7278 - val_accuracy: 0.7411\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 11.0888 - accuracy: 0.7498 - val_loss: 6.9251 - val_accuracy: 0.8296\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.6421 - accuracy: 0.7756 - val_loss: 6.3531 - val_accuracy: 0.8383\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.3149 - accuracy: 0.7718 - val_loss: 6.2829 - val_accuracy: 0.8199\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.2081 - accuracy: 0.7698 - val_loss: 5.9752 - val_accuracy: 0.8271\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.8245 - accuracy: 0.7758 - val_loss: 5.5940 - val_accuracy: 0.8464\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.7320 - accuracy: 0.7763 - val_loss: 5.5022 - val_accuracy: 0.8369\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.4527 - accuracy: 0.7797 - val_loss: 5.4734 - val_accuracy: 0.8324\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.2424 - accuracy: 0.7825 - val_loss: 5.3117 - val_accuracy: 0.8337\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.8681 - accuracy: 0.7887 - val_loss: 5.2010 - val_accuracy: 0.8378\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.3431 - accuracy: 0.7827 - val_loss: 5.0980 - val_accuracy: 0.8390\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.0385 - accuracy: 0.7809 - val_loss: 4.9788 - val_accuracy: 0.8452\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.7790 - accuracy: 0.7884 - val_loss: 4.9769 - val_accuracy: 0.8460\n",
      "Epoch 23/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.8771 - accuracy: 0.7870 - val_loss: 4.9356 - val_accuracy: 0.8462\n",
      "Epoch 24/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.5151 - accuracy: 0.7859 - val_loss: 5.0351 - val_accuracy: 0.8395\n",
      "21/21 - 0s - loss: 5.0351 - accuracy: 0.8395 - 43ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 2s 2ms/step - loss: 64.7265 - accuracy: 0.2969 - val_loss: 43.6421 - val_accuracy: 0.4451\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 38.2522 - accuracy: 0.5149 - val_loss: 27.4281 - val_accuracy: 0.6075\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 24.6620 - accuracy: 0.6496 - val_loss: 16.8630 - val_accuracy: 0.7170\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 16.5390 - accuracy: 0.7184 - val_loss: 11.5060 - val_accuracy: 0.7570\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 13.0948 - accuracy: 0.7295 - val_loss: 9.9322 - val_accuracy: 0.7511\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.4477 - accuracy: 0.7116 - val_loss: 9.7679 - val_accuracy: 0.7417\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.3295 - accuracy: 0.7087 - val_loss: 9.7576 - val_accuracy: 0.7393\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.3668 - accuracy: 0.7034 - val_loss: 9.7585 - val_accuracy: 0.7397\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.2107 - accuracy: 0.7068 - val_loss: 9.7575 - val_accuracy: 0.7376\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.3584 - accuracy: 0.7013 - val_loss: 9.7581 - val_accuracy: 0.7374\n",
      "21/21 - 0s - loss: 9.7581 - accuracy: 0.7374 - 49ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 11.3657 - accuracy: 0.7497 - val_loss: 5.6735 - val_accuracy: 0.8414\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.7638 - accuracy: 0.7868 - val_loss: 5.3363 - val_accuracy: 0.8253\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.9216 - accuracy: 0.8023 - val_loss: 5.4176 - val_accuracy: 0.8066\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.6263 - accuracy: 0.8070 - val_loss: 5.4834 - val_accuracy: 0.8220\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.2261 - accuracy: 0.8126 - val_loss: 5.0516 - val_accuracy: 0.8333\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.8736 - accuracy: 0.8188 - val_loss: 4.8829 - val_accuracy: 0.8359\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.9047 - accuracy: 0.8205 - val_loss: 4.8799 - val_accuracy: 0.8326\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6429 - accuracy: 0.8215 - val_loss: 4.7492 - val_accuracy: 0.8418\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5922 - accuracy: 0.8238 - val_loss: 4.6110 - val_accuracy: 0.8454\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5447 - accuracy: 0.8240 - val_loss: 4.6648 - val_accuracy: 0.8318\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.4703 - accuracy: 0.8247 - val_loss: 4.7721 - val_accuracy: 0.8355\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5597 - accuracy: 0.8236 - val_loss: 5.4725 - val_accuracy: 0.8201\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3973 - accuracy: 0.8257 - val_loss: 4.5976 - val_accuracy: 0.8359\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2111 - accuracy: 0.8269 - val_loss: 4.4138 - val_accuracy: 0.8430\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.4151 - accuracy: 0.8232 - val_loss: 4.9573 - val_accuracy: 0.8176\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3410 - accuracy: 0.8231 - val_loss: 4.6003 - val_accuracy: 0.8422\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2456 - accuracy: 0.8283 - val_loss: 4.5694 - val_accuracy: 0.8377\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2309 - accuracy: 0.8260 - val_loss: 4.5806 - val_accuracy: 0.8438\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2385 - accuracy: 0.8272 - val_loss: 5.0309 - val_accuracy: 0.8234\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3533 - accuracy: 0.8250 - val_loss: 4.5617 - val_accuracy: 0.8295\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2030 - accuracy: 0.8260 - val_loss: 4.6845 - val_accuracy: 0.8411\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2370 - accuracy: 0.8261 - val_loss: 4.5921 - val_accuracy: 0.8380\n",
      "21/21 - 0s - loss: 4.5921 - accuracy: 0.8380 - 43ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 2s 3ms/step - loss: 75.2533 - accuracy: 0.2102 - val_loss: 47.6642 - val_accuracy: 0.4062\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 45.2772 - accuracy: 0.4475 - val_loss: 35.8486 - val_accuracy: 0.5197\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 35.7636 - accuracy: 0.5406 - val_loss: 28.4950 - val_accuracy: 0.5959\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 29.1337 - accuracy: 0.6044 - val_loss: 23.0029 - val_accuracy: 0.6573\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 24.1173 - accuracy: 0.6532 - val_loss: 18.9617 - val_accuracy: 0.6958\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 20.6037 - accuracy: 0.6889 - val_loss: 15.9731 - val_accuracy: 0.7240\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 17.7985 - accuracy: 0.7102 - val_loss: 13.8227 - val_accuracy: 0.7432\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 15.8806 - accuracy: 0.7251 - val_loss: 12.1747 - val_accuracy: 0.7599\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 14.3285 - accuracy: 0.7451 - val_loss: 10.4613 - val_accuracy: 0.7897\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 12.7402 - accuracy: 0.7547 - val_loss: 9.1061 - val_accuracy: 0.8252\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.7416 - accuracy: 0.7691 - val_loss: 8.3694 - val_accuracy: 0.8202\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.1562 - accuracy: 0.7730 - val_loss: 7.8028 - val_accuracy: 0.8213\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4660 - accuracy: 0.7767 - val_loss: 7.2784 - val_accuracy: 0.8316\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.3593 - accuracy: 0.7703 - val_loss: 7.0292 - val_accuracy: 0.8301\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 9.8513 - accuracy: 0.7723 - val_loss: 6.7203 - val_accuracy: 0.8373\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.3861 - accuracy: 0.7706 - val_loss: 6.5036 - val_accuracy: 0.8312\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.4137 - accuracy: 0.7771 - val_loss: 6.2511 - val_accuracy: 0.8380\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.2942 - accuracy: 0.7766 - val_loss: 6.0465 - val_accuracy: 0.8377\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.3205 - accuracy: 0.7688 - val_loss: 5.8497 - val_accuracy: 0.8471\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 9.1467 - accuracy: 0.7754 - val_loss: 5.7584 - val_accuracy: 0.8441\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 9.0169 - accuracy: 0.7791 - val_loss: 5.7040 - val_accuracy: 0.8354\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.7471 - accuracy: 0.7735 - val_loss: 5.5131 - val_accuracy: 0.8393\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.4917 - accuracy: 0.7811 - val_loss: 5.4068 - val_accuracy: 0.8423\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 8.9851 - accuracy: 0.7747 - val_loss: 5.3258 - val_accuracy: 0.8446\n",
      "Epoch 25/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.6574 - accuracy: 0.7748 - val_loss: 5.3867 - val_accuracy: 0.8362\n",
      "Epoch 26/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.1018 - accuracy: 0.7788 - val_loss: 5.2313 - val_accuracy: 0.8451\n",
      "Epoch 27/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.1346 - accuracy: 0.7814 - val_loss: 5.2368 - val_accuracy: 0.8432\n",
      "Epoch 28/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.7810 - val_loss: 5.1306 - val_accuracy: 0.8412\n",
      "Epoch 29/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.1139 - accuracy: 0.7810 - val_loss: 5.0568 - val_accuracy: 0.8447\n",
      "Epoch 30/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.2196 - accuracy: 0.7839 - val_loss: 4.9646 - val_accuracy: 0.8506\n",
      "Epoch 31/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.1203 - accuracy: 0.7779 - val_loss: 5.0947 - val_accuracy: 0.8383\n",
      "Epoch 32/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.2994 - accuracy: 0.7777 - val_loss: 5.2376 - val_accuracy: 0.8246\n",
      "Epoch 33/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.1766 - accuracy: 0.7816 - val_loss: 4.9133 - val_accuracy: 0.8504\n",
      "Epoch 34/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.9519 - accuracy: 0.7794 - val_loss: 5.0038 - val_accuracy: 0.8389\n",
      "Epoch 35/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.7578 - accuracy: 0.7874 - val_loss: 4.9447 - val_accuracy: 0.8416\n",
      "Epoch 36/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.7257 - accuracy: 0.7867 - val_loss: 4.8752 - val_accuracy: 0.8442\n",
      "Epoch 37/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.6360 - accuracy: 0.7842 - val_loss: 4.7828 - val_accuracy: 0.8534\n",
      "Epoch 38/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.7933 - accuracy: 0.7829 - val_loss: 4.9621 - val_accuracy: 0.8336\n",
      "Epoch 39/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.6641 - accuracy: 0.7876 - val_loss: 4.8692 - val_accuracy: 0.8374\n",
      "Epoch 40/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.8117 - accuracy: 0.7890 - val_loss: 4.7542 - val_accuracy: 0.8449\n",
      "Epoch 41/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.0986 - accuracy: 0.7952 - val_loss: 4.7446 - val_accuracy: 0.8541\n",
      "Epoch 42/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.5582 - accuracy: 0.7916 - val_loss: 4.7657 - val_accuracy: 0.8483\n",
      "Epoch 43/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.3211 - accuracy: 0.7951 - val_loss: 4.7347 - val_accuracy: 0.8471\n",
      "Epoch 44/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.1604 - accuracy: 0.7933 - val_loss: 4.8524 - val_accuracy: 0.8405\n",
      "Epoch 45/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.5607 - accuracy: 0.7892 - val_loss: 4.8327 - val_accuracy: 0.8466\n",
      "Epoch 46/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.2866 - accuracy: 0.7935 - val_loss: 4.6758 - val_accuracy: 0.8458\n",
      "21/21 - 0s - loss: 4.6758 - accuracy: 0.8458 - 43ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 71.2349 - accuracy: 0.2377 - val_loss: 51.8422 - val_accuracy: 0.3706\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 50.3494 - accuracy: 0.4064 - val_loss: 41.4870 - val_accuracy: 0.4651\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 40.4285 - accuracy: 0.4950 - val_loss: 32.9065 - val_accuracy: 0.5507\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 32.6279 - accuracy: 0.5674 - val_loss: 25.7563 - val_accuracy: 0.6264\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 25.7868 - accuracy: 0.6335 - val_loss: 19.9719 - val_accuracy: 0.6851\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 20.9006 - accuracy: 0.6835 - val_loss: 15.6109 - val_accuracy: 0.7269\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 16.5380 - accuracy: 0.7183 - val_loss: 12.5226 - val_accuracy: 0.7538\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 14.0519 - accuracy: 0.7301 - val_loss: 10.7349 - val_accuracy: 0.7601\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 12.8833 - accuracy: 0.7240 - val_loss: 9.9722 - val_accuracy: 0.7525\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 12.8628 - accuracy: 0.7125 - val_loss: 9.8002 - val_accuracy: 0.7448\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 13.3814 - accuracy: 0.6982 - val_loss: 13.4839 - val_accuracy: 0.6958\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 13.0676 - accuracy: 0.6959 - val_loss: 9.7577 - val_accuracy: 0.7394\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 12.6897 - accuracy: 0.7042 - val_loss: 9.7567 - val_accuracy: 0.7385\n",
      "21/21 - 0s - loss: 9.7567 - accuracy: 0.7385 - 41ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 13.5654 - accuracy: 0.7322 - val_loss: 6.1324 - val_accuracy: 0.8273\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 8.0763 - accuracy: 0.7810 - val_loss: 5.1466 - val_accuracy: 0.8349\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 7.2217 - accuracy: 0.7955 - val_loss: 6.8607 - val_accuracy: 0.7537\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.9960 - accuracy: 0.8022 - val_loss: 5.1669 - val_accuracy: 0.8526\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.5019 - accuracy: 0.8071 - val_loss: 4.9005 - val_accuracy: 0.8392\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.3763 - accuracy: 0.8109 - val_loss: 4.6777 - val_accuracy: 0.8401\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.1184 - accuracy: 0.8139 - val_loss: 4.9128 - val_accuracy: 0.8180\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.9983 - accuracy: 0.8154 - val_loss: 5.8141 - val_accuracy: 0.7797\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.9050 - accuracy: 0.8163 - val_loss: 4.4580 - val_accuracy: 0.8482\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.6846 - accuracy: 0.8202 - val_loss: 4.7698 - val_accuracy: 0.8247\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.5511 - accuracy: 0.8191 - val_loss: 4.4103 - val_accuracy: 0.8401\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.6966 - accuracy: 0.8207 - val_loss: 4.6607 - val_accuracy: 0.8408\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.5066 - accuracy: 0.8224 - val_loss: 4.4165 - val_accuracy: 0.8416\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.7067 - accuracy: 0.8212 - val_loss: 4.4202 - val_accuracy: 0.8425\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.4335 - accuracy: 0.8248 - val_loss: 4.4714 - val_accuracy: 0.8464\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.4903 - accuracy: 0.8230 - val_loss: 4.7129 - val_accuracy: 0.8228\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3900 - accuracy: 0.8238 - val_loss: 4.4434 - val_accuracy: 0.8530\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3422 - accuracy: 0.8244 - val_loss: 4.6124 - val_accuracy: 0.8281\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3056 - accuracy: 0.8289 - val_loss: 4.5472 - val_accuracy: 0.8562\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.2085 - accuracy: 0.8285 - val_loss: 4.3172 - val_accuracy: 0.8484\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3448 - accuracy: 0.8271 - val_loss: 4.3899 - val_accuracy: 0.8433\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.2127 - accuracy: 0.8261 - val_loss: 4.4170 - val_accuracy: 0.8450\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3451 - accuracy: 0.8252 - val_loss: 4.3468 - val_accuracy: 0.8419\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0843 - accuracy: 0.8279 - val_loss: 4.3899 - val_accuracy: 0.8438\n",
      "21/21 - 0s - loss: 4.3899 - accuracy: 0.8438 - 41ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 89.7706 - accuracy: 0.1145 - val_loss: 63.5071 - val_accuracy: 0.2728\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 62.8634 - accuracy: 0.3037 - val_loss: 53.8170 - val_accuracy: 0.3536\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 54.6914 - accuracy: 0.3675 - val_loss: 47.6599 - val_accuracy: 0.4075\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 48.9916 - accuracy: 0.4160 - val_loss: 42.5517 - val_accuracy: 0.4552\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 44.0904 - accuracy: 0.4587 - val_loss: 38.1785 - val_accuracy: 0.4965\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 39.8189 - accuracy: 0.4986 - val_loss: 34.3093 - val_accuracy: 0.5357\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 36.4758 - accuracy: 0.5320 - val_loss: 30.8994 - val_accuracy: 0.5709\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 32.1758 - accuracy: 0.5704 - val_loss: 27.8731 - val_accuracy: 0.6026\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 30.2068 - accuracy: 0.5923 - val_loss: 25.2124 - val_accuracy: 0.6328\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 27.1234 - accuracy: 0.6241 - val_loss: 22.8640 - val_accuracy: 0.6574\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 25.0735 - accuracy: 0.6430 - val_loss: 20.8157 - val_accuracy: 0.6767\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 23.0699 - accuracy: 0.6627 - val_loss: 19.0263 - val_accuracy: 0.6951\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 21.1039 - accuracy: 0.6798 - val_loss: 17.4576 - val_accuracy: 0.7126\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 19.6809 - accuracy: 0.6945 - val_loss: 16.1356 - val_accuracy: 0.7227\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 18.5574 - accuracy: 0.7057 - val_loss: 14.9854 - val_accuracy: 0.7323\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 17.2527 - accuracy: 0.7155 - val_loss: 13.9878 - val_accuracy: 0.7415\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 16.4484 - accuracy: 0.7180 - val_loss: 13.1726 - val_accuracy: 0.7500\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 15.3844 - accuracy: 0.7223 - val_loss: 12.4895 - val_accuracy: 0.7539\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.1546 - accuracy: 0.7249 - val_loss: 11.9102 - val_accuracy: 0.7556\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.3962 - accuracy: 0.7278 - val_loss: 11.4368 - val_accuracy: 0.7572\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.8876 - accuracy: 0.7307 - val_loss: 11.0582 - val_accuracy: 0.7587\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.4672 - accuracy: 0.7288 - val_loss: 10.7513 - val_accuracy: 0.7600\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.4240 - accuracy: 0.7277 - val_loss: 10.4956 - val_accuracy: 0.7613\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.0343 - accuracy: 0.7267 - val_loss: 10.3179 - val_accuracy: 0.7611\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.8165 - accuracy: 0.7250 - val_loss: 10.1687 - val_accuracy: 0.7579\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.0712 - accuracy: 0.7225 - val_loss: 10.0535 - val_accuracy: 0.7549\n",
      "21/21 - 0s - loss: 10.0535 - accuracy: 0.7549 - 43ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 84.3425 - accuracy: 0.1506 - val_loss: 64.2775 - val_accuracy: 0.2693\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 64.2940 - accuracy: 0.2926 - val_loss: 56.7604 - val_accuracy: 0.3294\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 57.8518 - accuracy: 0.3444 - val_loss: 50.9885 - val_accuracy: 0.3781\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 51.9415 - accuracy: 0.3939 - val_loss: 45.7441 - val_accuracy: 0.4253\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 47.0325 - accuracy: 0.4332 - val_loss: 40.9017 - val_accuracy: 0.4705\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 42.3079 - accuracy: 0.4750 - val_loss: 36.4637 - val_accuracy: 0.5135\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 38.1613 - accuracy: 0.5145 - val_loss: 32.3506 - val_accuracy: 0.5565\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 33.6517 - accuracy: 0.5572 - val_loss: 28.6180 - val_accuracy: 0.5946\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 30.1046 - accuracy: 0.5932 - val_loss: 25.2142 - val_accuracy: 0.6328\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 26.7936 - accuracy: 0.6258 - val_loss: 22.1488 - val_accuracy: 0.6639\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 23.9275 - accuracy: 0.6550 - val_loss: 19.4629 - val_accuracy: 0.6904\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 21.1975 - accuracy: 0.6812 - val_loss: 17.1173 - val_accuracy: 0.7151\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 18.8593 - accuracy: 0.7024 - val_loss: 15.0788 - val_accuracy: 0.7315\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 17.1128 - accuracy: 0.7153 - val_loss: 13.4272 - val_accuracy: 0.7472\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.3053 - accuracy: 0.7235 - val_loss: 12.1011 - val_accuracy: 0.7550\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.5898 - accuracy: 0.7255 - val_loss: 11.0929 - val_accuracy: 0.7585\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.4665 - accuracy: 0.7271 - val_loss: 10.4045 - val_accuracy: 0.7618\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.1390 - accuracy: 0.7194 - val_loss: 10.0125 - val_accuracy: 0.7538\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.4695 - accuracy: 0.7217 - val_loss: 9.8422 - val_accuracy: 0.7473\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.5068 - accuracy: 0.7094 - val_loss: 9.7774 - val_accuracy: 0.7428\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.5910 - accuracy: 0.7078 - val_loss: 9.7648 - val_accuracy: 0.7412\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.5667 - accuracy: 0.7045 - val_loss: 9.7575 - val_accuracy: 0.7393\n",
      "21/21 - 0s - loss: 9.7575 - accuracy: 0.7393 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 17.6130 - accuracy: 0.7007 - val_loss: 6.6860 - val_accuracy: 0.8018\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.9735 - accuracy: 0.7761 - val_loss: 5.8829 - val_accuracy: 0.8320\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.1384 - accuracy: 0.7874 - val_loss: 5.5807 - val_accuracy: 0.8318\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.8205 - accuracy: 0.7901 - val_loss: 5.8494 - val_accuracy: 0.8042\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3558 - accuracy: 0.7971 - val_loss: 5.1239 - val_accuracy: 0.8364\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0111 - accuracy: 0.7982 - val_loss: 4.6917 - val_accuracy: 0.8460\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.8158 - accuracy: 0.8033 - val_loss: 4.9133 - val_accuracy: 0.8438\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.4349 - accuracy: 0.8092 - val_loss: 5.7314 - val_accuracy: 0.7867\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4312 - accuracy: 0.8108 - val_loss: 4.9750 - val_accuracy: 0.8197\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.2999 - accuracy: 0.8121 - val_loss: 4.8341 - val_accuracy: 0.8208\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0088 - accuracy: 0.8156 - val_loss: 4.5257 - val_accuracy: 0.8562\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.9025 - accuracy: 0.8195 - val_loss: 5.5867 - val_accuracy: 0.8023\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.0509 - accuracy: 0.8188 - val_loss: 7.1622 - val_accuracy: 0.7388\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.9068 - accuracy: 0.8199 - val_loss: 4.5003 - val_accuracy: 0.8400\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.9163 - accuracy: 0.8199 - val_loss: 4.4496 - val_accuracy: 0.8417\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.8417 - accuracy: 0.8205 - val_loss: 4.3091 - val_accuracy: 0.8517\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8436 - accuracy: 0.8187 - val_loss: 7.1738 - val_accuracy: 0.7352\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5992 - accuracy: 0.8224 - val_loss: 4.9878 - val_accuracy: 0.8090\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6209 - accuracy: 0.8214 - val_loss: 4.4096 - val_accuracy: 0.8537\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.7391 - accuracy: 0.8207 - val_loss: 4.9770 - val_accuracy: 0.8469\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5641 - accuracy: 0.8217 - val_loss: 7.1466 - val_accuracy: 0.7441\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4278 - accuracy: 0.8236 - val_loss: 4.4890 - val_accuracy: 0.8429\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3239 - accuracy: 0.8283 - val_loss: 4.3182 - val_accuracy: 0.8499\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4242 - accuracy: 0.8254 - val_loss: 5.2374 - val_accuracy: 0.8124\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4167 - accuracy: 0.8272 - val_loss: 5.0911 - val_accuracy: 0.8344\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4158 - accuracy: 0.8270 - val_loss: 4.9255 - val_accuracy: 0.8539\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6270 - accuracy: 0.8235 - val_loss: 4.8947 - val_accuracy: 0.8082\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3258 - accuracy: 0.8270 - val_loss: 4.4047 - val_accuracy: 0.8348\n",
      "21/21 - 0s - loss: 4.4047 - accuracy: 0.8348 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 2s 8ms/step - loss: 99.7628 - accuracy: 0.0383 - val_loss: 82.6798 - val_accuracy: 0.1122\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 80.7471 - accuracy: 0.1625 - val_loss: 67.0071 - val_accuracy: 0.2422\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 67.6332 - accuracy: 0.2655 - val_loss: 59.6417 - val_accuracy: 0.3053\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 61.6838 - accuracy: 0.3118 - val_loss: 55.0856 - val_accuracy: 0.3429\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 57.7490 - accuracy: 0.3451 - val_loss: 51.4435 - val_accuracy: 0.3740\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 54.3159 - accuracy: 0.3730 - val_loss: 48.3467 - val_accuracy: 0.4013\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 51.0688 - accuracy: 0.3993 - val_loss: 45.5585 - val_accuracy: 0.4269\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 48.2503 - accuracy: 0.4218 - val_loss: 42.9963 - val_accuracy: 0.4512\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 45.7883 - accuracy: 0.4444 - val_loss: 40.6221 - val_accuracy: 0.4731\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 43.4291 - accuracy: 0.4660 - val_loss: 38.4256 - val_accuracy: 0.4941\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 41.3315 - accuracy: 0.4870 - val_loss: 36.3783 - val_accuracy: 0.5144\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 38.8496 - accuracy: 0.5061 - val_loss: 34.4465 - val_accuracy: 0.5343\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 36.8921 - accuracy: 0.5264 - val_loss: 32.6391 - val_accuracy: 0.5536\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 35.1424 - accuracy: 0.5416 - val_loss: 30.9580 - val_accuracy: 0.5703\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 33.3374 - accuracy: 0.5611 - val_loss: 29.3720 - val_accuracy: 0.5866\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 31.8783 - accuracy: 0.5746 - val_loss: 27.8828 - val_accuracy: 0.6025\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 30.3523 - accuracy: 0.5908 - val_loss: 26.4921 - val_accuracy: 0.6180\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 28.7137 - accuracy: 0.6059 - val_loss: 25.1780 - val_accuracy: 0.6332\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 27.7463 - accuracy: 0.6154 - val_loss: 23.9586 - val_accuracy: 0.6477\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 26.8176 - accuracy: 0.6256 - val_loss: 22.8168 - val_accuracy: 0.6578\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 25.7219 - accuracy: 0.6394 - val_loss: 21.7345 - val_accuracy: 0.6678\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 24.0983 - accuracy: 0.6527 - val_loss: 20.7354 - val_accuracy: 0.6775\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 23.4793 - accuracy: 0.6611 - val_loss: 19.8056 - val_accuracy: 0.6869\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 22.5470 - accuracy: 0.6641 - val_loss: 18.9260 - val_accuracy: 0.6961\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 21.4915 - accuracy: 0.6751 - val_loss: 18.1242 - val_accuracy: 0.7050\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 20.8382 - accuracy: 0.6843 - val_loss: 17.3673 - val_accuracy: 0.7133\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 19.8095 - accuracy: 0.6917 - val_loss: 16.6752 - val_accuracy: 0.7185\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 19.3567 - accuracy: 0.7001 - val_loss: 16.0287 - val_accuracy: 0.7235\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 18.5043 - accuracy: 0.7083 - val_loss: 15.4312 - val_accuracy: 0.7285\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 18.5457 - accuracy: 0.7032 - val_loss: 14.8889 - val_accuracy: 0.7332\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.7877 - accuracy: 0.7104 - val_loss: 14.3848 - val_accuracy: 0.7377\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.2711 - accuracy: 0.7116 - val_loss: 13.9148 - val_accuracy: 0.7423\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 16.4677 - accuracy: 0.7193 - val_loss: 13.4873 - val_accuracy: 0.7466\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 16.1325 - accuracy: 0.7223 - val_loss: 13.0922 - val_accuracy: 0.7508\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 16.0374 - accuracy: 0.7220 - val_loss: 12.7391 - val_accuracy: 0.7532\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 15.3564 - accuracy: 0.7240 - val_loss: 12.4086 - val_accuracy: 0.7542\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.9002 - accuracy: 0.7273 - val_loss: 12.1107 - val_accuracy: 0.7550\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.8856 - accuracy: 0.7258 - val_loss: 11.8412 - val_accuracy: 0.7559\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 14.7648 - accuracy: 0.7291 - val_loss: 11.5877 - val_accuracy: 0.7569\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.1121 - accuracy: 0.7271 - val_loss: 11.3746 - val_accuracy: 0.7575\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.0349 - accuracy: 0.7293 - val_loss: 11.1789 - val_accuracy: 0.7582\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.0323 - accuracy: 0.7215 - val_loss: 10.9998 - val_accuracy: 0.7590\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.8757 - accuracy: 0.7260 - val_loss: 10.8403 - val_accuracy: 0.7596\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.5848 - accuracy: 0.7246 - val_loss: 10.6953 - val_accuracy: 0.7603\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.2521 - accuracy: 0.7242 - val_loss: 10.5731 - val_accuracy: 0.7609\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.2657 - accuracy: 0.7277 - val_loss: 10.4653 - val_accuracy: 0.7615\n",
      "21/21 - 0s - loss: 10.4653 - accuracy: 0.7615 - 40ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 80.3241 - accuracy: 0.1527 - val_loss: 52.4551 - val_accuracy: 0.3518\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 52.0099 - accuracy: 0.3842 - val_loss: 42.4188 - val_accuracy: 0.4557\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 44.7927 - accuracy: 0.4564 - val_loss: 38.5829 - val_accuracy: 0.4924\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 40.9064 - accuracy: 0.4885 - val_loss: 35.7111 - val_accuracy: 0.5212\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 38.2882 - accuracy: 0.5157 - val_loss: 33.2736 - val_accuracy: 0.5467\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 35.4609 - accuracy: 0.5403 - val_loss: 31.1149 - val_accuracy: 0.5687\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 33.6667 - accuracy: 0.5594 - val_loss: 29.1217 - val_accuracy: 0.5892\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 31.9295 - accuracy: 0.5769 - val_loss: 27.2952 - val_accuracy: 0.6090\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 29.5630 - accuracy: 0.5966 - val_loss: 25.5768 - val_accuracy: 0.6285\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 28.1404 - accuracy: 0.6130 - val_loss: 23.9679 - val_accuracy: 0.6476\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 26.5947 - accuracy: 0.6312 - val_loss: 22.4352 - val_accuracy: 0.6613\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 24.6410 - accuracy: 0.6479 - val_loss: 21.0201 - val_accuracy: 0.6747\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 23.1484 - accuracy: 0.6630 - val_loss: 19.6822 - val_accuracy: 0.6886\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 22.1910 - accuracy: 0.6696 - val_loss: 18.4212 - val_accuracy: 0.7017\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 20.5389 - accuracy: 0.6851 - val_loss: 17.2735 - val_accuracy: 0.7140\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 19.7634 - accuracy: 0.6954 - val_loss: 16.1955 - val_accuracy: 0.7222\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 18.6956 - accuracy: 0.7047 - val_loss: 15.1997 - val_accuracy: 0.7304\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.7981 - accuracy: 0.7104 - val_loss: 14.3073 - val_accuracy: 0.7385\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 16.9556 - accuracy: 0.7148 - val_loss: 13.4833 - val_accuracy: 0.7466\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 16.0988 - accuracy: 0.7240 - val_loss: 12.7522 - val_accuracy: 0.7532\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 15.9007 - accuracy: 0.7220 - val_loss: 12.1119 - val_accuracy: 0.7550\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.7369 - accuracy: 0.7274 - val_loss: 11.5489 - val_accuracy: 0.7568\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 14.2440 - accuracy: 0.7242 - val_loss: 11.0840 - val_accuracy: 0.7586\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.5531 - accuracy: 0.7287 - val_loss: 10.6657 - val_accuracy: 0.7604\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 13.3044 - accuracy: 0.7238 - val_loss: 10.2861 - val_accuracy: 0.7636\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 12.6624 - accuracy: 0.7281 - val_loss: 10.1159 - val_accuracy: 0.7566\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.7539 - accuracy: 0.7193 - val_loss: 9.9602 - val_accuracy: 0.7521\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.7035 - accuracy: 0.7189 - val_loss: 9.8483 - val_accuracy: 0.7476\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.4770 - accuracy: 0.7107 - val_loss: 9.7976 - val_accuracy: 0.7446\n",
      "21/21 - 0s - loss: 9.7976 - accuracy: 0.7446 - 39ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 21.2012 - accuracy: 0.6751 - val_loss: 6.6118 - val_accuracy: 0.8263\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 9.5715 - accuracy: 0.7639 - val_loss: 6.2766 - val_accuracy: 0.8232\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 9.2981 - accuracy: 0.7688 - val_loss: 6.0371 - val_accuracy: 0.8341\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.7487 - accuracy: 0.7797 - val_loss: 6.2630 - val_accuracy: 0.7996\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.4081 - accuracy: 0.7845 - val_loss: 5.3516 - val_accuracy: 0.8489\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.0024 - accuracy: 0.7876 - val_loss: 5.1435 - val_accuracy: 0.8404\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 7.9816 - accuracy: 0.7852 - val_loss: 5.3036 - val_accuracy: 0.8239\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.3308 - accuracy: 0.7940 - val_loss: 5.1525 - val_accuracy: 0.8398\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.0384 - accuracy: 0.8018 - val_loss: 4.9368 - val_accuracy: 0.8310\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.0991 - accuracy: 0.8018 - val_loss: 4.7029 - val_accuracy: 0.8479\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.3421 - accuracy: 0.8101 - val_loss: 4.7071 - val_accuracy: 0.8442\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.7724 - accuracy: 0.8032 - val_loss: 4.8557 - val_accuracy: 0.8468\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.6710 - accuracy: 0.8081 - val_loss: 4.7326 - val_accuracy: 0.8488\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.3631 - accuracy: 0.8138 - val_loss: 4.5091 - val_accuracy: 0.8486\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.3545 - accuracy: 0.8106 - val_loss: 4.5168 - val_accuracy: 0.8441\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.4466 - accuracy: 0.8094 - val_loss: 4.5797 - val_accuracy: 0.8569\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 6.1291 - accuracy: 0.8138 - val_loss: 5.5189 - val_accuracy: 0.7876\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.4198 - accuracy: 0.8088 - val_loss: 4.5550 - val_accuracy: 0.8474\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.0740 - accuracy: 0.8188 - val_loss: 4.5668 - val_accuracy: 0.8355\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.9336 - accuracy: 0.8196 - val_loss: 4.6011 - val_accuracy: 0.8307\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.9476 - accuracy: 0.8178 - val_loss: 4.6578 - val_accuracy: 0.8335\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.0908 - accuracy: 0.8168 - val_loss: 4.5387 - val_accuracy: 0.8495\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.8580 - accuracy: 0.8180 - val_loss: 4.3785 - val_accuracy: 0.8485\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.9598 - accuracy: 0.8176 - val_loss: 4.4384 - val_accuracy: 0.8574\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.6182 - accuracy: 0.8242 - val_loss: 4.6573 - val_accuracy: 0.8314\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 5.8292 - accuracy: 0.8227 - val_loss: 4.3308 - val_accuracy: 0.8484\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.8060 - accuracy: 0.8201 - val_loss: 4.4107 - val_accuracy: 0.8411\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.6305 - accuracy: 0.8238 - val_loss: 4.6946 - val_accuracy: 0.8263\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.6908 - accuracy: 0.8229 - val_loss: 4.5594 - val_accuracy: 0.8451\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.5066 - accuracy: 0.8237 - val_loss: 4.3700 - val_accuracy: 0.8411\n",
      "21/21 - 0s - loss: 4.3700 - accuracy: 0.8411 - 40ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 106.4410 - accuracy: 0.0085 - val_loss: 97.3211 - val_accuracy: 0.0251\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 97.6735 - accuracy: 0.0551 - val_loss: 86.6000 - val_accuracy: 0.0980\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 87.3187 - accuracy: 0.1249 - val_loss: 77.6263 - val_accuracy: 0.1679\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 80.3073 - accuracy: 0.1775 - val_loss: 73.2768 - val_accuracy: 0.2030\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 76.5021 - accuracy: 0.2057 - val_loss: 70.5768 - val_accuracy: 0.2228\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 73.7568 - accuracy: 0.2248 - val_loss: 68.3599 - val_accuracy: 0.2392\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 71.8303 - accuracy: 0.2391 - val_loss: 66.3797 - val_accuracy: 0.2539\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 69.3682 - accuracy: 0.2566 - val_loss: 64.5273 - val_accuracy: 0.2679\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 67.8012 - accuracy: 0.2690 - val_loss: 62.7944 - val_accuracy: 0.2813\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 66.4507 - accuracy: 0.2789 - val_loss: 61.1371 - val_accuracy: 0.2942\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 64.5212 - accuracy: 0.2927 - val_loss: 59.5454 - val_accuracy: 0.3068\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 63.3106 - accuracy: 0.3029 - val_loss: 58.0207 - val_accuracy: 0.3191\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61.2388 - accuracy: 0.3187 - val_loss: 56.5366 - val_accuracy: 0.3313\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59.9095 - accuracy: 0.3283 - val_loss: 55.1059 - val_accuracy: 0.3431\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57.9362 - accuracy: 0.3415 - val_loss: 53.7174 - val_accuracy: 0.3547\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56.8330 - accuracy: 0.3504 - val_loss: 52.3667 - val_accuracy: 0.3662\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55.3440 - accuracy: 0.3632 - val_loss: 51.0562 - val_accuracy: 0.3775\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 54.4982 - accuracy: 0.3715 - val_loss: 49.7776 - val_accuracy: 0.3887\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 53.1247 - accuracy: 0.3830 - val_loss: 48.5443 - val_accuracy: 0.3997\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51.6385 - accuracy: 0.3938 - val_loss: 47.3428 - val_accuracy: 0.4105\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50.2366 - accuracy: 0.4045 - val_loss: 46.1671 - val_accuracy: 0.4213\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49.1305 - accuracy: 0.4165 - val_loss: 45.0210 - val_accuracy: 0.4320\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48.1629 - accuracy: 0.4238 - val_loss: 43.9147 - val_accuracy: 0.4425\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46.8067 - accuracy: 0.4349 - val_loss: 42.8334 - val_accuracy: 0.4527\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45.8209 - accuracy: 0.4438 - val_loss: 41.7782 - val_accuracy: 0.4624\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45.0233 - accuracy: 0.4533 - val_loss: 40.7542 - val_accuracy: 0.4719\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.7879 - accuracy: 0.4626 - val_loss: 39.7561 - val_accuracy: 0.4813\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.1959 - accuracy: 0.4694 - val_loss: 38.7853 - val_accuracy: 0.4906\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41.8706 - accuracy: 0.4801 - val_loss: 37.8409 - val_accuracy: 0.4998\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40.9208 - accuracy: 0.4898 - val_loss: 36.9163 - val_accuracy: 0.5090\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.8764 - accuracy: 0.4993 - val_loss: 36.0152 - val_accuracy: 0.5181\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.1226 - accuracy: 0.5053 - val_loss: 35.1382 - val_accuracy: 0.5271\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 37.8205 - accuracy: 0.5182 - val_loss: 34.2813 - val_accuracy: 0.5360\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 37.2991 - accuracy: 0.5235 - val_loss: 33.4542 - val_accuracy: 0.5448\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 36.2959 - accuracy: 0.5299 - val_loss: 32.6444 - val_accuracy: 0.5535\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 35.3361 - accuracy: 0.5386 - val_loss: 31.8554 - val_accuracy: 0.5613\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 34.6761 - accuracy: 0.5468 - val_loss: 31.0890 - val_accuracy: 0.5690\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 33.8524 - accuracy: 0.5556 - val_loss: 30.3462 - val_accuracy: 0.5765\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 32.9970 - accuracy: 0.5624 - val_loss: 29.6173 - val_accuracy: 0.5840\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 32.7185 - accuracy: 0.5680 - val_loss: 28.9167 - val_accuracy: 0.5914\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 31.7752 - accuracy: 0.5791 - val_loss: 28.2354 - val_accuracy: 0.5987\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.9403 - accuracy: 0.5854 - val_loss: 27.5737 - val_accuracy: 0.6059\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.4151 - accuracy: 0.5898 - val_loss: 26.9248 - val_accuracy: 0.6131\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9519 - accuracy: 0.5966 - val_loss: 26.2900 - val_accuracy: 0.6203\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.2110 - accuracy: 0.6020 - val_loss: 25.6823 - val_accuracy: 0.6273\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 28.2287 - accuracy: 0.6103 - val_loss: 25.0914 - val_accuracy: 0.6342\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 28.0842 - accuracy: 0.6108 - val_loss: 24.5090 - val_accuracy: 0.6412\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 27.3081 - accuracy: 0.6202 - val_loss: 23.9529 - val_accuracy: 0.6477\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.9654 - accuracy: 0.6255 - val_loss: 23.4100 - val_accuracy: 0.6525\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 26.0875 - accuracy: 0.6314 - val_loss: 22.8889 - val_accuracy: 0.6571\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.7084 - accuracy: 0.6376 - val_loss: 22.3779 - val_accuracy: 0.6618\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.0647 - accuracy: 0.6436 - val_loss: 21.8821 - val_accuracy: 0.6664\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 24.5834 - accuracy: 0.6475 - val_loss: 21.4013 - val_accuracy: 0.6710\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 24.0018 - accuracy: 0.6542 - val_loss: 20.9401 - val_accuracy: 0.6754\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 23.8860 - accuracy: 0.6549 - val_loss: 20.4964 - val_accuracy: 0.6798\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 23.0419 - accuracy: 0.6661 - val_loss: 20.0605 - val_accuracy: 0.6842\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 23.0010 - accuracy: 0.6648 - val_loss: 19.6365 - val_accuracy: 0.6886\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.2710 - accuracy: 0.6675 - val_loss: 19.2243 - val_accuracy: 0.6929\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.0213 - accuracy: 0.6719 - val_loss: 18.8289 - val_accuracy: 0.6972\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.5772 - accuracy: 0.6773 - val_loss: 18.4455 - val_accuracy: 0.7014\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 20.9606 - accuracy: 0.6819 - val_loss: 18.0716 - val_accuracy: 0.7056\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.8175 - accuracy: 0.6842 - val_loss: 17.7190 - val_accuracy: 0.7097\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.7891 - accuracy: 0.6845 - val_loss: 17.3755 - val_accuracy: 0.7132\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.2647 - accuracy: 0.6889 - val_loss: 17.0426 - val_accuracy: 0.7157\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.2633 - accuracy: 0.6990 - val_loss: 16.7168 - val_accuracy: 0.7181\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.6086 - accuracy: 0.6968 - val_loss: 16.4075 - val_accuracy: 0.7205\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.1529 - accuracy: 0.7007 - val_loss: 16.1077 - val_accuracy: 0.7229\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.1713 - accuracy: 0.7004 - val_loss: 15.8373 - val_accuracy: 0.7250\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.5710 - accuracy: 0.7083 - val_loss: 15.5427 - val_accuracy: 0.7275\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.0742 - accuracy: 0.7080 - val_loss: 15.2750 - val_accuracy: 0.7298\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.8999 - accuracy: 0.7078 - val_loss: 15.0176 - val_accuracy: 0.7320\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.7209 - accuracy: 0.7100 - val_loss: 14.7703 - val_accuracy: 0.7342\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.4495 - accuracy: 0.7123 - val_loss: 14.5307 - val_accuracy: 0.7364\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.2416 - accuracy: 0.7156 - val_loss: 14.3043 - val_accuracy: 0.7385\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.1594 - accuracy: 0.7118 - val_loss: 14.0826 - val_accuracy: 0.7406\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.7298 - accuracy: 0.7187 - val_loss: 13.8703 - val_accuracy: 0.7427\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.3628 - accuracy: 0.7173 - val_loss: 13.6665 - val_accuracy: 0.7448\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.3967 - accuracy: 0.7175 - val_loss: 13.4698 - val_accuracy: 0.7468\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 16.2278 - accuracy: 0.7198 - val_loss: 13.2770 - val_accuracy: 0.7488\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1024 - accuracy: 0.7198 - val_loss: 13.0937 - val_accuracy: 0.7508\n",
      "Epoch 81/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.7399 - accuracy: 0.7237 - val_loss: 12.9170 - val_accuracy: 0.7528\n",
      "Epoch 82/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.9118 - accuracy: 0.7223 - val_loss: 12.7510 - val_accuracy: 0.7532\n",
      "Epoch 83/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.4878 - accuracy: 0.7279 - val_loss: 12.5898 - val_accuracy: 0.7536\n",
      "Epoch 84/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.3639 - accuracy: 0.7261 - val_loss: 12.4413 - val_accuracy: 0.7541\n",
      "Epoch 85/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.2179 - accuracy: 0.7285 - val_loss: 12.2961 - val_accuracy: 0.7545\n",
      "Epoch 86/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.2687 - accuracy: 0.7280 - val_loss: 12.1561 - val_accuracy: 0.7549\n",
      "Epoch 87/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.0512 - accuracy: 0.7259 - val_loss: 12.0244 - val_accuracy: 0.7553\n",
      "Epoch 88/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9379 - accuracy: 0.7283 - val_loss: 11.8955 - val_accuracy: 0.7557\n",
      "Epoch 89/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.6644 - accuracy: 0.7293 - val_loss: 11.7767 - val_accuracy: 0.7561\n",
      "Epoch 90/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.2888 - accuracy: 0.7294 - val_loss: 11.6584 - val_accuracy: 0.7565\n",
      "Epoch 91/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.4006 - accuracy: 0.7277 - val_loss: 11.5478 - val_accuracy: 0.7568\n",
      "Epoch 92/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.3383 - accuracy: 0.7272 - val_loss: 11.4427 - val_accuracy: 0.7572\n",
      "Epoch 93/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.1097 - accuracy: 0.7287 - val_loss: 11.3454 - val_accuracy: 0.7576\n",
      "Epoch 94/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.0597 - accuracy: 0.7315 - val_loss: 11.2481 - val_accuracy: 0.7579\n",
      "Epoch 95/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.1770 - accuracy: 0.7280 - val_loss: 11.1551 - val_accuracy: 0.7583\n",
      "Epoch 96/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.8736 - accuracy: 0.7263 - val_loss: 11.0701 - val_accuracy: 0.7586\n",
      "Epoch 97/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.8154 - accuracy: 0.7263 - val_loss: 10.9901 - val_accuracy: 0.7589\n",
      "Epoch 98/1000\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 13.4677 - accuracy: 0.7297 - val_loss: 10.9122 - val_accuracy: 0.7593\n",
      "Epoch 99/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 13.7105 - accuracy: 0.7239 - val_loss: 10.8407 - val_accuracy: 0.7596\n",
      "21/21 - 0s - loss: 10.8407 - accuracy: 0.7596 - 39ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 101.0933 - accuracy: 0.0314 - val_loss: 87.0672 - val_accuracy: 0.0863\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 87.1611 - accuracy: 0.1213 - val_loss: 74.0779 - val_accuracy: 0.2016\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 75.4322 - accuracy: 0.2086 - val_loss: 66.0028 - val_accuracy: 0.2528\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 68.8526 - accuracy: 0.2578 - val_loss: 61.9570 - val_accuracy: 0.2865\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65.7402 - accuracy: 0.2832 - val_loss: 59.4905 - val_accuracy: 0.3068\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 63.0346 - accuracy: 0.3029 - val_loss: 57.5524 - val_accuracy: 0.3228\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60.9549 - accuracy: 0.3198 - val_loss: 55.8608 - val_accuracy: 0.3368\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59.4508 - accuracy: 0.3322 - val_loss: 54.3004 - val_accuracy: 0.3498\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57.2791 - accuracy: 0.3468 - val_loss: 52.8142 - val_accuracy: 0.3624\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55.9852 - accuracy: 0.3595 - val_loss: 51.3774 - val_accuracy: 0.3747\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 54.5291 - accuracy: 0.3708 - val_loss: 49.9936 - val_accuracy: 0.3868\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 53.2382 - accuracy: 0.3818 - val_loss: 48.6420 - val_accuracy: 0.3988\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51.7797 - accuracy: 0.3932 - val_loss: 47.3240 - val_accuracy: 0.4107\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50.3589 - accuracy: 0.4046 - val_loss: 46.0362 - val_accuracy: 0.4226\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49.0611 - accuracy: 0.4170 - val_loss: 44.7726 - val_accuracy: 0.4344\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47.5470 - accuracy: 0.4270 - val_loss: 43.5420 - val_accuracy: 0.4461\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 46.3733 - accuracy: 0.4394 - val_loss: 42.3359 - val_accuracy: 0.4573\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45.1766 - accuracy: 0.4486 - val_loss: 41.1533 - val_accuracy: 0.4682\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.8859 - accuracy: 0.4609 - val_loss: 39.9981 - val_accuracy: 0.4790\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42.6327 - accuracy: 0.4718 - val_loss: 38.8582 - val_accuracy: 0.4899\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41.9529 - accuracy: 0.4792 - val_loss: 37.7494 - val_accuracy: 0.5007\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40.7130 - accuracy: 0.4898 - val_loss: 36.6568 - val_accuracy: 0.5116\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.4185 - accuracy: 0.5038 - val_loss: 35.5918 - val_accuracy: 0.5224\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 38.7607 - accuracy: 0.5125 - val_loss: 34.5407 - val_accuracy: 0.5333\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 37.4649 - accuracy: 0.5194 - val_loss: 33.5188 - val_accuracy: 0.5441\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 36.3485 - accuracy: 0.5313 - val_loss: 32.5135 - val_accuracy: 0.5549\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 35.3799 - accuracy: 0.5407 - val_loss: 31.5393 - val_accuracy: 0.5645\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 34.5282 - accuracy: 0.5503 - val_loss: 30.5738 - val_accuracy: 0.5742\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 33.4953 - accuracy: 0.5567 - val_loss: 29.6414 - val_accuracy: 0.5838\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 32.4857 - accuracy: 0.5679 - val_loss: 28.7261 - val_accuracy: 0.5934\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 31.4140 - accuracy: 0.5813 - val_loss: 27.8386 - val_accuracy: 0.6030\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.5119 - accuracy: 0.5884 - val_loss: 26.9695 - val_accuracy: 0.6126\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.6190 - accuracy: 0.5961 - val_loss: 26.1179 - val_accuracy: 0.6223\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 28.8388 - accuracy: 0.6045 - val_loss: 25.2922 - val_accuracy: 0.6319\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 28.1366 - accuracy: 0.6099 - val_loss: 24.4864 - val_accuracy: 0.6415\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.9851 - accuracy: 0.6214 - val_loss: 23.7006 - val_accuracy: 0.6499\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.7844 - accuracy: 0.6256 - val_loss: 22.9392 - val_accuracy: 0.6567\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.4359 - accuracy: 0.6377 - val_loss: 22.2012 - val_accuracy: 0.6634\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.1631 - accuracy: 0.6425 - val_loss: 21.4888 - val_accuracy: 0.6701\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 23.7579 - accuracy: 0.6568 - val_loss: 20.7888 - val_accuracy: 0.6769\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 23.3936 - accuracy: 0.6613 - val_loss: 20.1180 - val_accuracy: 0.6837\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.8122 - accuracy: 0.6638 - val_loss: 19.4593 - val_accuracy: 0.6905\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 22.1424 - accuracy: 0.6708 - val_loss: 18.8319 - val_accuracy: 0.6972\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.4272 - accuracy: 0.6781 - val_loss: 18.2206 - val_accuracy: 0.7039\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.8221 - accuracy: 0.6838 - val_loss: 17.6336 - val_accuracy: 0.7106\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.2492 - accuracy: 0.6895 - val_loss: 17.0679 - val_accuracy: 0.7155\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.5352 - accuracy: 0.6955 - val_loss: 16.5218 - val_accuracy: 0.7196\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.2785 - accuracy: 0.7014 - val_loss: 15.9978 - val_accuracy: 0.7238\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7773 - accuracy: 0.7033 - val_loss: 15.4975 - val_accuracy: 0.7279\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.7601 - accuracy: 0.7129 - val_loss: 15.0206 - val_accuracy: 0.7320\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.5594 - accuracy: 0.7109 - val_loss: 14.5651 - val_accuracy: 0.7361\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.0679 - accuracy: 0.7154 - val_loss: 14.1255 - val_accuracy: 0.7402\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 16.5315 - accuracy: 0.7185 - val_loss: 13.7125 - val_accuracy: 0.7443\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1870 - accuracy: 0.7202 - val_loss: 13.3221 - val_accuracy: 0.7483\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.9760 - accuracy: 0.7245 - val_loss: 12.9498 - val_accuracy: 0.7524\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.6578 - accuracy: 0.7228 - val_loss: 12.5924 - val_accuracy: 0.7536\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.2543 - accuracy: 0.7270 - val_loss: 12.2597 - val_accuracy: 0.7546\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.7966 - accuracy: 0.7288 - val_loss: 11.9576 - val_accuracy: 0.7555\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.4732 - accuracy: 0.7334 - val_loss: 11.6784 - val_accuracy: 0.7564\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.3219 - accuracy: 0.7273 - val_loss: 11.4084 - val_accuracy: 0.7573\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.8135 - accuracy: 0.7282 - val_loss: 11.1646 - val_accuracy: 0.7582\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.7766 - accuracy: 0.7275 - val_loss: 10.9408 - val_accuracy: 0.7592\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.5385 - accuracy: 0.7320 - val_loss: 10.7385 - val_accuracy: 0.7601\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.2163 - accuracy: 0.7331 - val_loss: 10.5560 - val_accuracy: 0.7609\n",
      "21/21 - 0s - loss: 10.5560 - accuracy: 0.7609 - 38ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 14ms/step - loss: 33.3071 - accuracy: 0.5825 - val_loss: 8.7442 - val_accuracy: 0.8203\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.7663 - accuracy: 0.7599 - val_loss: 6.8034 - val_accuracy: 0.8303\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7065 - accuracy: 0.7702 - val_loss: 6.3669 - val_accuracy: 0.8313\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7806 - accuracy: 0.7763 - val_loss: 6.3848 - val_accuracy: 0.8201\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9092 - accuracy: 0.7731 - val_loss: 6.2487 - val_accuracy: 0.8312\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3277 - accuracy: 0.7717 - val_loss: 6.2311 - val_accuracy: 0.8150\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4438 - accuracy: 0.7784 - val_loss: 5.9327 - val_accuracy: 0.8341\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3055 - accuracy: 0.7832 - val_loss: 5.6536 - val_accuracy: 0.8327\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5604 - accuracy: 0.7828 - val_loss: 5.4005 - val_accuracy: 0.8437\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9221 - accuracy: 0.7890 - val_loss: 5.5389 - val_accuracy: 0.8291\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0813 - accuracy: 0.7860 - val_loss: 5.4461 - val_accuracy: 0.8189\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7330 - accuracy: 0.7884 - val_loss: 5.0465 - val_accuracy: 0.8484\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.7636 - accuracy: 0.7913 - val_loss: 4.9164 - val_accuracy: 0.8503\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.2578 - accuracy: 0.7934 - val_loss: 4.8927 - val_accuracy: 0.8483\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.3484 - accuracy: 0.7969 - val_loss: 4.9050 - val_accuracy: 0.8428\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1978 - accuracy: 0.8020 - val_loss: 4.8979 - val_accuracy: 0.8406\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4000 - accuracy: 0.7947 - val_loss: 4.8076 - val_accuracy: 0.8446\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0620 - accuracy: 0.7982 - val_loss: 4.7544 - val_accuracy: 0.8484\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0919 - accuracy: 0.8007 - val_loss: 4.7504 - val_accuracy: 0.8501\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8078 - accuracy: 0.8035 - val_loss: 4.7415 - val_accuracy: 0.8423\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6527 - accuracy: 0.8052 - val_loss: 4.8048 - val_accuracy: 0.8501\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6138 - accuracy: 0.8059 - val_loss: 4.6846 - val_accuracy: 0.8415\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7200 - accuracy: 0.8076 - val_loss: 4.7267 - val_accuracy: 0.8382\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.6893 - accuracy: 0.8065 - val_loss: 4.6506 - val_accuracy: 0.8484\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.5559 - accuracy: 0.8078 - val_loss: 4.6440 - val_accuracy: 0.8413\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4851 - accuracy: 0.8071 - val_loss: 4.6642 - val_accuracy: 0.8523\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3648 - accuracy: 0.8116 - val_loss: 4.6085 - val_accuracy: 0.8435\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2820 - accuracy: 0.8134 - val_loss: 4.6338 - val_accuracy: 0.8376\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3770 - accuracy: 0.8096 - val_loss: 4.5980 - val_accuracy: 0.8461\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4047 - accuracy: 0.8120 - val_loss: 4.7151 - val_accuracy: 0.8319\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4589 - accuracy: 0.8106 - val_loss: 4.5084 - val_accuracy: 0.8472\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2261 - accuracy: 0.8151 - val_loss: 4.6904 - val_accuracy: 0.8500\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0968 - accuracy: 0.8164 - val_loss: 4.5309 - val_accuracy: 0.8388\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9685 - accuracy: 0.8179 - val_loss: 4.4532 - val_accuracy: 0.8462\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1798 - accuracy: 0.8153 - val_loss: 5.0473 - val_accuracy: 0.8060\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8408 - accuracy: 0.8195 - val_loss: 4.8068 - val_accuracy: 0.8171\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.0441 - accuracy: 0.8174 - val_loss: 4.3985 - val_accuracy: 0.8526\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.8830 - accuracy: 0.8195 - val_loss: 4.4854 - val_accuracy: 0.8490\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8049 - accuracy: 0.8206 - val_loss: 4.4610 - val_accuracy: 0.8401\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1842 - accuracy: 0.8145 - val_loss: 4.4077 - val_accuracy: 0.8473\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7817 - accuracy: 0.8211 - val_loss: 4.3686 - val_accuracy: 0.8553\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8906 - accuracy: 0.8160 - val_loss: 4.6774 - val_accuracy: 0.8325\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9407 - accuracy: 0.8186 - val_loss: 4.5508 - val_accuracy: 0.8400\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7106 - accuracy: 0.8196 - val_loss: 4.3822 - val_accuracy: 0.8451\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9803 - accuracy: 0.8185 - val_loss: 4.3572 - val_accuracy: 0.8455\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8732 - accuracy: 0.8217 - val_loss: 4.3579 - val_accuracy: 0.8500\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8972 - accuracy: 0.8188 - val_loss: 4.3279 - val_accuracy: 0.8521\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7304 - accuracy: 0.8213 - val_loss: 4.4918 - val_accuracy: 0.8546\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.5536 - accuracy: 0.8221 - val_loss: 4.4342 - val_accuracy: 0.8501\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9685 - accuracy: 0.8195 - val_loss: 4.3449 - val_accuracy: 0.8445\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.5129 - accuracy: 0.8269 - val_loss: 4.4251 - val_accuracy: 0.8557\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7704 - accuracy: 0.8202 - val_loss: 4.4482 - val_accuracy: 0.8370\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6350 - accuracy: 0.8228 - val_loss: 4.3936 - val_accuracy: 0.8550\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6925 - accuracy: 0.8231 - val_loss: 4.4897 - val_accuracy: 0.8328\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.4443 - accuracy: 0.8264 - val_loss: 4.3436 - val_accuracy: 0.8499\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6290 - accuracy: 0.8230 - val_loss: 4.4263 - val_accuracy: 0.8384\n",
      "21/21 - 0s - loss: 4.4263 - accuracy: 0.8384 - 39ms/epoch - 2ms/step\n",
      "Best hyperparameters: {'activation': 'relu', 'batch_size': 128, 'optimizer': 'adam'}\n",
      "Best validation accuracy: 0.8581386208534241\n"
     ]
    }
   ],
   "source": [
    "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용)\n",
    "act_func = ['relu', 'tanh']\n",
    "batch_lst = [8, 16, 32, 64, 128]\n",
    "opt_lst = ['adam', 'rmsprop', 'sgd']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            # 모델 구현\n",
    "            model = Sequential()\n",
    "            model.add(Dense(64, activation=func, input_dim=x.shape[1]))\n",
    "            model.add(Dropout(0.1))  # Dropout 추가\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(Dropout(0.1))  # Dropout 추가               \n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dropout(0.1))  # Dropout 추가\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dropout(0.1))  # Dropout 추가\n",
    "            model.add(Dense(4, activation=func))\n",
    "            model.add(Dropout(0.1))  # Dropout 추가\n",
    "            model.add(Dense(1, activation='linear'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(loss='mse', optimizer=opti, metrics=[accuracy])\n",
    "\n",
    "            # early stopping 구현 - 커스텀 정확도 기준\n",
    "            early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'optimizer': opti}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "334/334 [==============================] - 2s 2ms/step - loss: 18.6853 - accuracy: 0.7046 - val_loss: 5.0992 - val_accuracy: 0.8370\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.1359 - accuracy: 0.8382 - val_loss: 5.2181 - val_accuracy: 0.8197\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.0109 - accuracy: 0.8408 - val_loss: 5.0025 - val_accuracy: 0.8310\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8810 - accuracy: 0.8411 - val_loss: 4.6525 - val_accuracy: 0.8431\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8224 - accuracy: 0.8434 - val_loss: 4.5981 - val_accuracy: 0.8486\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7843 - accuracy: 0.8423 - val_loss: 4.8164 - val_accuracy: 0.8281\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6960 - accuracy: 0.8480 - val_loss: 4.8386 - val_accuracy: 0.8294\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6808 - accuracy: 0.8460 - val_loss: 4.9789 - val_accuracy: 0.8360\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6979 - accuracy: 0.8447 - val_loss: 4.4701 - val_accuracy: 0.8499\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7155 - accuracy: 0.8454 - val_loss: 5.1075 - val_accuracy: 0.8168\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6486 - accuracy: 0.8460 - val_loss: 4.8815 - val_accuracy: 0.8206\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6754 - accuracy: 0.8451 - val_loss: 4.5009 - val_accuracy: 0.8511\n",
      "21/21 - 0s - loss: 4.5009 - accuracy: 0.8511 - 39ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 24.0886 - accuracy: 0.6624 - val_loss: 5.7785 - val_accuracy: 0.8215\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3864 - accuracy: 0.8330 - val_loss: 5.2247 - val_accuracy: 0.8089\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.1316 - accuracy: 0.8378 - val_loss: 4.6639 - val_accuracy: 0.8434\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9265 - accuracy: 0.8401 - val_loss: 4.8849 - val_accuracy: 0.8246\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8602 - accuracy: 0.8417 - val_loss: 4.5495 - val_accuracy: 0.8512\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7817 - accuracy: 0.8432 - val_loss: 4.7108 - val_accuracy: 0.8299\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7306 - accuracy: 0.8438 - val_loss: 4.6018 - val_accuracy: 0.8465\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6948 - accuracy: 0.8449 - val_loss: 4.6870 - val_accuracy: 0.8234\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6406 - accuracy: 0.8445 - val_loss: 4.6170 - val_accuracy: 0.8406\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6430 - accuracy: 0.8443 - val_loss: 4.4452 - val_accuracy: 0.8492\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5647 - accuracy: 0.8467 - val_loss: 4.5096 - val_accuracy: 0.8485\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5897 - accuracy: 0.8474 - val_loss: 4.5767 - val_accuracy: 0.8365\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5668 - accuracy: 0.8465 - val_loss: 4.4447 - val_accuracy: 0.8510\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5396 - accuracy: 0.8480 - val_loss: 4.6108 - val_accuracy: 0.8287\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5328 - accuracy: 0.8484 - val_loss: 4.6379 - val_accuracy: 0.8379\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4699 - accuracy: 0.8497 - val_loss: 4.5080 - val_accuracy: 0.8398\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4608 - accuracy: 0.8491 - val_loss: 4.4511 - val_accuracy: 0.8442\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4303 - accuracy: 0.8499 - val_loss: 4.7718 - val_accuracy: 0.8269\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4411 - accuracy: 0.8490 - val_loss: 4.6316 - val_accuracy: 0.8307\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4421 - accuracy: 0.8496 - val_loss: 4.4186 - val_accuracy: 0.8503\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4433 - accuracy: 0.8505 - val_loss: 4.6950 - val_accuracy: 0.8245\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4142 - accuracy: 0.8505 - val_loss: 4.4353 - val_accuracy: 0.8540\n",
      "Epoch 23/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3792 - accuracy: 0.8503 - val_loss: 4.4914 - val_accuracy: 0.8475\n",
      "Epoch 24/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4282 - accuracy: 0.8507 - val_loss: 4.5700 - val_accuracy: 0.8328\n",
      "Epoch 25/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3503 - accuracy: 0.8513 - val_loss: 5.3838 - val_accuracy: 0.8098\n",
      "Epoch 26/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3032 - accuracy: 0.8515 - val_loss: 4.5272 - val_accuracy: 0.8385\n",
      "Epoch 27/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2872 - accuracy: 0.8514 - val_loss: 4.6909 - val_accuracy: 0.8273\n",
      "Epoch 28/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3421 - accuracy: 0.8504 - val_loss: 4.3797 - val_accuracy: 0.8486\n",
      "Epoch 29/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3070 - accuracy: 0.8515 - val_loss: 4.8433 - val_accuracy: 0.8260\n",
      "Epoch 30/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2884 - accuracy: 0.8522 - val_loss: 4.4760 - val_accuracy: 0.8399\n",
      "Epoch 31/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2967 - accuracy: 0.8507 - val_loss: 4.8525 - val_accuracy: 0.8190\n",
      "Epoch 32/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2904 - accuracy: 0.8503 - val_loss: 4.5238 - val_accuracy: 0.8516\n",
      "Epoch 33/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2384 - accuracy: 0.8515 - val_loss: 4.3680 - val_accuracy: 0.8457\n",
      "Epoch 34/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2773 - accuracy: 0.8529 - val_loss: 4.5667 - val_accuracy: 0.8555\n",
      "Epoch 35/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2577 - accuracy: 0.8520 - val_loss: 4.6386 - val_accuracy: 0.8424\n",
      "Epoch 36/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1915 - accuracy: 0.8532 - val_loss: 5.2971 - val_accuracy: 0.8110\n",
      "Epoch 37/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2799 - accuracy: 0.8523 - val_loss: 5.2361 - val_accuracy: 0.8190\n",
      "Epoch 38/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2486 - accuracy: 0.8518 - val_loss: 4.8247 - val_accuracy: 0.8272\n",
      "Epoch 39/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1947 - accuracy: 0.8538 - val_loss: 4.7246 - val_accuracy: 0.8300\n",
      "Epoch 40/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2318 - accuracy: 0.8528 - val_loss: 4.3539 - val_accuracy: 0.8425\n",
      "Epoch 41/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2025 - accuracy: 0.8531 - val_loss: 4.3799 - val_accuracy: 0.8474\n",
      "Epoch 42/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2040 - accuracy: 0.8535 - val_loss: 4.8745 - val_accuracy: 0.8246\n",
      "Epoch 43/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1861 - accuracy: 0.8539 - val_loss: 4.3846 - val_accuracy: 0.8430\n",
      "Epoch 44/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1939 - accuracy: 0.8537 - val_loss: 4.4253 - val_accuracy: 0.8439\n",
      "Epoch 45/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2038 - accuracy: 0.8533 - val_loss: 4.3404 - val_accuracy: 0.8469\n",
      "Epoch 46/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2096 - accuracy: 0.8543 - val_loss: 4.4197 - val_accuracy: 0.8486\n",
      "Epoch 47/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1280 - accuracy: 0.8550 - val_loss: 4.7639 - val_accuracy: 0.8242\n",
      "Epoch 48/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1819 - accuracy: 0.8542 - val_loss: 4.6619 - val_accuracy: 0.8380\n",
      "Epoch 49/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1161 - accuracy: 0.8550 - val_loss: 4.4532 - val_accuracy: 0.8373\n",
      "Epoch 50/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1376 - accuracy: 0.8553 - val_loss: 4.5041 - val_accuracy: 0.8515\n",
      "Epoch 51/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1350 - accuracy: 0.8551 - val_loss: 4.4905 - val_accuracy: 0.8392\n",
      "Epoch 52/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1400 - accuracy: 0.8547 - val_loss: 4.7220 - val_accuracy: 0.8297\n",
      "Epoch 53/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1230 - accuracy: 0.8547 - val_loss: 4.6451 - val_accuracy: 0.8349\n",
      "Epoch 54/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1379 - accuracy: 0.8538 - val_loss: 4.3444 - val_accuracy: 0.8537\n",
      "Epoch 55/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.0843 - accuracy: 0.8551 - val_loss: 4.5508 - val_accuracy: 0.8505\n",
      "21/21 - 0s - loss: 4.5508 - accuracy: 0.8505 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.3449 - accuracy: 0.7921 - val_loss: 5.3990 - val_accuracy: 0.8182\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5474 - accuracy: 0.8302 - val_loss: 5.0017 - val_accuracy: 0.8277\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.4108 - accuracy: 0.8305 - val_loss: 5.7493 - val_accuracy: 0.8195\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6400 - accuracy: 0.8255 - val_loss: 4.9778 - val_accuracy: 0.8512\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2653 - accuracy: 0.8305 - val_loss: 7.3214 - val_accuracy: 0.7292\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3111 - accuracy: 0.8324 - val_loss: 5.0915 - val_accuracy: 0.8060\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.0856 - accuracy: 0.8345 - val_loss: 4.3639 - val_accuracy: 0.8455\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.4693 - accuracy: 0.8267 - val_loss: 4.7826 - val_accuracy: 0.8529\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.0432 - accuracy: 0.8348 - val_loss: 5.5047 - val_accuracy: 0.8242\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2071 - accuracy: 0.8335 - val_loss: 4.6698 - val_accuracy: 0.8542\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9610 - accuracy: 0.8386 - val_loss: 5.7869 - val_accuracy: 0.7732\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9717 - accuracy: 0.8392 - val_loss: 4.4400 - val_accuracy: 0.8558\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9598 - accuracy: 0.8382 - val_loss: 4.5905 - val_accuracy: 0.8477\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9921 - accuracy: 0.8392 - val_loss: 4.5994 - val_accuracy: 0.8588\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9160 - accuracy: 0.8383 - val_loss: 5.0001 - val_accuracy: 0.8115\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8054 - accuracy: 0.8404 - val_loss: 4.8825 - val_accuracy: 0.8309\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8076 - accuracy: 0.8398 - val_loss: 4.4409 - val_accuracy: 0.8453\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7416 - accuracy: 0.8413 - val_loss: 4.6312 - val_accuracy: 0.8292\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 4.6755 - accuracy: 0.8423 - val_loss: 5.4609 - val_accuracy: 0.8010\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8148 - accuracy: 0.8402 - val_loss: 4.3629 - val_accuracy: 0.8542\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 4.5460 - accuracy: 0.8445 - val_loss: 4.6890 - val_accuracy: 0.8391\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7484 - accuracy: 0.8426 - val_loss: 4.3953 - val_accuracy: 0.8502\n",
      "Epoch 23/1000\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 4.6095 - accuracy: 0.8425 - val_loss: 4.5582 - val_accuracy: 0.8514\n",
      "Epoch 24/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6107 - accuracy: 0.8428 - val_loss: 5.3762 - val_accuracy: 0.8335\n",
      "Epoch 25/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6198 - accuracy: 0.8422 - val_loss: 4.5856 - val_accuracy: 0.8459\n",
      "Epoch 26/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6503 - accuracy: 0.8440 - val_loss: 4.5892 - val_accuracy: 0.8279\n",
      "21/21 - 0s - loss: 4.5892 - accuracy: 0.8279 - 40ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 2s 3ms/step - loss: 31.1135 - accuracy: 0.5804 - val_loss: 5.7559 - val_accuracy: 0.8191\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.4787 - accuracy: 0.8314 - val_loss: 4.8525 - val_accuracy: 0.8430\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0121 - accuracy: 0.8378 - val_loss: 4.6724 - val_accuracy: 0.8473\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.8536 - accuracy: 0.8421 - val_loss: 4.5852 - val_accuracy: 0.8426\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.8656 - accuracy: 0.8428 - val_loss: 4.6591 - val_accuracy: 0.8363\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6795 - accuracy: 0.8440 - val_loss: 5.0636 - val_accuracy: 0.8235\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6690 - accuracy: 0.8455 - val_loss: 5.5780 - val_accuracy: 0.8086\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6691 - accuracy: 0.8452 - val_loss: 4.7828 - val_accuracy: 0.8265\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6061 - accuracy: 0.8475 - val_loss: 4.9126 - val_accuracy: 0.8244\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5869 - accuracy: 0.8468 - val_loss: 4.5665 - val_accuracy: 0.8342\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 4.5284 - accuracy: 0.8476 - val_loss: 4.6920 - val_accuracy: 0.8550\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4952 - accuracy: 0.8480 - val_loss: 4.8089 - val_accuracy: 0.8401\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4661 - accuracy: 0.8509 - val_loss: 4.7748 - val_accuracy: 0.8354\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4532 - accuracy: 0.8486 - val_loss: 4.6942 - val_accuracy: 0.8322\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3907 - accuracy: 0.8525 - val_loss: 4.8856 - val_accuracy: 0.8323\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4106 - accuracy: 0.8509 - val_loss: 4.4687 - val_accuracy: 0.8447\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4622 - accuracy: 0.8502 - val_loss: 4.7279 - val_accuracy: 0.8302\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4180 - accuracy: 0.8499 - val_loss: 4.4836 - val_accuracy: 0.8412\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3929 - accuracy: 0.8522 - val_loss: 4.4408 - val_accuracy: 0.8481\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4489 - accuracy: 0.8502 - val_loss: 4.5061 - val_accuracy: 0.8485\n",
      "21/21 - 0s - loss: 4.5061 - accuracy: 0.8485 - 45ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 2ms/step - loss: 34.9731 - accuracy: 0.5411 - val_loss: 9.2808 - val_accuracy: 0.7484\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.0519 - accuracy: 0.8228 - val_loss: 5.1624 - val_accuracy: 0.8305\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.1053 - accuracy: 0.8368 - val_loss: 4.8969 - val_accuracy: 0.8275\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.9110 - accuracy: 0.8411 - val_loss: 4.7860 - val_accuracy: 0.8336\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7980 - accuracy: 0.8433 - val_loss: 4.6909 - val_accuracy: 0.8523\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7709 - accuracy: 0.8443 - val_loss: 4.6280 - val_accuracy: 0.8445\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7264 - accuracy: 0.8443 - val_loss: 4.9277 - val_accuracy: 0.8168\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6605 - accuracy: 0.8462 - val_loss: 5.1358 - val_accuracy: 0.8157\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6770 - accuracy: 0.8468 - val_loss: 4.5519 - val_accuracy: 0.8480\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6418 - accuracy: 0.8469 - val_loss: 4.6895 - val_accuracy: 0.8350\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6275 - accuracy: 0.8476 - val_loss: 4.6219 - val_accuracy: 0.8306\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5619 - accuracy: 0.8475 - val_loss: 4.6653 - val_accuracy: 0.8398\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5479 - accuracy: 0.8469 - val_loss: 4.5343 - val_accuracy: 0.8539\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5245 - accuracy: 0.8485 - val_loss: 4.5120 - val_accuracy: 0.8488\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5325 - accuracy: 0.8479 - val_loss: 4.5045 - val_accuracy: 0.8536\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4857 - accuracy: 0.8494 - val_loss: 4.4890 - val_accuracy: 0.8517\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4395 - accuracy: 0.8499 - val_loss: 4.5219 - val_accuracy: 0.8369\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4451 - accuracy: 0.8500 - val_loss: 4.5249 - val_accuracy: 0.8410\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4502 - accuracy: 0.8495 - val_loss: 4.5588 - val_accuracy: 0.8553\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4319 - accuracy: 0.8504 - val_loss: 4.5944 - val_accuracy: 0.8406\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4716 - accuracy: 0.8508 - val_loss: 4.8487 - val_accuracy: 0.8197\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3940 - accuracy: 0.8512 - val_loss: 4.7038 - val_accuracy: 0.8303\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3607 - accuracy: 0.8508 - val_loss: 4.5277 - val_accuracy: 0.8434\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3979 - accuracy: 0.8505 - val_loss: 4.5497 - val_accuracy: 0.8379\n",
      "Epoch 25/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3856 - accuracy: 0.8510 - val_loss: 4.4266 - val_accuracy: 0.8428\n",
      "Epoch 26/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3846 - accuracy: 0.8522 - val_loss: 4.3241 - val_accuracy: 0.8475\n",
      "Epoch 27/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3681 - accuracy: 0.8512 - val_loss: 4.3231 - val_accuracy: 0.8514\n",
      "Epoch 28/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3811 - accuracy: 0.8531 - val_loss: 4.4743 - val_accuracy: 0.8353\n",
      "Epoch 29/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3381 - accuracy: 0.8520 - val_loss: 4.3802 - val_accuracy: 0.8506\n",
      "Epoch 30/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3356 - accuracy: 0.8520 - val_loss: 4.4121 - val_accuracy: 0.8507\n",
      "Epoch 31/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3569 - accuracy: 0.8504 - val_loss: 4.4206 - val_accuracy: 0.8553\n",
      "Epoch 32/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3171 - accuracy: 0.8526 - val_loss: 4.4218 - val_accuracy: 0.8431\n",
      "Epoch 33/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3200 - accuracy: 0.8529 - val_loss: 4.3992 - val_accuracy: 0.8460\n",
      "21/21 - 0s - loss: 4.3992 - accuracy: 0.8460 - 57ms/epoch - 3ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 19.1751 - accuracy: 0.7034 - val_loss: 6.2040 - val_accuracy: 0.7753\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.2951 - accuracy: 0.8340 - val_loss: 5.0147 - val_accuracy: 0.8134\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 5.0168 - accuracy: 0.8384 - val_loss: 4.8430 - val_accuracy: 0.8170\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.9985 - accuracy: 0.8405 - val_loss: 4.7699 - val_accuracy: 0.8548\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0375 - accuracy: 0.8386 - val_loss: 4.4597 - val_accuracy: 0.8515\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7330 - accuracy: 0.8442 - val_loss: 4.5079 - val_accuracy: 0.8507\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.8078 - accuracy: 0.8427 - val_loss: 4.7498 - val_accuracy: 0.8208\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7027 - accuracy: 0.8451 - val_loss: 4.5023 - val_accuracy: 0.8443\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5590 - accuracy: 0.8445 - val_loss: 4.6202 - val_accuracy: 0.8315\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5403 - accuracy: 0.8459 - val_loss: 4.8638 - val_accuracy: 0.8539\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6400 - accuracy: 0.8446 - val_loss: 4.7148 - val_accuracy: 0.8301\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5968 - accuracy: 0.8448 - val_loss: 4.5667 - val_accuracy: 0.8576\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5508 - accuracy: 0.8463 - val_loss: 4.4301 - val_accuracy: 0.8547\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 4.5502 - accuracy: 0.8465 - val_loss: 4.3515 - val_accuracy: 0.8507\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5150 - accuracy: 0.8482 - val_loss: 4.4951 - val_accuracy: 0.8366\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5368 - accuracy: 0.8460 - val_loss: 4.3311 - val_accuracy: 0.8496\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4847 - accuracy: 0.8486 - val_loss: 4.4591 - val_accuracy: 0.8421\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4139 - accuracy: 0.8491 - val_loss: 4.6000 - val_accuracy: 0.8282\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4352 - accuracy: 0.8478 - val_loss: 4.3681 - val_accuracy: 0.8547\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5776 - accuracy: 0.8468 - val_loss: 4.2244 - val_accuracy: 0.8521\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5003 - accuracy: 0.8465 - val_loss: 4.4491 - val_accuracy: 0.8370\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4320 - accuracy: 0.8487 - val_loss: 4.3547 - val_accuracy: 0.8560\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3744 - accuracy: 0.8488 - val_loss: 4.3845 - val_accuracy: 0.8477\n",
      "21/21 - 0s - loss: 4.3845 - accuracy: 0.8477 - 40ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 52.4122 - accuracy: 0.3968 - val_loss: 13.4720 - val_accuracy: 0.7240\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4244 - accuracy: 0.7884 - val_loss: 5.7292 - val_accuracy: 0.8277\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5918 - accuracy: 0.8285 - val_loss: 5.0734 - val_accuracy: 0.8378\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1571 - accuracy: 0.8376 - val_loss: 5.2934 - val_accuracy: 0.8223\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0031 - accuracy: 0.8391 - val_loss: 4.9102 - val_accuracy: 0.8287\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8695 - accuracy: 0.8407 - val_loss: 4.7633 - val_accuracy: 0.8405\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7701 - accuracy: 0.8448 - val_loss: 4.6828 - val_accuracy: 0.8342\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7123 - accuracy: 0.8435 - val_loss: 4.6804 - val_accuracy: 0.8396\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7347 - accuracy: 0.8448 - val_loss: 4.6192 - val_accuracy: 0.8369\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6689 - accuracy: 0.8453 - val_loss: 4.8528 - val_accuracy: 0.8314\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7078 - accuracy: 0.8448 - val_loss: 4.5803 - val_accuracy: 0.8440\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6234 - accuracy: 0.8468 - val_loss: 4.8117 - val_accuracy: 0.8292\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5742 - accuracy: 0.8476 - val_loss: 4.6018 - val_accuracy: 0.8414\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5634 - accuracy: 0.8477 - val_loss: 4.5429 - val_accuracy: 0.8430\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5649 - accuracy: 0.8480 - val_loss: 4.5309 - val_accuracy: 0.8489\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4947 - accuracy: 0.8499 - val_loss: 4.5134 - val_accuracy: 0.8447\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5362 - accuracy: 0.8492 - val_loss: 4.4860 - val_accuracy: 0.8399\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5052 - accuracy: 0.8485 - val_loss: 4.4944 - val_accuracy: 0.8482\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5237 - accuracy: 0.8481 - val_loss: 4.6465 - val_accuracy: 0.8525\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4566 - accuracy: 0.8505 - val_loss: 4.4461 - val_accuracy: 0.8441\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4159 - accuracy: 0.8497 - val_loss: 4.6511 - val_accuracy: 0.8356\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4029 - accuracy: 0.8505 - val_loss: 4.4372 - val_accuracy: 0.8434\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4109 - accuracy: 0.8504 - val_loss: 4.6291 - val_accuracy: 0.8456\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3654 - accuracy: 0.8518 - val_loss: 4.5268 - val_accuracy: 0.8427\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4035 - accuracy: 0.8494 - val_loss: 4.5355 - val_accuracy: 0.8400\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4134 - accuracy: 0.8503 - val_loss: 4.4798 - val_accuracy: 0.8410\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3928 - accuracy: 0.8507 - val_loss: 4.4126 - val_accuracy: 0.8523\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3379 - accuracy: 0.8515 - val_loss: 4.4396 - val_accuracy: 0.8484\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4272 - accuracy: 0.8506 - val_loss: 4.4656 - val_accuracy: 0.8542\n",
      "21/21 - 0s - loss: 4.4656 - accuracy: 0.8542 - 56ms/epoch - 3ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 5ms/step - loss: 36.4011 - accuracy: 0.5262 - val_loss: 9.0295 - val_accuracy: 0.7650\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 6.2936 - accuracy: 0.8208 - val_loss: 5.2335 - val_accuracy: 0.8475\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1958 - accuracy: 0.8378 - val_loss: 4.8635 - val_accuracy: 0.8388\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9931 - accuracy: 0.8397 - val_loss: 5.7654 - val_accuracy: 0.7867\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8668 - accuracy: 0.8415 - val_loss: 4.6070 - val_accuracy: 0.8435\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7665 - accuracy: 0.8441 - val_loss: 4.6438 - val_accuracy: 0.8394\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7370 - accuracy: 0.8440 - val_loss: 4.7536 - val_accuracy: 0.8361\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7031 - accuracy: 0.8453 - val_loss: 5.0991 - val_accuracy: 0.8157\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6203 - accuracy: 0.8468 - val_loss: 5.3418 - val_accuracy: 0.8212\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6075 - accuracy: 0.8459 - val_loss: 4.5848 - val_accuracy: 0.8541\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5922 - accuracy: 0.8479 - val_loss: 4.4323 - val_accuracy: 0.8476\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5112 - accuracy: 0.8493 - val_loss: 4.4889 - val_accuracy: 0.8485\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5259 - accuracy: 0.8483 - val_loss: 4.5543 - val_accuracy: 0.8371\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4657 - accuracy: 0.8501 - val_loss: 4.5343 - val_accuracy: 0.8462\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4593 - accuracy: 0.8492 - val_loss: 4.4697 - val_accuracy: 0.8517\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4876 - accuracy: 0.8489 - val_loss: 4.6872 - val_accuracy: 0.8341\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4252 - accuracy: 0.8503 - val_loss: 4.5614 - val_accuracy: 0.8571\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4198 - accuracy: 0.8507 - val_loss: 4.4041 - val_accuracy: 0.8493\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3929 - accuracy: 0.8504 - val_loss: 5.2646 - val_accuracy: 0.7992\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4138 - accuracy: 0.8498 - val_loss: 4.3703 - val_accuracy: 0.8464\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3954 - accuracy: 0.8511 - val_loss: 4.5215 - val_accuracy: 0.8330\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3880 - accuracy: 0.8501 - val_loss: 4.3844 - val_accuracy: 0.8455\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3551 - accuracy: 0.8531 - val_loss: 5.0933 - val_accuracy: 0.8104\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3594 - accuracy: 0.8513 - val_loss: 4.7847 - val_accuracy: 0.8165\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3149 - accuracy: 0.8520 - val_loss: 5.0091 - val_accuracy: 0.8281\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3513 - accuracy: 0.8521 - val_loss: 4.3793 - val_accuracy: 0.8477\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2934 - accuracy: 0.8525 - val_loss: 4.6058 - val_accuracy: 0.8422\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2839 - accuracy: 0.8521 - val_loss: 4.3528 - val_accuracy: 0.8485\n",
      "21/21 - 0s - loss: 4.3528 - accuracy: 0.8485 - 71ms/epoch - 3ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 28.7533 - accuracy: 0.6121 - val_loss: 11.7130 - val_accuracy: 0.7833\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.9891 - accuracy: 0.8230 - val_loss: 4.9476 - val_accuracy: 0.8470\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5173 - accuracy: 0.8344 - val_loss: 6.0651 - val_accuracy: 0.8003\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0017 - accuracy: 0.8405 - val_loss: 4.6875 - val_accuracy: 0.8537\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8328 - accuracy: 0.8446 - val_loss: 5.1873 - val_accuracy: 0.8336\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8324 - accuracy: 0.8450 - val_loss: 4.5253 - val_accuracy: 0.8466\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7488 - accuracy: 0.8452 - val_loss: 6.6328 - val_accuracy: 0.7837\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7391 - accuracy: 0.8451 - val_loss: 4.5586 - val_accuracy: 0.8585\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6670 - accuracy: 0.8466 - val_loss: 4.3938 - val_accuracy: 0.8486\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6287 - accuracy: 0.8477 - val_loss: 4.6135 - val_accuracy: 0.8306\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5955 - accuracy: 0.8486 - val_loss: 4.4760 - val_accuracy: 0.8443\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5005 - accuracy: 0.8497 - val_loss: 4.3720 - val_accuracy: 0.8586\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5369 - accuracy: 0.8492 - val_loss: 4.4194 - val_accuracy: 0.8421\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4886 - accuracy: 0.8508 - val_loss: 6.0989 - val_accuracy: 0.7720\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5329 - accuracy: 0.8482 - val_loss: 4.4191 - val_accuracy: 0.8542\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4241 - accuracy: 0.8524 - val_loss: 4.6631 - val_accuracy: 0.8360\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5892 - accuracy: 0.8472 - val_loss: 4.2216 - val_accuracy: 0.8538\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4737 - accuracy: 0.8508 - val_loss: 4.4570 - val_accuracy: 0.8423\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3803 - accuracy: 0.8510 - val_loss: 4.6086 - val_accuracy: 0.8517\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4370 - accuracy: 0.8503 - val_loss: 4.8641 - val_accuracy: 0.8193\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3817 - accuracy: 0.8512 - val_loss: 4.4180 - val_accuracy: 0.8538\n",
      "21/21 - 0s - loss: 4.4180 - accuracy: 0.8538 - 51ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 7ms/step - loss: 86.0810 - accuracy: 0.1490 - val_loss: 42.8116 - val_accuracy: 0.4472\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 23.0648 - accuracy: 0.6132 - val_loss: 12.2869 - val_accuracy: 0.7342\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 9.4296 - accuracy: 0.7666 - val_loss: 6.5959 - val_accuracy: 0.8125\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.0808 - accuracy: 0.8230 - val_loss: 5.2355 - val_accuracy: 0.8374\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.4099 - accuracy: 0.8334 - val_loss: 5.0860 - val_accuracy: 0.8347\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.1626 - accuracy: 0.8377 - val_loss: 4.8315 - val_accuracy: 0.8411\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.9953 - accuracy: 0.8397 - val_loss: 4.8999 - val_accuracy: 0.8318\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.9040 - accuracy: 0.8436 - val_loss: 4.6668 - val_accuracy: 0.8414\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.8145 - accuracy: 0.8423 - val_loss: 4.6864 - val_accuracy: 0.8408\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.7607 - accuracy: 0.8444 - val_loss: 4.7670 - val_accuracy: 0.8367\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6987 - accuracy: 0.8450 - val_loss: 4.6616 - val_accuracy: 0.8403\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6560 - accuracy: 0.8467 - val_loss: 4.5328 - val_accuracy: 0.8497\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6077 - accuracy: 0.8465 - val_loss: 4.5766 - val_accuracy: 0.8444\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5559 - accuracy: 0.8485 - val_loss: 4.5268 - val_accuracy: 0.8506\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6089 - accuracy: 0.8461 - val_loss: 4.5308 - val_accuracy: 0.8508\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5168 - accuracy: 0.8491 - val_loss: 4.9046 - val_accuracy: 0.8233\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 4.5519 - accuracy: 0.8478 - val_loss: 4.8839 - val_accuracy: 0.8236\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5065 - accuracy: 0.8486 - val_loss: 4.5088 - val_accuracy: 0.8431\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4985 - accuracy: 0.8481 - val_loss: 4.5076 - val_accuracy: 0.8513\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4670 - accuracy: 0.8500 - val_loss: 4.5971 - val_accuracy: 0.8418\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4458 - accuracy: 0.8480 - val_loss: 4.6236 - val_accuracy: 0.8519\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5296 - accuracy: 0.8476 - val_loss: 4.5086 - val_accuracy: 0.8456\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4945 - accuracy: 0.8490 - val_loss: 4.6458 - val_accuracy: 0.8355\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3922 - accuracy: 0.8496 - val_loss: 4.4449 - val_accuracy: 0.8491\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4403 - accuracy: 0.8502 - val_loss: 4.4829 - val_accuracy: 0.8482\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3642 - accuracy: 0.8510 - val_loss: 4.6437 - val_accuracy: 0.8399\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3866 - accuracy: 0.8512 - val_loss: 4.4586 - val_accuracy: 0.8473\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3828 - accuracy: 0.8502 - val_loss: 4.5068 - val_accuracy: 0.8485\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3396 - accuracy: 0.8527 - val_loss: 4.5957 - val_accuracy: 0.8372\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.3804 - accuracy: 0.8503 - val_loss: 4.6085 - val_accuracy: 0.8524\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.3907 - accuracy: 0.8527 - val_loss: 4.4358 - val_accuracy: 0.8457\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3250 - accuracy: 0.8532 - val_loss: 4.4831 - val_accuracy: 0.8403\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3103 - accuracy: 0.8528 - val_loss: 4.5127 - val_accuracy: 0.8372\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2954 - accuracy: 0.8527 - val_loss: 4.5699 - val_accuracy: 0.8327\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3297 - accuracy: 0.8519 - val_loss: 4.4602 - val_accuracy: 0.8436\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3017 - accuracy: 0.8541 - val_loss: 4.5137 - val_accuracy: 0.8419\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2846 - accuracy: 0.8525 - val_loss: 4.4264 - val_accuracy: 0.8462\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.2971 - accuracy: 0.8516 - val_loss: 4.4008 - val_accuracy: 0.8513\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2665 - accuracy: 0.8539 - val_loss: 4.5857 - val_accuracy: 0.8395\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2703 - accuracy: 0.8531 - val_loss: 4.5808 - val_accuracy: 0.8303\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2898 - accuracy: 0.8512 - val_loss: 4.4934 - val_accuracy: 0.8428\n",
      "21/21 - 0s - loss: 4.4934 - accuracy: 0.8428 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 89.0563 - accuracy: 0.1311 - val_loss: 52.5587 - val_accuracy: 0.3730\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 32.5588 - accuracy: 0.5274 - val_loss: 19.0497 - val_accuracy: 0.6495\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 15.0181 - accuracy: 0.6938 - val_loss: 9.6007 - val_accuracy: 0.7596\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.6319 - accuracy: 0.7948 - val_loss: 5.6884 - val_accuracy: 0.8386\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.6474 - accuracy: 0.8302 - val_loss: 5.1505 - val_accuracy: 0.8196\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.2869 - accuracy: 0.8342 - val_loss: 5.0231 - val_accuracy: 0.8281\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.1439 - accuracy: 0.8372 - val_loss: 4.8929 - val_accuracy: 0.8338\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.0076 - accuracy: 0.8397 - val_loss: 4.6779 - val_accuracy: 0.8383\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9600 - accuracy: 0.8409 - val_loss: 4.8048 - val_accuracy: 0.8302\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9399 - accuracy: 0.8402 - val_loss: 4.7323 - val_accuracy: 0.8539\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.8408 - accuracy: 0.8432 - val_loss: 4.7941 - val_accuracy: 0.8364\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.7916 - accuracy: 0.8432 - val_loss: 4.5924 - val_accuracy: 0.8478\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.7466 - accuracy: 0.8437 - val_loss: 4.5785 - val_accuracy: 0.8468\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.7368 - accuracy: 0.8446 - val_loss: 4.5753 - val_accuracy: 0.8496\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.7422 - accuracy: 0.8445 - val_loss: 4.6597 - val_accuracy: 0.8382\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 4.6880 - accuracy: 0.8443 - val_loss: 4.5793 - val_accuracy: 0.8497\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6779 - accuracy: 0.8460 - val_loss: 4.9789 - val_accuracy: 0.8159\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6916 - accuracy: 0.8449 - val_loss: 4.5613 - val_accuracy: 0.8427\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6433 - accuracy: 0.8453 - val_loss: 4.6204 - val_accuracy: 0.8397\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5820 - accuracy: 0.8465 - val_loss: 4.6144 - val_accuracy: 0.8538\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5855 - accuracy: 0.8468 - val_loss: 4.5352 - val_accuracy: 0.8517\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.6206 - accuracy: 0.8465 - val_loss: 5.0942 - val_accuracy: 0.8105\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5624 - accuracy: 0.8475 - val_loss: 4.5740 - val_accuracy: 0.8442\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5827 - accuracy: 0.8470 - val_loss: 4.6293 - val_accuracy: 0.8340\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5495 - accuracy: 0.8481 - val_loss: 4.5018 - val_accuracy: 0.8481\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5540 - accuracy: 0.8467 - val_loss: 4.5013 - val_accuracy: 0.8468\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5439 - accuracy: 0.8466 - val_loss: 4.6793 - val_accuracy: 0.8262\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5341 - accuracy: 0.8475 - val_loss: 4.6856 - val_accuracy: 0.8290\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4862 - accuracy: 0.8489 - val_loss: 4.6571 - val_accuracy: 0.8349\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5129 - accuracy: 0.8478 - val_loss: 4.4858 - val_accuracy: 0.8510\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4597 - accuracy: 0.8494 - val_loss: 4.4901 - val_accuracy: 0.8465\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5082 - accuracy: 0.8485 - val_loss: 4.6015 - val_accuracy: 0.8390\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4741 - accuracy: 0.8485 - val_loss: 4.4957 - val_accuracy: 0.8421\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4624 - accuracy: 0.8490 - val_loss: 4.4743 - val_accuracy: 0.8486\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4498 - accuracy: 0.8499 - val_loss: 4.4583 - val_accuracy: 0.8439\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4417 - accuracy: 0.8493 - val_loss: 4.4510 - val_accuracy: 0.8537\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4230 - accuracy: 0.8505 - val_loss: 4.5638 - val_accuracy: 0.8351\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4163 - accuracy: 0.8495 - val_loss: 4.5627 - val_accuracy: 0.8525\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.4366 - accuracy: 0.8499 - val_loss: 4.4208 - val_accuracy: 0.8483\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3968 - accuracy: 0.8501 - val_loss: 4.4133 - val_accuracy: 0.8498\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3807 - accuracy: 0.8502 - val_loss: 4.4169 - val_accuracy: 0.8440\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4179 - accuracy: 0.8501 - val_loss: 4.3981 - val_accuracy: 0.8487\n",
      "21/21 - 0s - loss: 4.3981 - accuracy: 0.8487 - 41ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 7ms/step - loss: 24.9720 - accuracy: 0.6345 - val_loss: 11.4233 - val_accuracy: 0.7910\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.0783 - accuracy: 0.8191 - val_loss: 6.0659 - val_accuracy: 0.8496\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.0191 - accuracy: 0.8253 - val_loss: 4.6938 - val_accuracy: 0.8563\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.5054 - accuracy: 0.8330 - val_loss: 4.7431 - val_accuracy: 0.8278\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.3073 - accuracy: 0.8338 - val_loss: 4.7596 - val_accuracy: 0.8302\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.8351 - accuracy: 0.8437 - val_loss: 5.6629 - val_accuracy: 0.7876\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5797 - accuracy: 0.8478 - val_loss: 5.0473 - val_accuracy: 0.8129\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9451 - accuracy: 0.8406 - val_loss: 4.6306 - val_accuracy: 0.8335\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9704 - accuracy: 0.8428 - val_loss: 4.4004 - val_accuracy: 0.8559\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9093 - accuracy: 0.8427 - val_loss: 4.3296 - val_accuracy: 0.8494\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 4.5845 - accuracy: 0.8466 - val_loss: 4.3832 - val_accuracy: 0.8401\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6655 - accuracy: 0.8464 - val_loss: 4.6538 - val_accuracy: 0.8256\n",
      "21/21 - 0s - loss: 4.6538 - accuracy: 0.8256 - 85ms/epoch - 4ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 92.2642 - accuracy: 0.1059 - val_loss: 69.4446 - val_accuracy: 0.2456\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50.9764 - accuracy: 0.4015 - val_loss: 24.8749 - val_accuracy: 0.5911\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8691 - accuracy: 0.6463 - val_loss: 13.9915 - val_accuracy: 0.7212\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 10.4947 - accuracy: 0.7715 - val_loss: 8.0762 - val_accuracy: 0.7871\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1965 - accuracy: 0.8019 - val_loss: 6.2667 - val_accuracy: 0.8195\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.0826 - accuracy: 0.8242 - val_loss: 5.6242 - val_accuracy: 0.8216\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.6311 - accuracy: 0.8302 - val_loss: 5.3169 - val_accuracy: 0.8280\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.4166 - accuracy: 0.8317 - val_loss: 5.0793 - val_accuracy: 0.8316\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.2200 - accuracy: 0.8349 - val_loss: 4.9719 - val_accuracy: 0.8326\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0980 - accuracy: 0.8380 - val_loss: 4.9447 - val_accuracy: 0.8325\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.0044 - accuracy: 0.8403 - val_loss: 4.7790 - val_accuracy: 0.8368\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9175 - accuracy: 0.8406 - val_loss: 4.8900 - val_accuracy: 0.8289\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8541 - accuracy: 0.8416 - val_loss: 4.6966 - val_accuracy: 0.8372\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8046 - accuracy: 0.8436 - val_loss: 4.7801 - val_accuracy: 0.8318\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7731 - accuracy: 0.8427 - val_loss: 4.7181 - val_accuracy: 0.8350\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7038 - accuracy: 0.8441 - val_loss: 4.5872 - val_accuracy: 0.8437\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6946 - accuracy: 0.8464 - val_loss: 4.9620 - val_accuracy: 0.8225\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7875 - accuracy: 0.8431 - val_loss: 4.7877 - val_accuracy: 0.8320\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6347 - accuracy: 0.8463 - val_loss: 4.5456 - val_accuracy: 0.8429\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6025 - accuracy: 0.8461 - val_loss: 4.5133 - val_accuracy: 0.8467\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5629 - accuracy: 0.8479 - val_loss: 4.5970 - val_accuracy: 0.8376\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5553 - accuracy: 0.8467 - val_loss: 4.5286 - val_accuracy: 0.8441\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5442 - accuracy: 0.8469 - val_loss: 4.5033 - val_accuracy: 0.8456\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5116 - accuracy: 0.8488 - val_loss: 4.5186 - val_accuracy: 0.8432\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.4888 - accuracy: 0.8489 - val_loss: 4.5693 - val_accuracy: 0.8422\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4765 - accuracy: 0.8507 - val_loss: 4.4862 - val_accuracy: 0.8435\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4696 - accuracy: 0.8482 - val_loss: 4.5935 - val_accuracy: 0.8400\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4506 - accuracy: 0.8504 - val_loss: 4.5354 - val_accuracy: 0.8411\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4182 - accuracy: 0.8516 - val_loss: 4.6987 - val_accuracy: 0.8310\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.4726 - accuracy: 0.8452 - val_loss: 4.5853 - val_accuracy: 0.8387\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.4008 - accuracy: 0.8503 - val_loss: 4.4322 - val_accuracy: 0.8484\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.3738 - accuracy: 0.8511 - val_loss: 4.5276 - val_accuracy: 0.8378\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.3404 - accuracy: 0.8521 - val_loss: 4.5352 - val_accuracy: 0.8389\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3486 - accuracy: 0.8525 - val_loss: 4.5209 - val_accuracy: 0.8405\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3371 - accuracy: 0.8521 - val_loss: 4.5242 - val_accuracy: 0.8389\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3348 - accuracy: 0.8507 - val_loss: 4.5111 - val_accuracy: 0.8401\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.2974 - accuracy: 0.8532 - val_loss: 4.4319 - val_accuracy: 0.8464\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.2931 - accuracy: 0.8523 - val_loss: 4.4668 - val_accuracy: 0.8429\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.2937 - accuracy: 0.8529 - val_loss: 4.4339 - val_accuracy: 0.8451\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3165 - accuracy: 0.8529 - val_loss: 4.5648 - val_accuracy: 0.8368\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3214 - accuracy: 0.8497 - val_loss: 4.4433 - val_accuracy: 0.8448\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3140 - accuracy: 0.8532 - val_loss: 4.6504 - val_accuracy: 0.8356\n",
      "21/21 - 0s - loss: 4.6504 - accuracy: 0.8356 - 43ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 108.7167 - accuracy: 0.0079 - val_loss: 100.4018 - val_accuracy: 0.0293\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 96.1297 - accuracy: 0.0879 - val_loss: 76.3325 - val_accuracy: 0.2013\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 60.8287 - accuracy: 0.3350 - val_loss: 35.0776 - val_accuracy: 0.5113\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 27.6203 - accuracy: 0.5674 - val_loss: 19.5620 - val_accuracy: 0.6411\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.3850 - accuracy: 0.6676 - val_loss: 13.4686 - val_accuracy: 0.7133\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.3568 - accuracy: 0.7451 - val_loss: 8.9365 - val_accuracy: 0.7711\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6957 - accuracy: 0.8000 - val_loss: 6.6623 - val_accuracy: 0.8027\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.1811 - accuracy: 0.8209 - val_loss: 5.6518 - val_accuracy: 0.8229\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.7090 - accuracy: 0.8286 - val_loss: 5.3554 - val_accuracy: 0.8256\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.4090 - accuracy: 0.8327 - val_loss: 5.0679 - val_accuracy: 0.8435\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.2956 - accuracy: 0.8359 - val_loss: 5.0043 - val_accuracy: 0.8307\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.1195 - accuracy: 0.8375 - val_loss: 5.1708 - val_accuracy: 0.8247\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0667 - accuracy: 0.8390 - val_loss: 4.8199 - val_accuracy: 0.8392\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9809 - accuracy: 0.8405 - val_loss: 4.7538 - val_accuracy: 0.8428\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9046 - accuracy: 0.8409 - val_loss: 4.8476 - val_accuracy: 0.8337\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9173 - accuracy: 0.8412 - val_loss: 5.0944 - val_accuracy: 0.8267\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8625 - accuracy: 0.8427 - val_loss: 4.8403 - val_accuracy: 0.8258\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8075 - accuracy: 0.8430 - val_loss: 4.6432 - val_accuracy: 0.8487\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.7698 - accuracy: 0.8441 - val_loss: 4.7614 - val_accuracy: 0.8371\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7591 - accuracy: 0.8441 - val_loss: 4.7360 - val_accuracy: 0.8309\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7445 - accuracy: 0.8448 - val_loss: 4.6222 - val_accuracy: 0.8458\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7128 - accuracy: 0.8452 - val_loss: 4.6528 - val_accuracy: 0.8405\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7058 - accuracy: 0.8455 - val_loss: 4.6130 - val_accuracy: 0.8392\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.6548 - accuracy: 0.8457 - val_loss: 4.5981 - val_accuracy: 0.8448\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6571 - accuracy: 0.8465 - val_loss: 4.9590 - val_accuracy: 0.8178\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6678 - accuracy: 0.8440 - val_loss: 4.5597 - val_accuracy: 0.8521\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6359 - accuracy: 0.8451 - val_loss: 4.5235 - val_accuracy: 0.8487\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.5654 - accuracy: 0.8482 - val_loss: 4.7867 - val_accuracy: 0.8277\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5750 - accuracy: 0.8472 - val_loss: 4.7984 - val_accuracy: 0.8218\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.5590 - accuracy: 0.8476 - val_loss: 4.5960 - val_accuracy: 0.8382\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5483 - accuracy: 0.8479 - val_loss: 4.8769 - val_accuracy: 0.8260\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5783 - accuracy: 0.8471 - val_loss: 4.8561 - val_accuracy: 0.8275\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5665 - accuracy: 0.8470 - val_loss: 4.4977 - val_accuracy: 0.8461\n",
      "21/21 - 0s - loss: 4.4977 - accuracy: 0.8461 - 45ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 67.0547 - accuracy: 0.2884 - val_loss: 14.3937 - val_accuracy: 0.6281\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3720 - accuracy: 0.7891 - val_loss: 5.3157 - val_accuracy: 0.8351\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8611 - accuracy: 0.8057 - val_loss: 7.3852 - val_accuracy: 0.8360\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8273 - accuracy: 0.8070 - val_loss: 5.2951 - val_accuracy: 0.8385\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.8926 - accuracy: 0.8373 - val_loss: 4.8588 - val_accuracy: 0.8495\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9281 - accuracy: 0.8403 - val_loss: 5.0466 - val_accuracy: 0.8165\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.4091 - accuracy: 0.8331 - val_loss: 4.5989 - val_accuracy: 0.8459\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7646 - accuracy: 0.8435 - val_loss: 5.0369 - val_accuracy: 0.8539\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.0779 - accuracy: 0.8383 - val_loss: 4.5812 - val_accuracy: 0.8461\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6050 - accuracy: 0.8468 - val_loss: 4.7177 - val_accuracy: 0.8530\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.7919 - accuracy: 0.8451 - val_loss: 4.7311 - val_accuracy: 0.8342\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.0390 - accuracy: 0.8403 - val_loss: 5.2114 - val_accuracy: 0.8586\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7770 - accuracy: 0.8436 - val_loss: 4.5285 - val_accuracy: 0.8523\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8396 - accuracy: 0.8414 - val_loss: 4.6432 - val_accuracy: 0.8565\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7549 - accuracy: 0.8473 - val_loss: 5.1165 - val_accuracy: 0.8093\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5506 - accuracy: 0.8474 - val_loss: 4.4970 - val_accuracy: 0.8452\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0357 - accuracy: 0.8403 - val_loss: 5.1026 - val_accuracy: 0.8125\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.5509 - accuracy: 0.8456 - val_loss: 4.4288 - val_accuracy: 0.8479\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.0795 - accuracy: 0.8421 - val_loss: 4.6446 - val_accuracy: 0.8292\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.7545 - accuracy: 0.8452 - val_loss: 4.5686 - val_accuracy: 0.8423\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8303 - accuracy: 0.8456 - val_loss: 4.8975 - val_accuracy: 0.8282\n",
      "21/21 - 0s - loss: 4.8975 - accuracy: 0.8282 - 41ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 2s 2ms/step - loss: 65.6094 - accuracy: 0.2854 - val_loss: 44.9715 - val_accuracy: 0.4322\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 39.5122 - accuracy: 0.5011 - val_loss: 29.5713 - val_accuracy: 0.5845\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 26.7689 - accuracy: 0.6241 - val_loss: 20.1409 - val_accuracy: 0.6834\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 18.9322 - accuracy: 0.7042 - val_loss: 14.6238 - val_accuracy: 0.7356\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 14.5487 - accuracy: 0.7427 - val_loss: 11.7172 - val_accuracy: 0.7563\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.0985 - accuracy: 0.7537 - val_loss: 10.3880 - val_accuracy: 0.7619\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 11.0314 - accuracy: 0.7509 - val_loss: 9.8977 - val_accuracy: 0.7499\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.6063 - accuracy: 0.7422 - val_loss: 9.7666 - val_accuracy: 0.7417\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4680 - accuracy: 0.7366 - val_loss: 9.7987 - val_accuracy: 0.7359\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4237 - accuracy: 0.7335 - val_loss: 9.7782 - val_accuracy: 0.7340\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4114 - accuracy: 0.7324 - val_loss: 9.7896 - val_accuracy: 0.7328\n",
      "21/21 - 0s - loss: 9.7896 - accuracy: 0.7328 - 49ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 60.1784 - accuracy: 0.3241 - val_loss: 40.7726 - val_accuracy: 0.4717\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 35.1697 - accuracy: 0.5397 - val_loss: 25.3767 - val_accuracy: 0.6309\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 21.9139 - accuracy: 0.6734 - val_loss: 15.4854 - val_accuracy: 0.7280\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 14.1978 - accuracy: 0.7445 - val_loss: 10.8181 - val_accuracy: 0.7597\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 11.0369 - accuracy: 0.7508 - val_loss: 9.7905 - val_accuracy: 0.7440\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4655 - accuracy: 0.7375 - val_loss: 9.7724 - val_accuracy: 0.7347\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4149 - accuracy: 0.7325 - val_loss: 9.7920 - val_accuracy: 0.7328\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4089 - accuracy: 0.7297 - val_loss: 9.7816 - val_accuracy: 0.7337\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4093 - accuracy: 0.7304 - val_loss: 9.7794 - val_accuracy: 0.7339\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4137 - accuracy: 0.7316 - val_loss: 9.7900 - val_accuracy: 0.7329\n",
      "21/21 - 0s - loss: 9.7900 - accuracy: 0.7329 - 41ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.0835 - accuracy: 0.7914 - val_loss: 5.6342 - val_accuracy: 0.8221\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0052 - accuracy: 0.8196 - val_loss: 5.2185 - val_accuracy: 0.8547\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2965 - accuracy: 0.8304 - val_loss: 6.2448 - val_accuracy: 0.7742\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2646 - accuracy: 0.8318 - val_loss: 5.2464 - val_accuracy: 0.8094\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.0407 - accuracy: 0.8335 - val_loss: 4.5117 - val_accuracy: 0.8579\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.0794 - accuracy: 0.8357 - val_loss: 4.4616 - val_accuracy: 0.8440\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9351 - accuracy: 0.8390 - val_loss: 4.9152 - val_accuracy: 0.8287\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7676 - accuracy: 0.8425 - val_loss: 4.4857 - val_accuracy: 0.8443\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7416 - accuracy: 0.8427 - val_loss: 4.9900 - val_accuracy: 0.8494\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8466 - accuracy: 0.8412 - val_loss: 4.4916 - val_accuracy: 0.8457\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6663 - accuracy: 0.8460 - val_loss: 4.5994 - val_accuracy: 0.8499\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6619 - accuracy: 0.8458 - val_loss: 4.5599 - val_accuracy: 0.8387\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5906 - accuracy: 0.8458 - val_loss: 4.5498 - val_accuracy: 0.8476\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6189 - accuracy: 0.8455 - val_loss: 4.8265 - val_accuracy: 0.8271\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5777 - accuracy: 0.8451 - val_loss: 4.4770 - val_accuracy: 0.8389\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5278 - accuracy: 0.8471 - val_loss: 4.4476 - val_accuracy: 0.8489\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4912 - accuracy: 0.8471 - val_loss: 4.4997 - val_accuracy: 0.8495\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4661 - accuracy: 0.8459 - val_loss: 4.5562 - val_accuracy: 0.8507\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4795 - accuracy: 0.8475 - val_loss: 5.1362 - val_accuracy: 0.8195\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4252 - accuracy: 0.8480 - val_loss: 4.3224 - val_accuracy: 0.8506\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4303 - accuracy: 0.8484 - val_loss: 4.8404 - val_accuracy: 0.8423\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2992 - accuracy: 0.8512 - val_loss: 4.7834 - val_accuracy: 0.8374\n",
      "Epoch 23/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3790 - accuracy: 0.8484 - val_loss: 4.3076 - val_accuracy: 0.8502\n",
      "Epoch 24/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3207 - accuracy: 0.8482 - val_loss: 4.9884 - val_accuracy: 0.8182\n",
      "Epoch 25/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3194 - accuracy: 0.8484 - val_loss: 4.4342 - val_accuracy: 0.8548\n",
      "Epoch 26/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3627 - accuracy: 0.8478 - val_loss: 4.5702 - val_accuracy: 0.8386\n",
      "Epoch 27/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3431 - accuracy: 0.8489 - val_loss: 4.5380 - val_accuracy: 0.8381\n",
      "21/21 - 0s - loss: 4.5380 - accuracy: 0.8381 - 47ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 2s 3ms/step - loss: 85.8837 - accuracy: 0.1401 - val_loss: 67.8462 - val_accuracy: 0.2427\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 64.6941 - accuracy: 0.2901 - val_loss: 54.8537 - val_accuracy: 0.3451\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 53.0366 - accuracy: 0.3815 - val_loss: 44.8874 - val_accuracy: 0.4332\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 43.7476 - accuracy: 0.4602 - val_loss: 36.8470 - val_accuracy: 0.5097\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 36.1852 - accuracy: 0.5297 - val_loss: 30.3256 - val_accuracy: 0.5767\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 30.0554 - accuracy: 0.5901 - val_loss: 25.0734 - val_accuracy: 0.6345\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 25.1251 - accuracy: 0.6412 - val_loss: 20.9373 - val_accuracy: 0.6755\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 21.2281 - accuracy: 0.6816 - val_loss: 17.7071 - val_accuracy: 0.7098\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 18.3864 - accuracy: 0.7087 - val_loss: 15.2501 - val_accuracy: 0.7300\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 15.8649 - accuracy: 0.7324 - val_loss: 13.4294 - val_accuracy: 0.7472\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 14.1304 - accuracy: 0.7473 - val_loss: 12.0946 - val_accuracy: 0.7551\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 12.8736 - accuracy: 0.7514 - val_loss: 11.1814 - val_accuracy: 0.7582\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.9898 - accuracy: 0.7547 - val_loss: 10.5790 - val_accuracy: 0.7608\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 11.3843 - accuracy: 0.7558 - val_loss: 10.1898 - val_accuracy: 0.7584\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.9869 - accuracy: 0.7509 - val_loss: 9.9584 - val_accuracy: 0.7520\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.7356 - accuracy: 0.7461 - val_loss: 9.8353 - val_accuracy: 0.7469\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.5843 - accuracy: 0.7420 - val_loss: 9.7796 - val_accuracy: 0.7430\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4996 - accuracy: 0.7388 - val_loss: 9.7583 - val_accuracy: 0.7396\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4531 - accuracy: 0.7364 - val_loss: 9.7582 - val_accuracy: 0.7374\n",
      "21/21 - 0s - loss: 9.7582 - accuracy: 0.7374 - 43ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 74.3767 - accuracy: 0.2172 - val_loss: 58.0253 - val_accuracy: 0.3191\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 55.7154 - accuracy: 0.3589 - val_loss: 46.9135 - val_accuracy: 0.4145\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 45.2122 - accuracy: 0.4471 - val_loss: 37.5830 - val_accuracy: 0.5024\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 36.2412 - accuracy: 0.5298 - val_loss: 29.6517 - val_accuracy: 0.5837\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 28.6568 - accuracy: 0.6060 - val_loss: 23.0845 - val_accuracy: 0.6554\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 22.4196 - accuracy: 0.6682 - val_loss: 17.8494 - val_accuracy: 0.7081\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 17.5180 - accuracy: 0.7182 - val_loss: 13.9747 - val_accuracy: 0.7417\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 14.0204 - accuracy: 0.7471 - val_loss: 11.4911 - val_accuracy: 0.7570\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.8488 - accuracy: 0.7551 - val_loss: 10.1963 - val_accuracy: 0.7585\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.8131 - accuracy: 0.7465 - val_loss: 9.7951 - val_accuracy: 0.7444\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4910 - accuracy: 0.7371 - val_loss: 9.7578 - val_accuracy: 0.7374\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4227 - accuracy: 0.7345 - val_loss: 9.7790 - val_accuracy: 0.7339\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4120 - accuracy: 0.7323 - val_loss: 9.7925 - val_accuracy: 0.7327\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4110 - accuracy: 0.7315 - val_loss: 9.7982 - val_accuracy: 0.7323\n",
      "21/21 - 0s - loss: 9.7982 - accuracy: 0.7323 - 44ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 2ms/step - loss: 10.2840 - accuracy: 0.7832 - val_loss: 5.4913 - val_accuracy: 0.8146\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.6304 - accuracy: 0.8288 - val_loss: 7.5663 - val_accuracy: 0.7429\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3399 - accuracy: 0.8333 - val_loss: 5.0062 - val_accuracy: 0.8179\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0915 - accuracy: 0.8375 - val_loss: 5.3288 - val_accuracy: 0.8063\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.9793 - accuracy: 0.8406 - val_loss: 5.3532 - val_accuracy: 0.7994\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.8062 - accuracy: 0.8442 - val_loss: 4.3877 - val_accuracy: 0.8511\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7001 - accuracy: 0.8470 - val_loss: 4.6630 - val_accuracy: 0.8410\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6684 - accuracy: 0.8459 - val_loss: 4.3306 - val_accuracy: 0.8430\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7747 - accuracy: 0.8456 - val_loss: 4.4766 - val_accuracy: 0.8456\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6717 - accuracy: 0.8466 - val_loss: 4.4193 - val_accuracy: 0.8434\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5917 - accuracy: 0.8481 - val_loss: 4.3937 - val_accuracy: 0.8552\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5557 - accuracy: 0.8479 - val_loss: 4.5275 - val_accuracy: 0.8438\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5782 - accuracy: 0.8477 - val_loss: 4.9301 - val_accuracy: 0.8172\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5523 - accuracy: 0.8493 - val_loss: 4.6545 - val_accuracy: 0.8534\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5257 - accuracy: 0.8482 - val_loss: 4.4403 - val_accuracy: 0.8556\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6441 - accuracy: 0.8462 - val_loss: 4.2263 - val_accuracy: 0.8493\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4157 - accuracy: 0.8507 - val_loss: 4.6417 - val_accuracy: 0.8374\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4358 - accuracy: 0.8496 - val_loss: 4.3191 - val_accuracy: 0.8573\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4415 - accuracy: 0.8505 - val_loss: 4.3503 - val_accuracy: 0.8546\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4221 - accuracy: 0.8511 - val_loss: 4.6781 - val_accuracy: 0.8266\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4965 - accuracy: 0.8503 - val_loss: 4.4671 - val_accuracy: 0.8419\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4314 - accuracy: 0.8495 - val_loss: 4.3078 - val_accuracy: 0.8483\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4059 - accuracy: 0.8498 - val_loss: 4.3167 - val_accuracy: 0.8479\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3380 - accuracy: 0.8515 - val_loss: 4.2545 - val_accuracy: 0.8490\n",
      "Epoch 25/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3256 - accuracy: 0.8512 - val_loss: 4.5840 - val_accuracy: 0.8419\n",
      "Epoch 26/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3650 - accuracy: 0.8521 - val_loss: 4.6887 - val_accuracy: 0.8267\n",
      "Epoch 27/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3295 - accuracy: 0.8513 - val_loss: 4.6051 - val_accuracy: 0.8318\n",
      "Epoch 28/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2338 - accuracy: 0.8534 - val_loss: 4.4463 - val_accuracy: 0.8441\n",
      "Epoch 29/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2749 - accuracy: 0.8521 - val_loss: 4.3759 - val_accuracy: 0.8440\n",
      "Epoch 30/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2263 - accuracy: 0.8546 - val_loss: 4.3362 - val_accuracy: 0.8490\n",
      "Epoch 31/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2860 - accuracy: 0.8524 - val_loss: 4.7489 - val_accuracy: 0.8295\n",
      "Epoch 32/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2419 - accuracy: 0.8525 - val_loss: 4.2745 - val_accuracy: 0.8542\n",
      "Epoch 33/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2075 - accuracy: 0.8538 - val_loss: 4.6063 - val_accuracy: 0.8333\n",
      "Epoch 34/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2092 - accuracy: 0.8521 - val_loss: 4.5881 - val_accuracy: 0.8340\n",
      "Epoch 35/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1693 - accuracy: 0.8552 - val_loss: 4.5552 - val_accuracy: 0.8344\n",
      "Epoch 36/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1853 - accuracy: 0.8542 - val_loss: 4.5089 - val_accuracy: 0.8379\n",
      "Epoch 37/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1955 - accuracy: 0.8523 - val_loss: 4.3481 - val_accuracy: 0.8491\n",
      "Epoch 38/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1686 - accuracy: 0.8543 - val_loss: 4.3688 - val_accuracy: 0.8498\n",
      "Epoch 39/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1142 - accuracy: 0.8545 - val_loss: 4.4158 - val_accuracy: 0.8507\n",
      "Epoch 40/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1389 - accuracy: 0.8553 - val_loss: 4.3411 - val_accuracy: 0.8518\n",
      "Epoch 41/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1017 - accuracy: 0.8549 - val_loss: 4.3596 - val_accuracy: 0.8518\n",
      "Epoch 42/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1445 - accuracy: 0.8536 - val_loss: 4.4719 - val_accuracy: 0.8475\n",
      "Epoch 43/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0742 - accuracy: 0.8556 - val_loss: 4.4852 - val_accuracy: 0.8392\n",
      "Epoch 44/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1379 - accuracy: 0.8533 - val_loss: 4.3859 - val_accuracy: 0.8472\n",
      "Epoch 45/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1108 - accuracy: 0.8550 - val_loss: 4.7372 - val_accuracy: 0.8248\n",
      "Epoch 46/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0439 - accuracy: 0.8556 - val_loss: 4.5674 - val_accuracy: 0.8416\n",
      "Epoch 47/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0173 - accuracy: 0.8554 - val_loss: 4.4000 - val_accuracy: 0.8410\n",
      "Epoch 48/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0657 - accuracy: 0.8549 - val_loss: 4.4116 - val_accuracy: 0.8441\n",
      "Epoch 49/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 3.9916 - accuracy: 0.8561 - val_loss: 4.4375 - val_accuracy: 0.8493\n",
      "Epoch 50/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0180 - accuracy: 0.8562 - val_loss: 4.4427 - val_accuracy: 0.8447\n",
      "Epoch 51/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0416 - accuracy: 0.8543 - val_loss: 4.6929 - val_accuracy: 0.8467\n",
      "Epoch 52/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 3.9869 - accuracy: 0.8562 - val_loss: 4.4595 - val_accuracy: 0.8365\n",
      "Epoch 53/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 3.9606 - accuracy: 0.8557 - val_loss: 4.4327 - val_accuracy: 0.8494\n",
      "Epoch 54/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 3.9458 - accuracy: 0.8550 - val_loss: 4.4866 - val_accuracy: 0.8346\n",
      "Epoch 55/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0283 - accuracy: 0.8552 - val_loss: 4.7401 - val_accuracy: 0.8376\n",
      "21/21 - 0s - loss: 4.7401 - accuracy: 0.8376 - 39ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 92.2425 - accuracy: 0.0903 - val_loss: 74.5159 - val_accuracy: 0.1904\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 71.9498 - accuracy: 0.2361 - val_loss: 63.0260 - val_accuracy: 0.2793\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 63.1076 - accuracy: 0.3016 - val_loss: 56.0896 - val_accuracy: 0.3348\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 56.6402 - accuracy: 0.3515 - val_loss: 50.3605 - val_accuracy: 0.3835\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 51.0942 - accuracy: 0.3967 - val_loss: 45.3378 - val_accuracy: 0.4290\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 46.1905 - accuracy: 0.4384 - val_loss: 40.8851 - val_accuracy: 0.4706\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 41.8155 - accuracy: 0.4770 - val_loss: 36.8876 - val_accuracy: 0.5093\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 37.8928 - accuracy: 0.5137 - val_loss: 33.3349 - val_accuracy: 0.5461\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 34.3787 - accuracy: 0.5476 - val_loss: 30.1560 - val_accuracy: 0.5785\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 31.2340 - accuracy: 0.5784 - val_loss: 27.3236 - val_accuracy: 0.6087\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 28.4260 - accuracy: 0.6072 - val_loss: 24.7942 - val_accuracy: 0.6378\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 25.9178 - accuracy: 0.6339 - val_loss: 22.5641 - val_accuracy: 0.6601\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 23.6925 - accuracy: 0.6556 - val_loss: 20.5963 - val_accuracy: 0.6789\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 21.7214 - accuracy: 0.6758 - val_loss: 18.8530 - val_accuracy: 0.6972\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.2677 - accuracy: 0.6915 - val_loss: 17.3427 - val_accuracy: 0.7138\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 18.4826 - accuracy: 0.7099 - val_loss: 16.0420 - val_accuracy: 0.7234\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 17.1516 - accuracy: 0.7202 - val_loss: 14.9083 - val_accuracy: 0.7330\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 16.0069 - accuracy: 0.7308 - val_loss: 13.9407 - val_accuracy: 0.7420\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 15.0228 - accuracy: 0.7406 - val_loss: 13.1160 - val_accuracy: 0.7506\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.1824 - accuracy: 0.7478 - val_loss: 12.4274 - val_accuracy: 0.7541\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.4718 - accuracy: 0.7500 - val_loss: 11.8570 - val_accuracy: 0.7558\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.8711 - accuracy: 0.7515 - val_loss: 11.3777 - val_accuracy: 0.7574\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.3723 - accuracy: 0.7530 - val_loss: 10.9914 - val_accuracy: 0.7589\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.9589 - accuracy: 0.7545 - val_loss: 10.6833 - val_accuracy: 0.7603\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.6199 - accuracy: 0.7560 - val_loss: 10.4335 - val_accuracy: 0.7616\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.3446 - accuracy: 0.7560 - val_loss: 10.2358 - val_accuracy: 0.7594\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1226 - accuracy: 0.7533 - val_loss: 10.0949 - val_accuracy: 0.7560\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.9497 - accuracy: 0.7505 - val_loss: 9.9817 - val_accuracy: 0.7528\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.8118 - accuracy: 0.7477 - val_loss: 9.9026 - val_accuracy: 0.7500\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.7084 - accuracy: 0.7452 - val_loss: 9.8440 - val_accuracy: 0.7474\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.6265 - accuracy: 0.7434 - val_loss: 9.8069 - val_accuracy: 0.7452\n",
      "21/21 - 0s - loss: 9.8069 - accuracy: 0.7452 - 39ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 82.8624 - accuracy: 0.1559 - val_loss: 65.4244 - val_accuracy: 0.2609\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 65.0703 - accuracy: 0.2868 - val_loss: 57.7678 - val_accuracy: 0.3212\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 58.2073 - accuracy: 0.3394 - val_loss: 51.7339 - val_accuracy: 0.3716\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 52.3671 - accuracy: 0.3863 - val_loss: 46.3689 - val_accuracy: 0.4195\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 47.0268 - accuracy: 0.4316 - val_loss: 41.4642 - val_accuracy: 0.4653\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 42.1507 - accuracy: 0.4742 - val_loss: 36.9403 - val_accuracy: 0.5088\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 37.6526 - accuracy: 0.5160 - val_loss: 32.8151 - val_accuracy: 0.5517\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 33.5273 - accuracy: 0.5560 - val_loss: 29.0163 - val_accuracy: 0.5903\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 29.7044 - accuracy: 0.5934 - val_loss: 25.5499 - val_accuracy: 0.6289\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 26.2497 - accuracy: 0.6304 - val_loss: 22.4555 - val_accuracy: 0.6611\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 23.1563 - accuracy: 0.6605 - val_loss: 19.7060 - val_accuracy: 0.6879\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 20.4011 - accuracy: 0.6901 - val_loss: 17.2974 - val_accuracy: 0.7138\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 18.0180 - accuracy: 0.7131 - val_loss: 15.2381 - val_accuracy: 0.7301\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 15.9733 - accuracy: 0.7312 - val_loss: 13.5459 - val_accuracy: 0.7460\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.2581 - accuracy: 0.7465 - val_loss: 12.1524 - val_accuracy: 0.7549\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.8677 - accuracy: 0.7522 - val_loss: 11.1196 - val_accuracy: 0.7584\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.8287 - accuracy: 0.7551 - val_loss: 10.3899 - val_accuracy: 0.7619\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.1264 - accuracy: 0.7532 - val_loss: 9.9836 - val_accuracy: 0.7529\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7169 - accuracy: 0.7454 - val_loss: 9.8026 - val_accuracy: 0.7449\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.5159 - accuracy: 0.7392 - val_loss: 9.7570 - val_accuracy: 0.7389\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.4383 - accuracy: 0.7353 - val_loss: 9.7650 - val_accuracy: 0.7357\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.4172 - accuracy: 0.7331 - val_loss: 9.7793 - val_accuracy: 0.7339\n",
      "21/21 - 0s - loss: 9.7793 - accuracy: 0.7339 - 38ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 14.8593 - accuracy: 0.7473 - val_loss: 6.2638 - val_accuracy: 0.8259\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5965 - accuracy: 0.8195 - val_loss: 5.7659 - val_accuracy: 0.8226\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6263 - accuracy: 0.8351 - val_loss: 5.2969 - val_accuracy: 0.8294\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2978 - accuracy: 0.8355 - val_loss: 5.1975 - val_accuracy: 0.8075\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9099 - accuracy: 0.8428 - val_loss: 5.2659 - val_accuracy: 0.8282\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8325 - accuracy: 0.8435 - val_loss: 6.1269 - val_accuracy: 0.7981\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7620 - accuracy: 0.8440 - val_loss: 4.5777 - val_accuracy: 0.8421\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8011 - accuracy: 0.8430 - val_loss: 4.8964 - val_accuracy: 0.8203\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7500 - accuracy: 0.8430 - val_loss: 5.1170 - val_accuracy: 0.8049\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6766 - accuracy: 0.8463 - val_loss: 5.7039 - val_accuracy: 0.7881\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6146 - accuracy: 0.8457 - val_loss: 4.6166 - val_accuracy: 0.8233\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5345 - accuracy: 0.8471 - val_loss: 4.7372 - val_accuracy: 0.8499\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5104 - accuracy: 0.8470 - val_loss: 4.4198 - val_accuracy: 0.8384\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5312 - accuracy: 0.8494 - val_loss: 4.8501 - val_accuracy: 0.8213\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4862 - accuracy: 0.8484 - val_loss: 4.2795 - val_accuracy: 0.8452\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4302 - accuracy: 0.8480 - val_loss: 4.3956 - val_accuracy: 0.8525\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4219 - accuracy: 0.8501 - val_loss: 4.6848 - val_accuracy: 0.8469\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4276 - accuracy: 0.8492 - val_loss: 4.3918 - val_accuracy: 0.8376\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4012 - accuracy: 0.8498 - val_loss: 5.2018 - val_accuracy: 0.8098\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4196 - accuracy: 0.8488 - val_loss: 4.3303 - val_accuracy: 0.8444\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4287 - accuracy: 0.8503 - val_loss: 4.2880 - val_accuracy: 0.8417\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3806 - accuracy: 0.8516 - val_loss: 4.6073 - val_accuracy: 0.8261\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3241 - accuracy: 0.8511 - val_loss: 4.5771 - val_accuracy: 0.8399\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2840 - accuracy: 0.8522 - val_loss: 4.2263 - val_accuracy: 0.8442\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2858 - accuracy: 0.8522 - val_loss: 4.2006 - val_accuracy: 0.8502\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3346 - accuracy: 0.8506 - val_loss: 4.4125 - val_accuracy: 0.8511\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2152 - accuracy: 0.8539 - val_loss: 4.7669 - val_accuracy: 0.8506\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2532 - accuracy: 0.8538 - val_loss: 4.8018 - val_accuracy: 0.8141\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2766 - accuracy: 0.8499 - val_loss: 4.2897 - val_accuracy: 0.8474\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2870 - accuracy: 0.8511 - val_loss: 4.4288 - val_accuracy: 0.8549\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2164 - accuracy: 0.8532 - val_loss: 5.7308 - val_accuracy: 0.8075\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.1708 - accuracy: 0.8527 - val_loss: 4.3950 - val_accuracy: 0.8571\n",
      "21/21 - 0s - loss: 4.3950 - accuracy: 0.8571 - 45ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 106.5932 - accuracy: 0.0101 - val_loss: 98.4111 - val_accuracy: 0.0321\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 99.2776 - accuracy: 0.0563 - val_loss: 90.9667 - val_accuracy: 0.0836\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 92.3592 - accuracy: 0.1024 - val_loss: 84.9520 - val_accuracy: 0.1247\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 86.9032 - accuracy: 0.1373 - val_loss: 80.3840 - val_accuracy: 0.1549\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 82.5372 - accuracy: 0.1658 - val_loss: 76.3565 - val_accuracy: 0.1823\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 78.5901 - accuracy: 0.1916 - val_loss: 72.6691 - val_accuracy: 0.2082\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 74.9317 - accuracy: 0.2164 - val_loss: 69.2387 - val_accuracy: 0.2329\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 71.5035 - accuracy: 0.2401 - val_loss: 66.0020 - val_accuracy: 0.2569\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 68.2629 - accuracy: 0.2632 - val_loss: 62.9375 - val_accuracy: 0.2802\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 65.1900 - accuracy: 0.2858 - val_loss: 60.0182 - val_accuracy: 0.3031\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 62.2623 - accuracy: 0.3078 - val_loss: 57.2523 - val_accuracy: 0.3254\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 59.4776 - accuracy: 0.3294 - val_loss: 54.6086 - val_accuracy: 0.3473\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 56.8179 - accuracy: 0.3501 - val_loss: 52.0974 - val_accuracy: 0.3685\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 54.2783 - accuracy: 0.3701 - val_loss: 49.7089 - val_accuracy: 0.3893\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 51.8617 - accuracy: 0.3902 - val_loss: 47.4045 - val_accuracy: 0.4100\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 49.5410 - accuracy: 0.4096 - val_loss: 45.2350 - val_accuracy: 0.4300\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 47.3318 - accuracy: 0.4288 - val_loss: 43.1530 - val_accuracy: 0.4498\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 45.2253 - accuracy: 0.4472 - val_loss: 41.1493 - val_accuracy: 0.4682\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 43.2059 - accuracy: 0.4646 - val_loss: 39.2617 - val_accuracy: 0.4860\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 41.2876 - accuracy: 0.4819 - val_loss: 37.4517 - val_accuracy: 0.5037\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 39.4504 - accuracy: 0.4987 - val_loss: 35.7384 - val_accuracy: 0.5209\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 37.7067 - accuracy: 0.5153 - val_loss: 34.0906 - val_accuracy: 0.5380\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 36.0391 - accuracy: 0.5318 - val_loss: 32.5361 - val_accuracy: 0.5547\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 34.4520 - accuracy: 0.5470 - val_loss: 31.0620 - val_accuracy: 0.5692\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 32.9480 - accuracy: 0.5612 - val_loss: 29.6424 - val_accuracy: 0.5838\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 31.5078 - accuracy: 0.5753 - val_loss: 28.3156 - val_accuracy: 0.5978\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 30.1476 - accuracy: 0.5891 - val_loss: 27.0455 - val_accuracy: 0.6118\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 28.8508 - accuracy: 0.6026 - val_loss: 25.8507 - val_accuracy: 0.6254\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 27.6229 - accuracy: 0.6159 - val_loss: 24.7153 - val_accuracy: 0.6387\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 26.4584 - accuracy: 0.6288 - val_loss: 23.6392 - val_accuracy: 0.6505\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 25.3546 - accuracy: 0.6394 - val_loss: 22.6289 - val_accuracy: 0.6595\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 24.3114 - accuracy: 0.6491 - val_loss: 21.6719 - val_accuracy: 0.6684\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 23.3252 - accuracy: 0.6590 - val_loss: 20.7666 - val_accuracy: 0.6772\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 22.3936 - accuracy: 0.6684 - val_loss: 19.9107 - val_accuracy: 0.6858\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 21.5129 - accuracy: 0.6778 - val_loss: 19.1125 - val_accuracy: 0.6941\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 20.6856 - accuracy: 0.6869 - val_loss: 18.3600 - val_accuracy: 0.7024\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 19.9923 - accuracy: 0.6947 - val_loss: 17.6610 - val_accuracy: 0.7103\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 19.1918 - accuracy: 0.7038 - val_loss: 17.0026 - val_accuracy: 0.7160\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 18.4845 - accuracy: 0.7093 - val_loss: 16.3797 - val_accuracy: 0.7208\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.8380 - accuracy: 0.7144 - val_loss: 15.8022 - val_accuracy: 0.7254\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.2330 - accuracy: 0.7194 - val_loss: 15.2675 - val_accuracy: 0.7299\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 16.6686 - accuracy: 0.7245 - val_loss: 14.7666 - val_accuracy: 0.7343\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 16.1403 - accuracy: 0.7295 - val_loss: 14.3016 - val_accuracy: 0.7386\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 15.6477 - accuracy: 0.7342 - val_loss: 13.8709 - val_accuracy: 0.7427\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 15.1892 - accuracy: 0.7388 - val_loss: 13.4699 - val_accuracy: 0.7468\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 14.7573 - accuracy: 0.7436 - val_loss: 12.9464 - val_accuracy: 0.7571\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 14.3333 - accuracy: 0.7490 - val_loss: 12.7651 - val_accuracy: 0.7532\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 14.0018 - accuracy: 0.7486 - val_loss: 12.4475 - val_accuracy: 0.7540\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 13.6623 - accuracy: 0.7495 - val_loss: 12.1608 - val_accuracy: 0.7549\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 13.3508 - accuracy: 0.7503 - val_loss: 11.8962 - val_accuracy: 0.7557\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 13.0627 - accuracy: 0.7511 - val_loss: 11.6567 - val_accuracy: 0.7565\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 12.7989 - accuracy: 0.7519 - val_loss: 11.4364 - val_accuracy: 0.7572\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 12.5548 - accuracy: 0.7526 - val_loss: 11.2378 - val_accuracy: 0.7580\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 12.3329 - accuracy: 0.7533 - val_loss: 11.0555 - val_accuracy: 0.7587\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 12.1287 - accuracy: 0.7540 - val_loss: 10.8929 - val_accuracy: 0.7594\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.9426 - accuracy: 0.7547 - val_loss: 10.7482 - val_accuracy: 0.7600\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.7749 - accuracy: 0.7554 - val_loss: 10.6152 - val_accuracy: 0.7607\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.6219 - accuracy: 0.7559 - val_loss: 10.4957 - val_accuracy: 0.7613\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.4826 - accuracy: 0.7566 - val_loss: 10.3920 - val_accuracy: 0.7619\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.3582 - accuracy: 0.7566 - val_loss: 10.2985 - val_accuracy: 0.7607\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.2457 - accuracy: 0.7551 - val_loss: 10.2148 - val_accuracy: 0.7589\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.1438 - accuracy: 0.7536 - val_loss: 10.1424 - val_accuracy: 0.7573\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.0535 - accuracy: 0.7521 - val_loss: 10.0783 - val_accuracy: 0.7556\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.9712 - accuracy: 0.7509 - val_loss: 10.0250 - val_accuracy: 0.7541\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.9008 - accuracy: 0.7494 - val_loss: 9.9738 - val_accuracy: 0.7526\n",
      "21/21 - 0s - loss: 9.9738 - accuracy: 0.7526 - 47ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 96.8008 - accuracy: 0.0603 - val_loss: 83.9027 - val_accuracy: 0.1267\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 84.8478 - accuracy: 0.1491 - val_loss: 78.0397 - val_accuracy: 0.1705\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 80.1713 - accuracy: 0.1808 - val_loss: 74.1729 - val_accuracy: 0.1975\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 76.4417 - accuracy: 0.2059 - val_loss: 70.6962 - val_accuracy: 0.2223\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 72.9685 - accuracy: 0.2299 - val_loss: 67.3925 - val_accuracy: 0.2465\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 69.6441 - accuracy: 0.2533 - val_loss: 64.2225 - val_accuracy: 0.2704\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 66.4420 - accuracy: 0.2765 - val_loss: 61.1659 - val_accuracy: 0.2940\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 63.3436 - accuracy: 0.2996 - val_loss: 58.2029 - val_accuracy: 0.3177\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 60.3366 - accuracy: 0.3225 - val_loss: 55.3266 - val_accuracy: 0.3413\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 57.4299 - accuracy: 0.3451 - val_loss: 52.5593 - val_accuracy: 0.3646\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 54.6261 - accuracy: 0.3675 - val_loss: 49.8855 - val_accuracy: 0.3878\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 51.8997 - accuracy: 0.3898 - val_loss: 47.2933 - val_accuracy: 0.4110\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 49.2563 - accuracy: 0.4122 - val_loss: 44.7799 - val_accuracy: 0.4343\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 46.6964 - accuracy: 0.4344 - val_loss: 42.3546 - val_accuracy: 0.4571\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 44.2419 - accuracy: 0.4558 - val_loss: 40.0285 - val_accuracy: 0.4787\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 41.8739 - accuracy: 0.4767 - val_loss: 37.7960 - val_accuracy: 0.5003\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 39.5903 - accuracy: 0.4977 - val_loss: 35.6317 - val_accuracy: 0.5220\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 37.3946 - accuracy: 0.5186 - val_loss: 33.5710 - val_accuracy: 0.5436\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 35.2762 - accuracy: 0.5392 - val_loss: 31.5877 - val_accuracy: 0.5640\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 33.2398 - accuracy: 0.5585 - val_loss: 29.6798 - val_accuracy: 0.5834\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 31.2971 - accuracy: 0.5774 - val_loss: 27.8678 - val_accuracy: 0.6027\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 29.4424 - accuracy: 0.5963 - val_loss: 26.1483 - val_accuracy: 0.6219\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 27.6845 - accuracy: 0.6151 - val_loss: 24.5233 - val_accuracy: 0.6410\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 26.0225 - accuracy: 0.6331 - val_loss: 22.9899 - val_accuracy: 0.6562\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 24.4277 - accuracy: 0.6482 - val_loss: 21.5209 - val_accuracy: 0.6698\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 22.9136 - accuracy: 0.6629 - val_loss: 20.1451 - val_accuracy: 0.6834\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 21.5140 - accuracy: 0.6778 - val_loss: 18.8693 - val_accuracy: 0.6968\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 20.1922 - accuracy: 0.6925 - val_loss: 17.6792 - val_accuracy: 0.7101\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 18.9570 - accuracy: 0.7053 - val_loss: 16.5667 - val_accuracy: 0.7193\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 17.7964 - accuracy: 0.7148 - val_loss: 15.5455 - val_accuracy: 0.7275\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 16.7219 - accuracy: 0.7240 - val_loss: 14.5971 - val_accuracy: 0.7358\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 15.7478 - accuracy: 0.7332 - val_loss: 13.7482 - val_accuracy: 0.7439\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 14.8566 - accuracy: 0.7425 - val_loss: 12.9834 - val_accuracy: 0.7520\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 14.0370 - accuracy: 0.7485 - val_loss: 12.2960 - val_accuracy: 0.7545\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 13.3122 - accuracy: 0.7506 - val_loss: 11.6986 - val_accuracy: 0.7563\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.6822 - accuracy: 0.7524 - val_loss: 11.1941 - val_accuracy: 0.7581\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.1360 - accuracy: 0.7540 - val_loss: 10.7687 - val_accuracy: 0.7599\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.6642 - accuracy: 0.7557 - val_loss: 10.4186 - val_accuracy: 0.7617\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.2749 - accuracy: 0.7553 - val_loss: 10.1490 - val_accuracy: 0.7574\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.9595 - accuracy: 0.7508 - val_loss: 9.9561 - val_accuracy: 0.7520\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.7381 - accuracy: 0.7464 - val_loss: 9.8359 - val_accuracy: 0.7470\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.5931 - accuracy: 0.7420 - val_loss: 9.7815 - val_accuracy: 0.7432\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.5048 - accuracy: 0.7389 - val_loss: 9.7588 - val_accuracy: 0.7398\n",
      "21/21 - 0s - loss: 9.7588 - accuracy: 0.7398 - 44ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 24.8931 - accuracy: 0.6564 - val_loss: 6.9763 - val_accuracy: 0.7967\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.8986 - accuracy: 0.8165 - val_loss: 5.9660 - val_accuracy: 0.8273\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.1264 - accuracy: 0.8276 - val_loss: 5.3032 - val_accuracy: 0.8534\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.5406 - accuracy: 0.8354 - val_loss: 5.0589 - val_accuracy: 0.8347\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.3369 - accuracy: 0.8371 - val_loss: 4.8564 - val_accuracy: 0.8331\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.0872 - accuracy: 0.8415 - val_loss: 4.8280 - val_accuracy: 0.8394\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.9656 - accuracy: 0.8424 - val_loss: 4.5510 - val_accuracy: 0.8529\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9181 - accuracy: 0.8429 - val_loss: 4.5544 - val_accuracy: 0.8583\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.7829 - accuracy: 0.8454 - val_loss: 4.6988 - val_accuracy: 0.8485\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.8244 - accuracy: 0.8460 - val_loss: 4.4847 - val_accuracy: 0.8403\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6870 - accuracy: 0.8468 - val_loss: 4.5833 - val_accuracy: 0.8453\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.7336 - accuracy: 0.8461 - val_loss: 4.5107 - val_accuracy: 0.8592\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6735 - accuracy: 0.8464 - val_loss: 4.4053 - val_accuracy: 0.8460\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6796 - accuracy: 0.8468 - val_loss: 4.4118 - val_accuracy: 0.8579\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.7110 - accuracy: 0.8454 - val_loss: 4.8252 - val_accuracy: 0.8325\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5864 - accuracy: 0.8484 - val_loss: 4.3414 - val_accuracy: 0.8538\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6567 - accuracy: 0.8458 - val_loss: 4.6123 - val_accuracy: 0.8377\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5715 - accuracy: 0.8486 - val_loss: 4.3856 - val_accuracy: 0.8592\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6016 - accuracy: 0.8492 - val_loss: 4.3047 - val_accuracy: 0.8528\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4973 - accuracy: 0.8498 - val_loss: 4.6443 - val_accuracy: 0.8411\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6131 - accuracy: 0.8475 - val_loss: 4.2601 - val_accuracy: 0.8552\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4180 - accuracy: 0.8513 - val_loss: 4.2431 - val_accuracy: 0.8545\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4437 - accuracy: 0.8511 - val_loss: 4.3333 - val_accuracy: 0.8450\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4081 - accuracy: 0.8513 - val_loss: 4.3402 - val_accuracy: 0.8428\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4437 - accuracy: 0.8502 - val_loss: 5.1901 - val_accuracy: 0.8197\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3354 - accuracy: 0.8522 - val_loss: 4.4370 - val_accuracy: 0.8453\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3241 - accuracy: 0.8528 - val_loss: 4.5592 - val_accuracy: 0.8365\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3300 - accuracy: 0.8529 - val_loss: 4.1925 - val_accuracy: 0.8551\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3164 - accuracy: 0.8525 - val_loss: 4.3371 - val_accuracy: 0.8400\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3299 - accuracy: 0.8512 - val_loss: 4.5483 - val_accuracy: 0.8593\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3197 - accuracy: 0.8516 - val_loss: 4.5641 - val_accuracy: 0.8577\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3656 - accuracy: 0.8520 - val_loss: 4.2650 - val_accuracy: 0.8445\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3014 - accuracy: 0.8530 - val_loss: 4.3525 - val_accuracy: 0.8415\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3216 - accuracy: 0.8532 - val_loss: 5.8972 - val_accuracy: 0.7754\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3092 - accuracy: 0.8514 - val_loss: 4.4219 - val_accuracy: 0.8497\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2955 - accuracy: 0.8538 - val_loss: 4.4979 - val_accuracy: 0.8541\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2966 - accuracy: 0.8533 - val_loss: 4.2124 - val_accuracy: 0.8496\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2071 - accuracy: 0.8534 - val_loss: 4.2233 - val_accuracy: 0.8571\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2622 - accuracy: 0.8534 - val_loss: 4.2389 - val_accuracy: 0.8484\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2565 - accuracy: 0.8534 - val_loss: 4.6467 - val_accuracy: 0.8287\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2030 - accuracy: 0.8547 - val_loss: 4.3758 - val_accuracy: 0.8499\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2363 - accuracy: 0.8542 - val_loss: 4.1847 - val_accuracy: 0.8548\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2191 - accuracy: 0.8541 - val_loss: 4.2210 - val_accuracy: 0.8563\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.1821 - accuracy: 0.8542 - val_loss: 4.2571 - val_accuracy: 0.8426\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2243 - accuracy: 0.8537 - val_loss: 4.4977 - val_accuracy: 0.8338\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2560 - accuracy: 0.8530 - val_loss: 4.1650 - val_accuracy: 0.8515\n",
      "21/21 - 0s - loss: 4.1650 - accuracy: 0.8515 - 37ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 97.6230 - accuracy: 0.0265 - val_loss: 88.2623 - val_accuracy: 0.0596\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 93.4286 - accuracy: 0.0503 - val_loss: 86.1234 - val_accuracy: 0.0727\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 91.1718 - accuracy: 0.0643 - val_loss: 83.1393 - val_accuracy: 0.0950\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 84.4694 - accuracy: 0.1132 - val_loss: 73.8149 - val_accuracy: 0.1639\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 74.4371 - accuracy: 0.1923 - val_loss: 64.0035 - val_accuracy: 0.2581\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 63.1341 - accuracy: 0.2968 - val_loss: 56.0359 - val_accuracy: 0.3351\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 58.2522 - accuracy: 0.3386 - val_loss: 53.5479 - val_accuracy: 0.3561\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 55.9931 - accuracy: 0.3564 - val_loss: 51.5793 - val_accuracy: 0.3729\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 54.0843 - accuracy: 0.3718 - val_loss: 49.8240 - val_accuracy: 0.3882\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 52.3467 - accuracy: 0.3860 - val_loss: 48.2212 - val_accuracy: 0.4025\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 50.7401 - accuracy: 0.3994 - val_loss: 46.7216 - val_accuracy: 0.4162\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 49.2337 - accuracy: 0.4123 - val_loss: 45.2968 - val_accuracy: 0.4294\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 47.7954 - accuracy: 0.4248 - val_loss: 43.9543 - val_accuracy: 0.4421\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46.4336 - accuracy: 0.4368 - val_loss: 42.6629 - val_accuracy: 0.4542\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45.1266 - accuracy: 0.4480 - val_loss: 41.4255 - val_accuracy: 0.4656\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.8702 - accuracy: 0.4589 - val_loss: 40.2416 - val_accuracy: 0.4767\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42.6598 - accuracy: 0.4695 - val_loss: 39.1070 - val_accuracy: 0.4875\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 41.5008 - accuracy: 0.4799 - val_loss: 38.0034 - val_accuracy: 0.4982\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40.3743 - accuracy: 0.4902 - val_loss: 36.9444 - val_accuracy: 0.5087\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 39.2896 - accuracy: 0.5003 - val_loss: 35.9208 - val_accuracy: 0.5190\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 38.2415 - accuracy: 0.5102 - val_loss: 34.9292 - val_accuracy: 0.5292\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 37.2305 - accuracy: 0.5201 - val_loss: 33.9650 - val_accuracy: 0.5393\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 36.2442 - accuracy: 0.5298 - val_loss: 33.0429 - val_accuracy: 0.5492\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 35.2934 - accuracy: 0.5391 - val_loss: 32.1505 - val_accuracy: 0.5584\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 34.3776 - accuracy: 0.5477 - val_loss: 31.2791 - val_accuracy: 0.5671\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 33.4822 - accuracy: 0.5561 - val_loss: 30.4434 - val_accuracy: 0.5755\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 32.6193 - accuracy: 0.5644 - val_loss: 29.6331 - val_accuracy: 0.5839\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 31.7814 - accuracy: 0.5725 - val_loss: 28.8501 - val_accuracy: 0.5921\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 30.9744 - accuracy: 0.5807 - val_loss: 28.0851 - val_accuracy: 0.6003\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 30.1858 - accuracy: 0.5886 - val_loss: 27.3512 - val_accuracy: 0.6084\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 29.4245 - accuracy: 0.5964 - val_loss: 26.6413 - val_accuracy: 0.6163\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 28.6909 - accuracy: 0.6043 - val_loss: 25.9477 - val_accuracy: 0.6242\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 27.9766 - accuracy: 0.6120 - val_loss: 25.2795 - val_accuracy: 0.6320\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 27.2854 - accuracy: 0.6196 - val_loss: 24.6340 - val_accuracy: 0.6397\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 26.6139 - accuracy: 0.6271 - val_loss: 24.0148 - val_accuracy: 0.6472\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 25.9702 - accuracy: 0.6337 - val_loss: 23.4088 - val_accuracy: 0.6525\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 25.3417 - accuracy: 0.6395 - val_loss: 22.8257 - val_accuracy: 0.6577\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 24.7354 - accuracy: 0.6452 - val_loss: 22.2620 - val_accuracy: 0.6629\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 24.1467 - accuracy: 0.6509 - val_loss: 21.7201 - val_accuracy: 0.6680\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 23.5792 - accuracy: 0.6566 - val_loss: 21.1929 - val_accuracy: 0.6730\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 23.0392 - accuracy: 0.6617 - val_loss: 20.7020 - val_accuracy: 0.6778\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 22.5055 - accuracy: 0.6673 - val_loss: 20.1975 - val_accuracy: 0.6828\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 21.9905 - accuracy: 0.6726 - val_loss: 19.7239 - val_accuracy: 0.6877\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 21.4959 - accuracy: 0.6779 - val_loss: 19.2659 - val_accuracy: 0.6925\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 21.0140 - accuracy: 0.6831 - val_loss: 18.8307 - val_accuracy: 0.6972\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 20.5555 - accuracy: 0.6882 - val_loss: 18.4049 - val_accuracy: 0.7019\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 20.1084 - accuracy: 0.6933 - val_loss: 17.9964 - val_accuracy: 0.7065\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 19.6802 - accuracy: 0.6983 - val_loss: 17.5988 - val_accuracy: 0.7111\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 19.2625 - accuracy: 0.7029 - val_loss: 17.2210 - val_accuracy: 0.7143\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 18.8610 - accuracy: 0.7060 - val_loss: 16.8602 - val_accuracy: 0.7170\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.4797 - accuracy: 0.7091 - val_loss: 16.5047 - val_accuracy: 0.7198\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.1048 - accuracy: 0.7122 - val_loss: 16.1696 - val_accuracy: 0.7224\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.7470 - accuracy: 0.7151 - val_loss: 15.8477 - val_accuracy: 0.7250\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.4021 - accuracy: 0.7180 - val_loss: 15.5387 - val_accuracy: 0.7275\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.0724 - accuracy: 0.7209 - val_loss: 15.2371 - val_accuracy: 0.7301\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.7521 - accuracy: 0.7237 - val_loss: 14.9494 - val_accuracy: 0.7326\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.4450 - accuracy: 0.7265 - val_loss: 14.6745 - val_accuracy: 0.7351\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.1500 - accuracy: 0.7293 - val_loss: 14.4111 - val_accuracy: 0.7375\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.8672 - accuracy: 0.7320 - val_loss: 14.1579 - val_accuracy: 0.7399\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.5965 - accuracy: 0.7347 - val_loss: 13.9136 - val_accuracy: 0.7423\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.3330 - accuracy: 0.7373 - val_loss: 13.6841 - val_accuracy: 0.7446\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.0825 - accuracy: 0.7399 - val_loss: 13.4650 - val_accuracy: 0.7468\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.8441 - accuracy: 0.7424 - val_loss: 13.2522 - val_accuracy: 0.7491\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.6136 - accuracy: 0.7449 - val_loss: 13.0493 - val_accuracy: 0.7513\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.3922 - accuracy: 0.7473 - val_loss: 12.8571 - val_accuracy: 0.7529\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.7483 - val_loss: 12.6720 - val_accuracy: 0.7534\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.9802 - accuracy: 0.7488 - val_loss: 12.4954 - val_accuracy: 0.7539\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.7857 - accuracy: 0.7493 - val_loss: 12.3298 - val_accuracy: 0.7544\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.6027 - accuracy: 0.7497 - val_loss: 12.1693 - val_accuracy: 0.7549\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 13.4263 - accuracy: 0.7501 - val_loss: 12.0169 - val_accuracy: 0.7553\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.2561 - accuracy: 0.7506 - val_loss: 11.8747 - val_accuracy: 0.7558\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.0974 - accuracy: 0.7511 - val_loss: 11.7355 - val_accuracy: 0.7562\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.9420 - accuracy: 0.7515 - val_loss: 11.6057 - val_accuracy: 0.7567\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.7943 - accuracy: 0.7520 - val_loss: 11.4758 - val_accuracy: 0.7574\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.6880 - accuracy: 0.7527 - val_loss: 11.3719 - val_accuracy: 0.7574\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.5253 - accuracy: 0.7527 - val_loss: 11.2594 - val_accuracy: 0.7579\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.4008 - accuracy: 0.7531 - val_loss: 11.1522 - val_accuracy: 0.7583\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.2797 - accuracy: 0.7535 - val_loss: 11.0535 - val_accuracy: 0.7587\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.1662 - accuracy: 0.7539 - val_loss: 10.9597 - val_accuracy: 0.7591\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.0583 - accuracy: 0.7543 - val_loss: 10.8720 - val_accuracy: 0.7594\n",
      "Epoch 81/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.9559 - accuracy: 0.7547 - val_loss: 10.7894 - val_accuracy: 0.7598\n",
      "Epoch 82/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.8587 - accuracy: 0.7550 - val_loss: 10.7119 - val_accuracy: 0.7602\n",
      "Epoch 83/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.7666 - accuracy: 0.7554 - val_loss: 10.6388 - val_accuracy: 0.7605\n",
      "Epoch 84/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.6811 - accuracy: 0.7557 - val_loss: 10.5675 - val_accuracy: 0.7609\n",
      "Epoch 85/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.5964 - accuracy: 0.7561 - val_loss: 10.5044 - val_accuracy: 0.7612\n",
      "Epoch 86/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.5193 - accuracy: 0.7564 - val_loss: 10.4434 - val_accuracy: 0.7616\n",
      "Epoch 87/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.4468 - accuracy: 0.7568 - val_loss: 10.3849 - val_accuracy: 0.7619\n",
      "Epoch 88/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.3755 - accuracy: 0.7569 - val_loss: 10.3329 - val_accuracy: 0.7614\n",
      "Epoch 89/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.3112 - accuracy: 0.7561 - val_loss: 10.2822 - val_accuracy: 0.7604\n",
      "Epoch 90/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.2482 - accuracy: 0.7552 - val_loss: 10.2370 - val_accuracy: 0.7594\n",
      "Epoch 91/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.1901 - accuracy: 0.7544 - val_loss: 10.1946 - val_accuracy: 0.7585\n",
      "Epoch 92/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.1364 - accuracy: 0.7535 - val_loss: 10.1532 - val_accuracy: 0.7575\n",
      "Epoch 93/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 11.0841 - accuracy: 0.7527 - val_loss: 10.1162 - val_accuracy: 0.7566\n",
      "21/21 - 0s - loss: 10.1162 - accuracy: 0.7566 - 57ms/epoch - 3ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 10ms/step - loss: 104.7379 - accuracy: 0.0201 - val_loss: 95.7906 - val_accuracy: 0.0443\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 97.4836 - accuracy: 0.0625 - val_loss: 90.3927 - val_accuracy: 0.0812\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 93.3594 - accuracy: 0.0888 - val_loss: 87.0506 - val_accuracy: 0.1040\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 89.9585 - accuracy: 0.1122 - val_loss: 83.7778 - val_accuracy: 0.1288\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 86.3195 - accuracy: 0.1400 - val_loss: 80.7363 - val_accuracy: 0.1521\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 83.9094 - accuracy: 0.1561 - val_loss: 78.6503 - val_accuracy: 0.1662\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 81.7774 - accuracy: 0.1702 - val_loss: 76.5600 - val_accuracy: 0.1809\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 79.7027 - accuracy: 0.1841 - val_loss: 74.6464 - val_accuracy: 0.1942\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 77.7915 - accuracy: 0.1968 - val_loss: 72.8294 - val_accuracy: 0.2070\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 75.9593 - accuracy: 0.2092 - val_loss: 71.0783 - val_accuracy: 0.2196\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 74.1898 - accuracy: 0.2213 - val_loss: 69.3807 - val_accuracy: 0.2319\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 72.4706 - accuracy: 0.2333 - val_loss: 67.7271 - val_accuracy: 0.2440\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 70.7903 - accuracy: 0.2452 - val_loss: 66.1085 - val_accuracy: 0.2561\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 69.1398 - accuracy: 0.2569 - val_loss: 64.5206 - val_accuracy: 0.2681\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 67.5235 - accuracy: 0.2685 - val_loss: 62.9632 - val_accuracy: 0.2800\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65.9340 - accuracy: 0.2802 - val_loss: 61.4333 - val_accuracy: 0.2919\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 64.3782 - accuracy: 0.2918 - val_loss: 59.9375 - val_accuracy: 0.3038\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 62.8470 - accuracy: 0.3033 - val_loss: 58.4580 - val_accuracy: 0.3156\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 61.3374 - accuracy: 0.3149 - val_loss: 57.0074 - val_accuracy: 0.3274\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 59.8562 - accuracy: 0.3264 - val_loss: 55.5819 - val_accuracy: 0.3392\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 58.3928 - accuracy: 0.3377 - val_loss: 54.1749 - val_accuracy: 0.3509\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 56.9589 - accuracy: 0.3490 - val_loss: 52.7971 - val_accuracy: 0.3625\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 55.5469 - accuracy: 0.3601 - val_loss: 51.4405 - val_accuracy: 0.3742\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 54.1560 - accuracy: 0.3713 - val_loss: 50.1017 - val_accuracy: 0.3858\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 52.7903 - accuracy: 0.3826 - val_loss: 48.7935 - val_accuracy: 0.3974\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 51.4430 - accuracy: 0.3936 - val_loss: 47.4984 - val_accuracy: 0.4091\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 50.1089 - accuracy: 0.4048 - val_loss: 46.2189 - val_accuracy: 0.4209\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 48.8046 - accuracy: 0.4160 - val_loss: 44.9749 - val_accuracy: 0.4325\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 47.5301 - accuracy: 0.4272 - val_loss: 43.7531 - val_accuracy: 0.4441\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 46.2737 - accuracy: 0.4382 - val_loss: 42.5493 - val_accuracy: 0.4553\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 45.0358 - accuracy: 0.4488 - val_loss: 41.3687 - val_accuracy: 0.4662\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 43.8220 - accuracy: 0.4593 - val_loss: 40.2113 - val_accuracy: 0.4770\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 42.6332 - accuracy: 0.4698 - val_loss: 39.0753 - val_accuracy: 0.4878\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 41.4632 - accuracy: 0.4803 - val_loss: 37.9596 - val_accuracy: 0.4987\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 40.3085 - accuracy: 0.4908 - val_loss: 36.8577 - val_accuracy: 0.5096\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 39.1816 - accuracy: 0.5013 - val_loss: 35.7859 - val_accuracy: 0.5204\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 38.0785 - accuracy: 0.5118 - val_loss: 34.7368 - val_accuracy: 0.5313\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 36.9964 - accuracy: 0.5223 - val_loss: 33.7114 - val_accuracy: 0.5421\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 35.9389 - accuracy: 0.5328 - val_loss: 32.7087 - val_accuracy: 0.5528\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 34.9022 - accuracy: 0.5429 - val_loss: 31.7224 - val_accuracy: 0.5627\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 33.8770 - accuracy: 0.5524 - val_loss: 30.7519 - val_accuracy: 0.5724\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 32.8781 - accuracy: 0.5619 - val_loss: 29.8080 - val_accuracy: 0.5821\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 31.9085 - accuracy: 0.5715 - val_loss: 28.8974 - val_accuracy: 0.5916\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 30.9550 - accuracy: 0.5809 - val_loss: 27.9957 - val_accuracy: 0.6013\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 30.0279 - accuracy: 0.5904 - val_loss: 27.1263 - val_accuracy: 0.6109\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 29.1241 - accuracy: 0.5998 - val_loss: 26.2732 - val_accuracy: 0.6205\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 28.2322 - accuracy: 0.6092 - val_loss: 25.4374 - val_accuracy: 0.6302\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 27.3693 - accuracy: 0.6187 - val_loss: 24.6307 - val_accuracy: 0.6398\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.5267 - accuracy: 0.6281 - val_loss: 23.8382 - val_accuracy: 0.6487\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 25.7068 - accuracy: 0.6361 - val_loss: 23.0768 - val_accuracy: 0.6554\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 24.9099 - accuracy: 0.6436 - val_loss: 22.3305 - val_accuracy: 0.6622\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 24.1335 - accuracy: 0.6510 - val_loss: 21.6107 - val_accuracy: 0.6690\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 23.3740 - accuracy: 0.6584 - val_loss: 20.9057 - val_accuracy: 0.6758\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 22.6438 - accuracy: 0.6658 - val_loss: 20.2329 - val_accuracy: 0.6825\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 21.9326 - accuracy: 0.6732 - val_loss: 19.5704 - val_accuracy: 0.6893\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 21.2372 - accuracy: 0.6807 - val_loss: 18.9302 - val_accuracy: 0.6961\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 20.5697 - accuracy: 0.6881 - val_loss: 18.3219 - val_accuracy: 0.7028\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 19.9279 - accuracy: 0.6954 - val_loss: 17.7294 - val_accuracy: 0.7095\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 19.2992 - accuracy: 0.7025 - val_loss: 17.1534 - val_accuracy: 0.7148\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 18.6950 - accuracy: 0.7073 - val_loss: 16.6075 - val_accuracy: 0.7190\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 18.1122 - accuracy: 0.7121 - val_loss: 16.0748 - val_accuracy: 0.7232\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.5523 - accuracy: 0.7167 - val_loss: 15.5744 - val_accuracy: 0.7272\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.0197 - accuracy: 0.7213 - val_loss: 15.0939 - val_accuracy: 0.7313\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.5010 - accuracy: 0.7260 - val_loss: 14.6256 - val_accuracy: 0.7355\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.0041 - accuracy: 0.7307 - val_loss: 14.1834 - val_accuracy: 0.7397\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.5250 - accuracy: 0.7353 - val_loss: 13.7591 - val_accuracy: 0.7438\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.0774 - accuracy: 0.7400 - val_loss: 13.3688 - val_accuracy: 0.7478\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.6499 - accuracy: 0.7446 - val_loss: 12.9899 - val_accuracy: 0.7520\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.2411 - accuracy: 0.7480 - val_loss: 12.6357 - val_accuracy: 0.7535\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.8510 - accuracy: 0.7491 - val_loss: 12.2996 - val_accuracy: 0.7545\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.4925 - accuracy: 0.7499 - val_loss: 11.9947 - val_accuracy: 0.7554\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.1483 - accuracy: 0.7510 - val_loss: 11.7014 - val_accuracy: 0.7563\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.8209 - accuracy: 0.7518 - val_loss: 11.4275 - val_accuracy: 0.7573\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.5189 - accuracy: 0.7527 - val_loss: 11.1799 - val_accuracy: 0.7582\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.2423 - accuracy: 0.7536 - val_loss: 10.9561 - val_accuracy: 0.7591\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.9855 - accuracy: 0.7546 - val_loss: 10.7491 - val_accuracy: 0.7600\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.7468 - accuracy: 0.7555 - val_loss: 10.5615 - val_accuracy: 0.7609\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 11.5280 - accuracy: 0.7564 - val_loss: 10.3972 - val_accuracy: 0.7618\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 11.3382 - accuracy: 0.7562 - val_loss: 10.2547 - val_accuracy: 0.7598\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.1632 - accuracy: 0.7539 - val_loss: 10.1300 - val_accuracy: 0.7569\n",
      "Epoch 81/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.0060 - accuracy: 0.7513 - val_loss: 10.0226 - val_accuracy: 0.7541\n",
      "Epoch 82/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.8661 - accuracy: 0.7489 - val_loss: 9.9317 - val_accuracy: 0.7511\n",
      "Epoch 83/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.7521 - accuracy: 0.7464 - val_loss: 9.8680 - val_accuracy: 0.7485\n",
      "21/21 - 0s - loss: 9.8680 - accuracy: 0.7485 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 10ms/step - loss: 37.9751 - accuracy: 0.5441 - val_loss: 9.4131 - val_accuracy: 0.8155\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.7103 - accuracy: 0.8075 - val_loss: 6.5481 - val_accuracy: 0.8294\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.1054 - accuracy: 0.8166 - val_loss: 6.5105 - val_accuracy: 0.8077\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.9237 - accuracy: 0.8132 - val_loss: 6.2368 - val_accuracy: 0.8216\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.7221 - accuracy: 0.8175 - val_loss: 6.0957 - val_accuracy: 0.8241\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5061 - accuracy: 0.8229 - val_loss: 5.8485 - val_accuracy: 0.8250\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1467 - accuracy: 0.8285 - val_loss: 5.7529 - val_accuracy: 0.8148\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.8103 - accuracy: 0.8328 - val_loss: 5.0446 - val_accuracy: 0.8477\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.4741 - accuracy: 0.8387 - val_loss: 4.9957 - val_accuracy: 0.8344\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.2257 - accuracy: 0.8423 - val_loss: 5.3699 - val_accuracy: 0.8033\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0615 - accuracy: 0.8422 - val_loss: 4.8402 - val_accuracy: 0.8351\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.9909 - accuracy: 0.8444 - val_loss: 4.5864 - val_accuracy: 0.8517\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9028 - accuracy: 0.8470 - val_loss: 4.8589 - val_accuracy: 0.8241\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8517 - accuracy: 0.8461 - val_loss: 4.5058 - val_accuracy: 0.8426\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7338 - accuracy: 0.8470 - val_loss: 4.6229 - val_accuracy: 0.8458\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7966 - accuracy: 0.8463 - val_loss: 4.4936 - val_accuracy: 0.8523\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7272 - accuracy: 0.8457 - val_loss: 4.6995 - val_accuracy: 0.8282\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7841 - accuracy: 0.8471 - val_loss: 4.4077 - val_accuracy: 0.8513\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7114 - accuracy: 0.8489 - val_loss: 4.7208 - val_accuracy: 0.8365\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6536 - accuracy: 0.8476 - val_loss: 4.7703 - val_accuracy: 0.8444\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.5535 - accuracy: 0.8508 - val_loss: 4.9339 - val_accuracy: 0.8157\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.7792 - accuracy: 0.8418 - val_loss: 4.3076 - val_accuracy: 0.8558\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5325 - accuracy: 0.8514 - val_loss: 4.7070 - val_accuracy: 0.8264\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4641 - accuracy: 0.8506 - val_loss: 4.3574 - val_accuracy: 0.8520\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4728 - accuracy: 0.8521 - val_loss: 4.3533 - val_accuracy: 0.8438\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4101 - accuracy: 0.8534 - val_loss: 4.6462 - val_accuracy: 0.8303\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4568 - accuracy: 0.8522 - val_loss: 5.3974 - val_accuracy: 0.8075\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6372 - accuracy: 0.8465 - val_loss: 4.2733 - val_accuracy: 0.8505\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3947 - accuracy: 0.8535 - val_loss: 4.4276 - val_accuracy: 0.8337\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.4309 - accuracy: 0.8521 - val_loss: 4.5367 - val_accuracy: 0.8343\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.4025 - accuracy: 0.8515 - val_loss: 4.3258 - val_accuracy: 0.8473\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5201 - accuracy: 0.8492 - val_loss: 4.3104 - val_accuracy: 0.8496\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4458 - accuracy: 0.8516 - val_loss: 4.7632 - val_accuracy: 0.8163\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3885 - accuracy: 0.8524 - val_loss: 4.2731 - val_accuracy: 0.8539\n",
      "21/21 - 0s - loss: 4.2731 - accuracy: 0.8539 - 43ms/epoch - 2ms/step\n",
      "Best hyperparameters: {'activation': 'tanh', 'batch_size': 32, 'optimizer': 'sgd', 'dropout': 'no'}\n",
      "Best validation accuracy: 0.8571187257766724\n"
     ]
    }
   ],
   "source": [
    "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용X)\n",
    "act_func = ['relu', 'tanh']\n",
    "batch_lst = [8, 16, 32, 64, 128]\n",
    "opt_lst = ['adam', 'rmsprop', 'sgd']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            # 모델 구현\n",
    "            model = Sequential()\n",
    "            model.add(Dense(64, activation=func, input_dim=x.shape[1]))\n",
    "            model.add(Dense(32, activation=func))              \n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(4, activation=func))\n",
    "            model.add(Dense(1, activation='linear'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(loss='mse', optimizer=opti, metrics=[accuracy])\n",
    "\n",
    "            # early stopping 구현 - 커스텀 정확도 기준\n",
    "            early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'optimizer': opti, 'dropout': 'no'}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST MODEL\n",
    "1. early stopping을 통해 정확도가 높은 모델 선정\n",
    "\n",
    "2. 검증 데이터를 통해 검증 정확도가 높은 모델 선정 - 과적합 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'activation': 'tanh', 'batch_size': 32, 'optimizer': 'sgd', 'dropout': 'no'}\n",
      "Best accuracy: 0.8571187257766724\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best accuracy:', best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[안내] 모델이 실행됩니다.\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 13.5313 - accuracy: 0.7575 - val_loss: 7.3383 - val_accuracy: 0.7576\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.2903 - accuracy: 0.8226 - val_loss: 6.3149 - val_accuracy: 0.8223\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4810 - accuracy: 0.8344 - val_loss: 4.9085 - val_accuracy: 0.8352\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2057 - accuracy: 0.8381 - val_loss: 5.2294 - val_accuracy: 0.8051\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0363 - accuracy: 0.8402 - val_loss: 4.5126 - val_accuracy: 0.8513\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8435 - accuracy: 0.8448 - val_loss: 4.9233 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7926 - accuracy: 0.8445 - val_loss: 4.6663 - val_accuracy: 0.8236\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6748 - accuracy: 0.8466 - val_loss: 4.4445 - val_accuracy: 0.8392\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7245 - accuracy: 0.8458 - val_loss: 4.4625 - val_accuracy: 0.8362\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6081 - accuracy: 0.8463 - val_loss: 4.4224 - val_accuracy: 0.8580\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6589 - accuracy: 0.8471 - val_loss: 4.3952 - val_accuracy: 0.8426\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5481 - accuracy: 0.8503 - val_loss: 4.2798 - val_accuracy: 0.8556\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5250 - accuracy: 0.8479 - val_loss: 4.7666 - val_accuracy: 0.8437\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6017 - accuracy: 0.8468 - val_loss: 4.4020 - val_accuracy: 0.8478\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4885 - accuracy: 0.8475 - val_loss: 5.6330 - val_accuracy: 0.8288\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5399 - accuracy: 0.8475 - val_loss: 4.5743 - val_accuracy: 0.8357\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4681 - accuracy: 0.8514 - val_loss: 4.3446 - val_accuracy: 0.8550\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4849 - accuracy: 0.8515 - val_loss: 4.3708 - val_accuracy: 0.8484\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3935 - accuracy: 0.8522 - val_loss: 4.2507 - val_accuracy: 0.8546\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4843 - accuracy: 0.8490 - val_loss: 4.1961 - val_accuracy: 0.8462\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3963 - accuracy: 0.8500 - val_loss: 4.2363 - val_accuracy: 0.8493\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3189 - accuracy: 0.8518 - val_loss: 4.7057 - val_accuracy: 0.8297\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3220 - accuracy: 0.8514 - val_loss: 4.2688 - val_accuracy: 0.8462\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3753 - accuracy: 0.8517 - val_loss: 4.3364 - val_accuracy: 0.8436\n",
      "131/131 [==============================] - 0s 1ms/step\n",
      "[안내] 최종 모델\n",
      "[안내] train loss, accuracy\n",
      "84/84 - 0s - loss: 4.1426 - accuracy: 0.8550 - 122ms/epoch - 1ms/step\n",
      "[안내] validation loss, accuracy\n",
      "21/21 - 0s - loss: 4.3364 - accuracy: 0.8436 - 45ms/epoch - 2ms/step\n",
      "[안내] 실행 시간 : 6.070 seconds\n",
      "[안내] 샘플 10개의 결과\n",
      "      Rings       pred\n",
      "1437      6   6.981085\n",
      "728      13  12.539680\n",
      "3470     11  12.399845\n",
      "2856     11   9.402239\n",
      "1178      9  11.320084\n",
      "1061      6   5.034081\n",
      "2467     16  11.640235\n",
      "2486     13  14.279268\n",
      "3289     15  11.623315\n",
      "850      10  11.831802\n"
     ]
    }
   ],
   "source": [
    "# 최고 모델 사용자 친화적 구현\n",
    "start_time = time.time()\n",
    "print(\"[안내] 모델이 실행됩니다.\")\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='tanh', input_dim=x.shape[1]))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "model.add(Dense(4, activation='tanh'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=[accuracy])\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "\n",
    "if input_2 == 'y':\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    y_pred = model.predict(X)\n",
    "else:\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "print(\"[안내] 최종 모델\")\n",
    "if input_2 == 'y':\n",
    "    print(\"[안내] train loss, accuracy\")\n",
    "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "    print(\"[안내] validation loss, accuracy\")\n",
    "    loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "else:\n",
    "    print(\"[안내] train loss, accuracy\")\n",
    "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "    print(\"[안내] test loss, accuracy\")\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"[안내] 실행 시간 : {:.3f} seconds\".format(execution_time))\n",
    "\n",
    "input_3 = input(\"[안내] 예측 샘플을 확인할까요? : \")\n",
    "if input_3 == 'y':\n",
    "    print(\"[안내] 샘플 10개의 결과\")\n",
    "    new_y = y\n",
    "    stacked_array = np.vstack((y_pred))\n",
    "    new_df = pd.DataFrame(stacked_array)\n",
    "    new_y = pd.DataFrame(new_y)\n",
    "    new_y['pred'] = new_df[0]\n",
    "    print(new_y.sample(10))\n",
    "else:\n",
    "    print(\"[안내] 실행을 종료합니다.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model Advanced\n",
    "실행 샘플 데이터 - 분포가 많은 값으로 예측한 것으로 추측\n",
    "-> dropout 을 사용한 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[안내] 모델이 실행됩니다.\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 2s 4ms/step - loss: 39.9279 - accuracy: 0.4857 - val_loss: 8.6186 - val_accuracy: 0.8031\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 20.1747 - accuracy: 0.6566 - val_loss: 6.0916 - val_accuracy: 0.8434\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 17.6490 - accuracy: 0.6749 - val_loss: 6.9548 - val_accuracy: 0.8296\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 16.1590 - accuracy: 0.6954 - val_loss: 6.1991 - val_accuracy: 0.8353\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.0945 - accuracy: 0.7142 - val_loss: 5.5175 - val_accuracy: 0.8501\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.4944 - accuracy: 0.7231 - val_loss: 5.3725 - val_accuracy: 0.8489\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.3775 - accuracy: 0.7276 - val_loss: 4.9858 - val_accuracy: 0.8444\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.6834 - accuracy: 0.7342 - val_loss: 5.4584 - val_accuracy: 0.8511\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.5178 - accuracy: 0.7424 - val_loss: 5.7562 - val_accuracy: 0.8473\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.4888 - accuracy: 0.7435 - val_loss: 5.5588 - val_accuracy: 0.8508\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.5177 - accuracy: 0.7576 - val_loss: 4.8759 - val_accuracy: 0.8488\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.1149 - accuracy: 0.7544 - val_loss: 4.8450 - val_accuracy: 0.8576\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.8062 - accuracy: 0.7565 - val_loss: 4.4886 - val_accuracy: 0.8519\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.0953 - accuracy: 0.7615 - val_loss: 4.5862 - val_accuracy: 0.8542\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.3795 - accuracy: 0.7593 - val_loss: 5.2512 - val_accuracy: 0.8560\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4866 - accuracy: 0.7667 - val_loss: 4.8480 - val_accuracy: 0.8583\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7910 - accuracy: 0.7643 - val_loss: 4.4812 - val_accuracy: 0.8543\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.5229 - accuracy: 0.7696 - val_loss: 4.8556 - val_accuracy: 0.8571\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.7444 - accuracy: 0.7647 - val_loss: 4.6316 - val_accuracy: 0.8570\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.4380 - accuracy: 0.7761 - val_loss: 4.6377 - val_accuracy: 0.8544\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0565 - accuracy: 0.7705 - val_loss: 4.5018 - val_accuracy: 0.8510\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.0488 - accuracy: 0.7778 - val_loss: 4.5816 - val_accuracy: 0.8517\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.8714 - accuracy: 0.7757 - val_loss: 4.6215 - val_accuracy: 0.8584\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.1445 - accuracy: 0.7747 - val_loss: 5.2088 - val_accuracy: 0.8516\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2436 - accuracy: 0.7786 - val_loss: 4.4895 - val_accuracy: 0.8555\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.2391 - accuracy: 0.7768 - val_loss: 4.8947 - val_accuracy: 0.8556\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.1836 - accuracy: 0.7784 - val_loss: 4.8641 - val_accuracy: 0.8545\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.0100 - accuracy: 0.7786 - val_loss: 4.7892 - val_accuracy: 0.8539\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.4178 - accuracy: 0.7806 - val_loss: 4.8472 - val_accuracy: 0.8517\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.7472 - accuracy: 0.7787 - val_loss: 4.7063 - val_accuracy: 0.8546\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.5463 - accuracy: 0.7822 - val_loss: 4.4561 - val_accuracy: 0.8577\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.8055 - accuracy: 0.7808 - val_loss: 4.4568 - val_accuracy: 0.8535\n",
      "Epoch 33/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.6386 - accuracy: 0.7822 - val_loss: 4.5633 - val_accuracy: 0.8575\n",
      "Epoch 34/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.4872 - accuracy: 0.7836 - val_loss: 4.4552 - val_accuracy: 0.8575\n",
      "Epoch 35/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.2146 - accuracy: 0.7859 - val_loss: 4.6959 - val_accuracy: 0.8585\n",
      "Epoch 36/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.7069 - accuracy: 0.7855 - val_loss: 4.6098 - val_accuracy: 0.8571\n",
      "Epoch 37/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.4483 - accuracy: 0.7877 - val_loss: 4.5887 - val_accuracy: 0.8533\n",
      "Epoch 38/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.3307 - accuracy: 0.7882 - val_loss: 4.4735 - val_accuracy: 0.8562\n",
      "Epoch 39/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.0840 - accuracy: 0.7926 - val_loss: 4.4850 - val_accuracy: 0.8541\n",
      "Epoch 40/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.9249 - accuracy: 0.7928 - val_loss: 4.4458 - val_accuracy: 0.8505\n",
      "Epoch 41/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.8769 - accuracy: 0.7918 - val_loss: 4.5169 - val_accuracy: 0.8540\n",
      "Epoch 42/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.0534 - accuracy: 0.7890 - val_loss: 4.8471 - val_accuracy: 0.8563\n",
      "Epoch 43/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.9671 - accuracy: 0.7933 - val_loss: 4.5205 - val_accuracy: 0.8532\n",
      "Epoch 44/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6005 - accuracy: 0.7944 - val_loss: 4.8622 - val_accuracy: 0.8571\n",
      "Epoch 45/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.0278 - accuracy: 0.7931 - val_loss: 4.5445 - val_accuracy: 0.8558\n",
      "Epoch 46/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6723 - accuracy: 0.7959 - val_loss: 4.6080 - val_accuracy: 0.8549\n",
      "Epoch 47/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.7742 - accuracy: 0.7964 - val_loss: 4.4834 - val_accuracy: 0.8537\n",
      "Epoch 48/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.9700 - accuracy: 0.7929 - val_loss: 4.4830 - val_accuracy: 0.8559\n",
      "Epoch 49/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6440 - accuracy: 0.7956 - val_loss: 4.4421 - val_accuracy: 0.8549\n",
      "Epoch 50/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1991 - accuracy: 0.7998 - val_loss: 4.4663 - val_accuracy: 0.8458\n",
      "Epoch 51/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.1652 - accuracy: 0.7936 - val_loss: 4.3798 - val_accuracy: 0.8534\n",
      "Epoch 52/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3027 - accuracy: 0.8017 - val_loss: 4.6045 - val_accuracy: 0.8554\n",
      "Epoch 53/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2316 - accuracy: 0.8006 - val_loss: 4.4725 - val_accuracy: 0.8542\n",
      "Epoch 54/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6984 - accuracy: 0.7982 - val_loss: 4.5271 - val_accuracy: 0.8526\n",
      "Epoch 55/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1169 - accuracy: 0.8036 - val_loss: 4.4601 - val_accuracy: 0.8561\n",
      "Epoch 56/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1679 - accuracy: 0.8049 - val_loss: 4.3654 - val_accuracy: 0.8538\n",
      "Epoch 57/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3688 - accuracy: 0.8014 - val_loss: 4.4303 - val_accuracy: 0.8514\n",
      "Epoch 58/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0960 - accuracy: 0.8039 - val_loss: 4.6401 - val_accuracy: 0.8549\n",
      "Epoch 59/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0917 - accuracy: 0.8002 - val_loss: 4.5175 - val_accuracy: 0.8543\n",
      "Epoch 60/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.7652 - accuracy: 0.8070 - val_loss: 4.5803 - val_accuracy: 0.8569\n",
      "Epoch 61/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.4458 - accuracy: 0.8012 - val_loss: 4.5434 - val_accuracy: 0.8565\n",
      "Epoch 62/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.9221 - accuracy: 0.8064 - val_loss: 4.4815 - val_accuracy: 0.8475\n",
      "Epoch 63/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.8650 - accuracy: 0.8089 - val_loss: 4.3782 - val_accuracy: 0.8531\n",
      "Epoch 64/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3848 - accuracy: 0.8033 - val_loss: 4.4291 - val_accuracy: 0.8535\n",
      "Epoch 65/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0464 - accuracy: 0.8053 - val_loss: 4.5372 - val_accuracy: 0.8565\n",
      "Epoch 66/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.8615 - accuracy: 0.8106 - val_loss: 4.3668 - val_accuracy: 0.8531\n",
      "Epoch 67/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0829 - accuracy: 0.8084 - val_loss: 4.4676 - val_accuracy: 0.8526\n",
      "Epoch 68/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6813 - accuracy: 0.8088 - val_loss: 4.7473 - val_accuracy: 0.8551\n",
      "Epoch 69/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6875 - accuracy: 0.8090 - val_loss: 4.5200 - val_accuracy: 0.8555\n",
      "Epoch 70/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6861 - accuracy: 0.8131 - val_loss: 4.5730 - val_accuracy: 0.8558\n",
      "Epoch 71/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5822 - accuracy: 0.8127 - val_loss: 4.5358 - val_accuracy: 0.8564\n",
      "Epoch 72/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6742 - accuracy: 0.8112 - val_loss: 4.3864 - val_accuracy: 0.8448\n",
      "Epoch 73/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.4608 - accuracy: 0.8136 - val_loss: 4.3269 - val_accuracy: 0.8526\n",
      "Epoch 74/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.7052 - accuracy: 0.8097 - val_loss: 4.4375 - val_accuracy: 0.8445\n",
      "Epoch 75/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6639 - accuracy: 0.8121 - val_loss: 4.5474 - val_accuracy: 0.8523\n",
      "Epoch 76/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0832 - accuracy: 0.8084 - val_loss: 4.3439 - val_accuracy: 0.8498\n",
      "Epoch 77/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.4022 - accuracy: 0.8141 - val_loss: 4.2696 - val_accuracy: 0.8559\n",
      "Epoch 78/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.4580 - accuracy: 0.8113 - val_loss: 4.4619 - val_accuracy: 0.8530\n",
      "Epoch 79/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.3734 - accuracy: 0.8165 - val_loss: 4.3176 - val_accuracy: 0.8486\n",
      "Epoch 80/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0675 - accuracy: 0.8202 - val_loss: 4.2993 - val_accuracy: 0.8508\n",
      "Epoch 81/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4367 - accuracy: 0.8158 - val_loss: 4.3873 - val_accuracy: 0.8460\n",
      "Epoch 82/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1866 - accuracy: 0.8192 - val_loss: 4.3710 - val_accuracy: 0.8517\n",
      "Epoch 83/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7897 - accuracy: 0.8113 - val_loss: 4.5201 - val_accuracy: 0.8511\n",
      "Epoch 84/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0256 - accuracy: 0.8175 - val_loss: 4.3808 - val_accuracy: 0.8478\n",
      "Epoch 85/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3108 - accuracy: 0.8174 - val_loss: 4.3463 - val_accuracy: 0.8468\n",
      "131/131 [==============================] - 0s 1ms/step\n",
      "[안내] 최종 모델\n",
      "[안내] train loss, accuracy\n",
      "84/84 - 0s - loss: 3.7997 - accuracy: 0.8607 - 125ms/epoch - 1ms/step\n",
      "[안내] validation loss, accuracy\n",
      "21/21 - 0s - loss: 4.3463 - accuracy: 0.8468 - 52ms/epoch - 2ms/step\n",
      "[안내] 실행 시간 : 19.306 seconds\n",
      "[안내] 샘플 10개의 결과\n",
      "      Rings       pred\n",
      "41       14  11.026981\n",
      "2398     14   9.980166\n",
      "534      10   9.393583\n",
      "4063     11  11.600614\n",
      "2330      9   8.405786\n",
      "2369     12  14.531243\n",
      "1855      9   7.935930\n",
      "2974     12  10.983240\n",
      "679       8   8.640882\n",
      "1218      5   6.573978\n"
     ]
    }
   ],
   "source": [
    "# 최고 모델 사용자 친화적 구현\n",
    "start_time = time.time()\n",
    "print(\"[안내] 모델이 실행됩니다.\")\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=x.shape[1]))\n",
    "model.add(Dropout(0.1))  # Dropout 추가\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.1))  # Dropout 추가\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))  # Dropout 추가\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.1))  # Dropout 추가\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dropout(0.1))  # Dropout 추가\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[accuracy])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "\n",
    "if input_2 == 'y':\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    y_pred = model.predict(X)\n",
    "else:\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "print(\"[안내] 최종 모델\")\n",
    "if input_2 == 'y':\n",
    "    print(\"[안내] train loss, accuracy\")\n",
    "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "    print(\"[안내] validation loss, accuracy\")\n",
    "    loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "else:\n",
    "    print(\"[안내] train loss, accuracy\")\n",
    "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "    print(\"[안내] test loss, accuracy\")\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"[안내] 실행 시간 : {:.3f} seconds\".format(execution_time))\n",
    "\n",
    "input_3 = input(\"[안내] 예측 샘플을 확인할까요? : \")\n",
    "if input_3 == 'y':\n",
    "    print(\"[안내] 샘플 10개의 결과\")\n",
    "    new_y = y\n",
    "    stacked_array = np.vstack((y_pred))\n",
    "    new_df = pd.DataFrame(stacked_array)\n",
    "    new_y = pd.DataFrame(new_y)\n",
    "    new_y['pred'] = new_df[0]\n",
    "    print(new_y.sample(10))\n",
    "else:\n",
    "    print(\"[안내] 실행을 종료합니다.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 model 구현\n",
    "* 고려사항\n",
    "\n",
    "1. 실행시간이 짧은 Best Model 1번 사용\n",
    "\n",
    "2. 사용자 친화적 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저로 부터 입력을 받아 검증 데이터 셋을 사용할 것인지, 표준화를 사용할 것인지 정함.\n",
    "def create_best():\n",
    "    print(\"[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\")\n",
    "    input_1 = input(\"[안내] 데이터를 표준화 하시겠습니까? : \")\n",
    "    input_2 = input(\"[안내] 검증 데이터셋을 분리할까요? : \")\n",
    "\n",
    "    # 표준화 진행 여부\n",
    "    if input_1 == 'y':\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(x)\n",
    "        print(\"[안내] 데이터 표준화를 진행했습니다.\")\n",
    "    else:\n",
    "        X = x\n",
    "        print(\"[안내] 데이터 표준화를 진행하지 않습니다.\")\n",
    "\n",
    "    # 검증 데이터 진행 여부\n",
    "    if input_2 == 'y':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "        print(\"[안내] 검증 데이터를 추가로 분리했습니다.\")\n",
    "\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(\"[안내] 검증 데이터를 분리하지 않았습니다.\")\n",
    "\n",
    "    # 최고 모델 사용자 친화적 구현\n",
    "    start_time = time.time()\n",
    "    print(\"[안내] 모델이 실행됩니다.\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='tanh', input_dim=x.shape[1]))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dense(8, activation='tanh'))\n",
    "    model.add(Dense(4, activation='tanh'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='sgd', metrics=[accuracy])\n",
    "    early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "\n",
    "    if input_2 == 'y':\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        y_pred = model.predict(X)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "    print(\"[안내] 최종 모델\")\n",
    "    if input_2 == 'y':\n",
    "        print(\"[안내] train loss, accuracy\")\n",
    "        train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "        print(\"[안내] validation loss, accuracy\")\n",
    "        loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "    else:\n",
    "        print(\"[안내] train loss, accuracy\")\n",
    "        train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "        print(\"[안내] test loss, accuracy\")\n",
    "        loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    print(\"[안내] 실행 시간 : {:.3f} seconds\".format(execution_time))\n",
    "\n",
    "    input_3 = input(\"[안내] 예측 샘플을 확인할까요? : \")\n",
    "    if input_3 == 'y':\n",
    "        print(\"[안내] 샘플 10개의 결과\")\n",
    "        new_y = y\n",
    "        stacked_array = np.vstack((y_pred))\n",
    "        new_df = pd.DataFrame(stacked_array)\n",
    "        new_y = pd.DataFrame(new_y)\n",
    "        new_y['pred'] = new_df[0]\n",
    "        print(new_y.sample(10))\n",
    "        print(\"[안내] 실행을 종료합니다.\")\n",
    "\n",
    "    else:\n",
    "        print(\"[안내] 실행을 종료합니다.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\n",
      "[안내] 데이터 표준화를 진행했습니다.\n",
      "[안내] 검증 데이터를 추가로 분리했습니다.\n",
      "[안내] 모델이 실행됩니다.\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 14.8807 - accuracy: 0.7425 - val_loss: 6.8556 - val_accuracy: 0.7796\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.4742 - accuracy: 0.8189 - val_loss: 6.0546 - val_accuracy: 0.8004\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4681 - accuracy: 0.8347 - val_loss: 5.6419 - val_accuracy: 0.7908\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1346 - accuracy: 0.8383 - val_loss: 5.2808 - val_accuracy: 0.8156\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0836 - accuracy: 0.8383 - val_loss: 4.9870 - val_accuracy: 0.8370\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8500 - accuracy: 0.8452 - val_loss: 5.0930 - val_accuracy: 0.8229\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7599 - accuracy: 0.8456 - val_loss: 4.6503 - val_accuracy: 0.8341\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7465 - accuracy: 0.8449 - val_loss: 4.7282 - val_accuracy: 0.8400\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6223 - accuracy: 0.8487 - val_loss: 4.6614 - val_accuracy: 0.8440\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5859 - accuracy: 0.8476 - val_loss: 4.9642 - val_accuracy: 0.8084\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5688 - accuracy: 0.8473 - val_loss: 5.5856 - val_accuracy: 0.8205\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4998 - accuracy: 0.8502 - val_loss: 5.2856 - val_accuracy: 0.7932\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4561 - accuracy: 0.8516 - val_loss: 4.5705 - val_accuracy: 0.8486\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5058 - accuracy: 0.8495 - val_loss: 4.3193 - val_accuracy: 0.8497\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4128 - accuracy: 0.8515 - val_loss: 4.8551 - val_accuracy: 0.8252\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4178 - accuracy: 0.8514 - val_loss: 5.9671 - val_accuracy: 0.7804\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5043 - accuracy: 0.8480 - val_loss: 4.3322 - val_accuracy: 0.8435\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3307 - accuracy: 0.8522 - val_loss: 4.4643 - val_accuracy: 0.8449\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3723 - accuracy: 0.8514 - val_loss: 4.3455 - val_accuracy: 0.8463\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3511 - accuracy: 0.8510 - val_loss: 4.3745 - val_accuracy: 0.8514\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3122 - accuracy: 0.8520 - val_loss: 4.3747 - val_accuracy: 0.8416\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2808 - accuracy: 0.8533 - val_loss: 4.5865 - val_accuracy: 0.8427\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3376 - accuracy: 0.8512 - val_loss: 4.9135 - val_accuracy: 0.8107\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2942 - accuracy: 0.8518 - val_loss: 4.4367 - val_accuracy: 0.8389\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2715 - accuracy: 0.8525 - val_loss: 4.4740 - val_accuracy: 0.8354\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2872 - accuracy: 0.8529 - val_loss: 4.7518 - val_accuracy: 0.8339\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2789 - accuracy: 0.8531 - val_loss: 4.5857 - val_accuracy: 0.8274\n",
      "131/131 [==============================] - 0s 943us/step\n",
      "[안내] 최종 모델\n",
      "[안내] train loss, accuracy\n",
      "84/84 - 0s - loss: 4.2456 - accuracy: 0.8389 - 96ms/epoch - 1ms/step\n",
      "[안내] validation loss, accuracy\n",
      "21/21 - 0s - loss: 4.5857 - accuracy: 0.8274 - 43ms/epoch - 2ms/step\n",
      "[안내] 실행 시간 : 5.841 seconds\n",
      "[안내] 샘플 10개의 결과\n",
      "      Rings       pred\n",
      "2183      6  15.308678\n",
      "1033     10  13.749382\n",
      "1779      9   7.927064\n",
      "2590      8  10.104479\n",
      "248       7   6.621666\n",
      "2931      9  10.401048\n",
      "3664      9  10.256289\n",
      "2276     14  14.942583\n",
      "1082      7   7.944169\n",
      "3249      6   7.652831\n",
      "[안내] 실행을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "create_best()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
