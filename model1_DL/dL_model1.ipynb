{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Regression_data_preprocessing.csv')\n",
    "target = 'Rings'\n",
    "y = df[target]\n",
    "x = df.drop(target, axis =1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 배치 정규화 - 사용 X\n",
    "배치 정규화는 일반적으로 분류(classification) 문제에서 성능 향상에 더 많이 사용됩니다. 이는 배치 정규화가 입력 데이터의 분포를 정규화하고, 이를 통해 다음 층으로 전달되는 값을 안정화시키기 때문입니다.\n",
    "\n",
    "### 2. Dropout - 성능에 따라 사용\n",
    "드롭아웃은 분류(classification) 문제에서 주로 사용되는 정규화 방법이지만, 회귀(regression) 문제에서도 일부 경우에 사용될 수 있습니다. 회귀 모델에서 드롭아웃을 사용하면, 모델이 특정 입력값에 과도하게 의존하는 것을 방지하여 일반화 성능을 향상시킬 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 활성화 함수\n",
    "1. Relu:\n",
    " 입력층(input layer)과 은닉층(hidden layer)에서는 일반적으로 ReLU(Rectified Linear Unit) 활성화 함수가 많이 사용됩니다. ReLU 함수는 계산이 간단하고, 학습 속도가 빠르며, 특정 입력값에 대해 미분 가능하기 때문에, 딥러닝 모델에서 가장 많이 사용되는 활성화 함수 중 하나입니다.\n",
    "\n",
    "2. tanh:\n",
    " 입력값의 범위가 -1에서 1 사이인 경우에는 하이퍼볼릭 탄젠트(tanh) 함수를 사용하는 것이 좋습니다. 이는 입력값이 크거나 작을 때 출력값이 포화되는 문제를 해결할 수 있기 때문입니다. 따라서 입력값의 범위에 따라 적절한 활성화 함수를 선택하는 것이 좋습니다.\n",
    "\n",
    "3. sigmoid:\n",
    " 입력값을 0과 1 사이의 값으로 변환하는 함수로, 이진 분류(binary classification) 문제에서 출력층의 활성화 함수로 많이 사용됩니다. 하지만 회귀(regression) 문제에서는 선형 모델과 달리 출력값이 제한되지 않아야 하므로, sigmoid 함수를 활성화 함수로 사용하는 것은 적합하지 않습니다.\n",
    "\n",
    " 4. linear:\n",
    " 회귀 문제에서는 출력층의 활성화 함수로 linear 함수를 사용하는 것이 적합합니다. linear 함수는 입력값과 동일한 값을 출력하므로, 출력값의 범위가 제한되지 않습니다. 따라서 linear 함수를 사용하면 모델이 임의의 값을 예측할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\n",
      "[안내] 데이터 표준화를 진행했습니다.\n",
      "[안내] 검증 데이터를 추가로 분리했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 유저로 부터 입력을 받아 검증 데이터 셋을 사용할 것인지, 표준화를 사용할 것인지 정함.\n",
    "print(\"[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\")\n",
    "input_1 = input(\"[안내] 데이터를 표준화 하시겠습니까? : \")\n",
    "input_2 = input(\"[안내] 검증 데이터셋을 분리할까요? : \")\n",
    "\n",
    "# 표준화 진행 여부\n",
    "if input_1 == 'y':\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(x)\n",
    "    print(\"[안내] 데이터 표준화를 진행했습니다.\")\n",
    "else:\n",
    "    X = x\n",
    "    print(\"[안내] 데이터 표준화를 진행하지 않습니다.\")\n",
    "\n",
    "# 검증 데이터 진행 여부\n",
    "if input_2 == 'y':\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    print(\"[안내] 검증 데이터를 추가로 분리했습니다.\")\n",
    "\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"[안내] 검증 데이터를 분리하지 않았습니다.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현\n",
    "\n",
    "1. SGD (Stochastic Gradient Descent):\n",
    "가장 기본적인 옵티마이저로, 경사 하강법의 확률적인 버전입니다.\n",
    "각 학습 단계에서 미니 배치(mini-batch) 단위로 데이터를 사용하여 가중치를 업데이트합니다.\n",
    "단순하고 직관적인 방법이지만, 수렴 속도가 느리고 지역 최소값(local minimum)에 빠질 가능성이 있습니다.\n",
    "\n",
    "2. Adam (Adaptive Moment Estimation):\n",
    "학습률(learning rate)을 조정하는 방법을 통해 경사 하강법을 개선한 알고리즘입니다.\n",
    "학습 속도를 개선하기 위해 모멘텀(Momentum)과 학습률 스케줄링(learning rate scheduling)을 조합합니다.\n",
    "이동 평균(moving average)을 사용하여 각 가중치의 업데이트 속도를 조절하며, 자동으로 적응적인 학습률을 제공합니다.\n",
    "다양한 유형의 신경망 구조와 데이터에 대해 일반적으로 좋은 성능을 보입니다.\n",
    "\n",
    "3. RMSProp (Root Mean Square Propagation):\n",
    "과거 그래디언트(gradient)의 제곱을 이동 평균하여 학습률을 조정하는 알고리즘입니다.\n",
    "최근 그래디언트에 더 큰 가중치를 부여하여 중요한 그래디언트를 잘 반영합니다.\n",
    "이동 평균을 사용하여 각 가중치의 업데이트 속도를 조절하며, 최적의 학습률을 자동으로 조정합니다.\n",
    "비교적 안정적인 학습을 제공하고, RNN(Recurrent Neural Network)과 같은 모델에서 잘 작동하는 경향이 있습니다.\n",
    "\n",
    "### 정확도 \n",
    "- custom metric 사용 : 절대 비율 오차 (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method_custom_metric 구현\n",
    "def accuracy(y_true, y_pred):\n",
    "    return 1 - tf.abs((y_true - y_pred) / y_true) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
    }
   ],
   "source": [
    "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용)\n",
    "act_func = ['relu', 'tanh']\n",
    "batch_lst = [8, 16, 32, 64, 128]\n",
    "opt_lst = ['adam', 'rmsprop', 'sgd']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            # 모델 구현\n",
    "            model = Sequential()\n",
    "            model.add(Dense(64, activation=func, input_dim=x.shape[1]))\n",
    "            model.add(Dropout(0.1))  # Dropout 추가\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(Dropout(0.1))  # Dropout 추가               \n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dropout(0.1))  # Dropout 추가\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dropout(0.1))  # Dropout 추가\n",
    "            model.add(Dense(4, activation=func))\n",
    "            model.add(Dropout(0.1))  # Dropout 추가\n",
    "            model.add(Dense(1, activation='linear'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(loss='mse', optimizer=opti, metrics=[accuracy])\n",
    "\n",
    "            # early stopping 구현 - 커스텀 정확도 기준\n",
    "            early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'optimizer': opti}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "334/334 [==============================] - 2s 2ms/step - loss: 18.6853 - accuracy: 0.7046 - val_loss: 5.0992 - val_accuracy: 0.8370\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.1359 - accuracy: 0.8382 - val_loss: 5.2181 - val_accuracy: 0.8197\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.0109 - accuracy: 0.8408 - val_loss: 5.0025 - val_accuracy: 0.8310\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8810 - accuracy: 0.8411 - val_loss: 4.6525 - val_accuracy: 0.8431\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8224 - accuracy: 0.8434 - val_loss: 4.5981 - val_accuracy: 0.8486\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7843 - accuracy: 0.8423 - val_loss: 4.8164 - val_accuracy: 0.8281\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6960 - accuracy: 0.8480 - val_loss: 4.8386 - val_accuracy: 0.8294\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6808 - accuracy: 0.8460 - val_loss: 4.9789 - val_accuracy: 0.8360\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6979 - accuracy: 0.8447 - val_loss: 4.4701 - val_accuracy: 0.8499\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7155 - accuracy: 0.8454 - val_loss: 5.1075 - val_accuracy: 0.8168\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6486 - accuracy: 0.8460 - val_loss: 4.8815 - val_accuracy: 0.8206\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6754 - accuracy: 0.8451 - val_loss: 4.5009 - val_accuracy: 0.8511\n",
      "21/21 - 0s - loss: 4.5009 - accuracy: 0.8511 - 39ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 24.0886 - accuracy: 0.6624 - val_loss: 5.7785 - val_accuracy: 0.8215\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3864 - accuracy: 0.8330 - val_loss: 5.2247 - val_accuracy: 0.8089\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.1316 - accuracy: 0.8378 - val_loss: 4.6639 - val_accuracy: 0.8434\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9265 - accuracy: 0.8401 - val_loss: 4.8849 - val_accuracy: 0.8246\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8602 - accuracy: 0.8417 - val_loss: 4.5495 - val_accuracy: 0.8512\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7817 - accuracy: 0.8432 - val_loss: 4.7108 - val_accuracy: 0.8299\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7306 - accuracy: 0.8438 - val_loss: 4.6018 - val_accuracy: 0.8465\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6948 - accuracy: 0.8449 - val_loss: 4.6870 - val_accuracy: 0.8234\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6406 - accuracy: 0.8445 - val_loss: 4.6170 - val_accuracy: 0.8406\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6430 - accuracy: 0.8443 - val_loss: 4.4452 - val_accuracy: 0.8492\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5647 - accuracy: 0.8467 - val_loss: 4.5096 - val_accuracy: 0.8485\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5897 - accuracy: 0.8474 - val_loss: 4.5767 - val_accuracy: 0.8365\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5668 - accuracy: 0.8465 - val_loss: 4.4447 - val_accuracy: 0.8510\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5396 - accuracy: 0.8480 - val_loss: 4.6108 - val_accuracy: 0.8287\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5328 - accuracy: 0.8484 - val_loss: 4.6379 - val_accuracy: 0.8379\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4699 - accuracy: 0.8497 - val_loss: 4.5080 - val_accuracy: 0.8398\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4608 - accuracy: 0.8491 - val_loss: 4.4511 - val_accuracy: 0.8442\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4303 - accuracy: 0.8499 - val_loss: 4.7718 - val_accuracy: 0.8269\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4411 - accuracy: 0.8490 - val_loss: 4.6316 - val_accuracy: 0.8307\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4421 - accuracy: 0.8496 - val_loss: 4.4186 - val_accuracy: 0.8503\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4433 - accuracy: 0.8505 - val_loss: 4.6950 - val_accuracy: 0.8245\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4142 - accuracy: 0.8505 - val_loss: 4.4353 - val_accuracy: 0.8540\n",
      "Epoch 23/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3792 - accuracy: 0.8503 - val_loss: 4.4914 - val_accuracy: 0.8475\n",
      "Epoch 24/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4282 - accuracy: 0.8507 - val_loss: 4.5700 - val_accuracy: 0.8328\n",
      "Epoch 25/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3503 - accuracy: 0.8513 - val_loss: 5.3838 - val_accuracy: 0.8098\n",
      "Epoch 26/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3032 - accuracy: 0.8515 - val_loss: 4.5272 - val_accuracy: 0.8385\n",
      "Epoch 27/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2872 - accuracy: 0.8514 - val_loss: 4.6909 - val_accuracy: 0.8273\n",
      "Epoch 28/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3421 - accuracy: 0.8504 - val_loss: 4.3797 - val_accuracy: 0.8486\n",
      "Epoch 29/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3070 - accuracy: 0.8515 - val_loss: 4.8433 - val_accuracy: 0.8260\n",
      "Epoch 30/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2884 - accuracy: 0.8522 - val_loss: 4.4760 - val_accuracy: 0.8399\n",
      "Epoch 31/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2967 - accuracy: 0.8507 - val_loss: 4.8525 - val_accuracy: 0.8190\n",
      "Epoch 32/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2904 - accuracy: 0.8503 - val_loss: 4.5238 - val_accuracy: 0.8516\n",
      "Epoch 33/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2384 - accuracy: 0.8515 - val_loss: 4.3680 - val_accuracy: 0.8457\n",
      "Epoch 34/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2773 - accuracy: 0.8529 - val_loss: 4.5667 - val_accuracy: 0.8555\n",
      "Epoch 35/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2577 - accuracy: 0.8520 - val_loss: 4.6386 - val_accuracy: 0.8424\n",
      "Epoch 36/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1915 - accuracy: 0.8532 - val_loss: 5.2971 - val_accuracy: 0.8110\n",
      "Epoch 37/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2799 - accuracy: 0.8523 - val_loss: 5.2361 - val_accuracy: 0.8190\n",
      "Epoch 38/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2486 - accuracy: 0.8518 - val_loss: 4.8247 - val_accuracy: 0.8272\n",
      "Epoch 39/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1947 - accuracy: 0.8538 - val_loss: 4.7246 - val_accuracy: 0.8300\n",
      "Epoch 40/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2318 - accuracy: 0.8528 - val_loss: 4.3539 - val_accuracy: 0.8425\n",
      "Epoch 41/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2025 - accuracy: 0.8531 - val_loss: 4.3799 - val_accuracy: 0.8474\n",
      "Epoch 42/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2040 - accuracy: 0.8535 - val_loss: 4.8745 - val_accuracy: 0.8246\n",
      "Epoch 43/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1861 - accuracy: 0.8539 - val_loss: 4.3846 - val_accuracy: 0.8430\n",
      "Epoch 44/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1939 - accuracy: 0.8537 - val_loss: 4.4253 - val_accuracy: 0.8439\n",
      "Epoch 45/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2038 - accuracy: 0.8533 - val_loss: 4.3404 - val_accuracy: 0.8469\n",
      "Epoch 46/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2096 - accuracy: 0.8543 - val_loss: 4.4197 - val_accuracy: 0.8486\n",
      "Epoch 47/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1280 - accuracy: 0.8550 - val_loss: 4.7639 - val_accuracy: 0.8242\n",
      "Epoch 48/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1819 - accuracy: 0.8542 - val_loss: 4.6619 - val_accuracy: 0.8380\n",
      "Epoch 49/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1161 - accuracy: 0.8550 - val_loss: 4.4532 - val_accuracy: 0.8373\n",
      "Epoch 50/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1376 - accuracy: 0.8553 - val_loss: 4.5041 - val_accuracy: 0.8515\n",
      "Epoch 51/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1350 - accuracy: 0.8551 - val_loss: 4.4905 - val_accuracy: 0.8392\n",
      "Epoch 52/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1400 - accuracy: 0.8547 - val_loss: 4.7220 - val_accuracy: 0.8297\n",
      "Epoch 53/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1230 - accuracy: 0.8547 - val_loss: 4.6451 - val_accuracy: 0.8349\n",
      "Epoch 54/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.1379 - accuracy: 0.8538 - val_loss: 4.3444 - val_accuracy: 0.8537\n",
      "Epoch 55/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.0843 - accuracy: 0.8551 - val_loss: 4.5508 - val_accuracy: 0.8505\n",
      "21/21 - 0s - loss: 4.5508 - accuracy: 0.8505 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.3449 - accuracy: 0.7921 - val_loss: 5.3990 - val_accuracy: 0.8182\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.5474 - accuracy: 0.8302 - val_loss: 5.0017 - val_accuracy: 0.8277\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.4108 - accuracy: 0.8305 - val_loss: 5.7493 - val_accuracy: 0.8195\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6400 - accuracy: 0.8255 - val_loss: 4.9778 - val_accuracy: 0.8512\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2653 - accuracy: 0.8305 - val_loss: 7.3214 - val_accuracy: 0.7292\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.3111 - accuracy: 0.8324 - val_loss: 5.0915 - val_accuracy: 0.8060\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.0856 - accuracy: 0.8345 - val_loss: 4.3639 - val_accuracy: 0.8455\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.4693 - accuracy: 0.8267 - val_loss: 4.7826 - val_accuracy: 0.8529\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.0432 - accuracy: 0.8348 - val_loss: 5.5047 - val_accuracy: 0.8242\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2071 - accuracy: 0.8335 - val_loss: 4.6698 - val_accuracy: 0.8542\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9610 - accuracy: 0.8386 - val_loss: 5.7869 - val_accuracy: 0.7732\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9717 - accuracy: 0.8392 - val_loss: 4.4400 - val_accuracy: 0.8558\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9598 - accuracy: 0.8382 - val_loss: 4.5905 - val_accuracy: 0.8477\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9921 - accuracy: 0.8392 - val_loss: 4.5994 - val_accuracy: 0.8588\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9160 - accuracy: 0.8383 - val_loss: 5.0001 - val_accuracy: 0.8115\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8054 - accuracy: 0.8404 - val_loss: 4.8825 - val_accuracy: 0.8309\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8076 - accuracy: 0.8398 - val_loss: 4.4409 - val_accuracy: 0.8453\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7416 - accuracy: 0.8413 - val_loss: 4.6312 - val_accuracy: 0.8292\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 4.6755 - accuracy: 0.8423 - val_loss: 5.4609 - val_accuracy: 0.8010\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8148 - accuracy: 0.8402 - val_loss: 4.3629 - val_accuracy: 0.8542\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 4.5460 - accuracy: 0.8445 - val_loss: 4.6890 - val_accuracy: 0.8391\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7484 - accuracy: 0.8426 - val_loss: 4.3953 - val_accuracy: 0.8502\n",
      "Epoch 23/1000\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 4.6095 - accuracy: 0.8425 - val_loss: 4.5582 - val_accuracy: 0.8514\n",
      "Epoch 24/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6107 - accuracy: 0.8428 - val_loss: 5.3762 - val_accuracy: 0.8335\n",
      "Epoch 25/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6198 - accuracy: 0.8422 - val_loss: 4.5856 - val_accuracy: 0.8459\n",
      "Epoch 26/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6503 - accuracy: 0.8440 - val_loss: 4.5892 - val_accuracy: 0.8279\n",
      "21/21 - 0s - loss: 4.5892 - accuracy: 0.8279 - 40ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 2s 3ms/step - loss: 31.1135 - accuracy: 0.5804 - val_loss: 5.7559 - val_accuracy: 0.8191\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.4787 - accuracy: 0.8314 - val_loss: 4.8525 - val_accuracy: 0.8430\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0121 - accuracy: 0.8378 - val_loss: 4.6724 - val_accuracy: 0.8473\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.8536 - accuracy: 0.8421 - val_loss: 4.5852 - val_accuracy: 0.8426\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.8656 - accuracy: 0.8428 - val_loss: 4.6591 - val_accuracy: 0.8363\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6795 - accuracy: 0.8440 - val_loss: 5.0636 - val_accuracy: 0.8235\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6690 - accuracy: 0.8455 - val_loss: 5.5780 - val_accuracy: 0.8086\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6691 - accuracy: 0.8452 - val_loss: 4.7828 - val_accuracy: 0.8265\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6061 - accuracy: 0.8475 - val_loss: 4.9126 - val_accuracy: 0.8244\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5869 - accuracy: 0.8468 - val_loss: 4.5665 - val_accuracy: 0.8342\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 4.5284 - accuracy: 0.8476 - val_loss: 4.6920 - val_accuracy: 0.8550\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4952 - accuracy: 0.8480 - val_loss: 4.8089 - val_accuracy: 0.8401\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4661 - accuracy: 0.8509 - val_loss: 4.7748 - val_accuracy: 0.8354\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4532 - accuracy: 0.8486 - val_loss: 4.6942 - val_accuracy: 0.8322\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3907 - accuracy: 0.8525 - val_loss: 4.8856 - val_accuracy: 0.8323\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4106 - accuracy: 0.8509 - val_loss: 4.4687 - val_accuracy: 0.8447\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4622 - accuracy: 0.8502 - val_loss: 4.7279 - val_accuracy: 0.8302\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4180 - accuracy: 0.8499 - val_loss: 4.4836 - val_accuracy: 0.8412\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3929 - accuracy: 0.8522 - val_loss: 4.4408 - val_accuracy: 0.8481\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4489 - accuracy: 0.8502 - val_loss: 4.5061 - val_accuracy: 0.8485\n",
      "21/21 - 0s - loss: 4.5061 - accuracy: 0.8485 - 45ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 2ms/step - loss: 34.9731 - accuracy: 0.5411 - val_loss: 9.2808 - val_accuracy: 0.7484\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 6.0519 - accuracy: 0.8228 - val_loss: 5.1624 - val_accuracy: 0.8305\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.1053 - accuracy: 0.8368 - val_loss: 4.8969 - val_accuracy: 0.8275\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.9110 - accuracy: 0.8411 - val_loss: 4.7860 - val_accuracy: 0.8336\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7980 - accuracy: 0.8433 - val_loss: 4.6909 - val_accuracy: 0.8523\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7709 - accuracy: 0.8443 - val_loss: 4.6280 - val_accuracy: 0.8445\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7264 - accuracy: 0.8443 - val_loss: 4.9277 - val_accuracy: 0.8168\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6605 - accuracy: 0.8462 - val_loss: 5.1358 - val_accuracy: 0.8157\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6770 - accuracy: 0.8468 - val_loss: 4.5519 - val_accuracy: 0.8480\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6418 - accuracy: 0.8469 - val_loss: 4.6895 - val_accuracy: 0.8350\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6275 - accuracy: 0.8476 - val_loss: 4.6219 - val_accuracy: 0.8306\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5619 - accuracy: 0.8475 - val_loss: 4.6653 - val_accuracy: 0.8398\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5479 - accuracy: 0.8469 - val_loss: 4.5343 - val_accuracy: 0.8539\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5245 - accuracy: 0.8485 - val_loss: 4.5120 - val_accuracy: 0.8488\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5325 - accuracy: 0.8479 - val_loss: 4.5045 - val_accuracy: 0.8536\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4857 - accuracy: 0.8494 - val_loss: 4.4890 - val_accuracy: 0.8517\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4395 - accuracy: 0.8499 - val_loss: 4.5219 - val_accuracy: 0.8369\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4451 - accuracy: 0.8500 - val_loss: 4.5249 - val_accuracy: 0.8410\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4502 - accuracy: 0.8495 - val_loss: 4.5588 - val_accuracy: 0.8553\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4319 - accuracy: 0.8504 - val_loss: 4.5944 - val_accuracy: 0.8406\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4716 - accuracy: 0.8508 - val_loss: 4.8487 - val_accuracy: 0.8197\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3940 - accuracy: 0.8512 - val_loss: 4.7038 - val_accuracy: 0.8303\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3607 - accuracy: 0.8508 - val_loss: 4.5277 - val_accuracy: 0.8434\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3979 - accuracy: 0.8505 - val_loss: 4.5497 - val_accuracy: 0.8379\n",
      "Epoch 25/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3856 - accuracy: 0.8510 - val_loss: 4.4266 - val_accuracy: 0.8428\n",
      "Epoch 26/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3846 - accuracy: 0.8522 - val_loss: 4.3241 - val_accuracy: 0.8475\n",
      "Epoch 27/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3681 - accuracy: 0.8512 - val_loss: 4.3231 - val_accuracy: 0.8514\n",
      "Epoch 28/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3811 - accuracy: 0.8531 - val_loss: 4.4743 - val_accuracy: 0.8353\n",
      "Epoch 29/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3381 - accuracy: 0.8520 - val_loss: 4.3802 - val_accuracy: 0.8506\n",
      "Epoch 30/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3356 - accuracy: 0.8520 - val_loss: 4.4121 - val_accuracy: 0.8507\n",
      "Epoch 31/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3569 - accuracy: 0.8504 - val_loss: 4.4206 - val_accuracy: 0.8553\n",
      "Epoch 32/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3171 - accuracy: 0.8526 - val_loss: 4.4218 - val_accuracy: 0.8431\n",
      "Epoch 33/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3200 - accuracy: 0.8529 - val_loss: 4.3992 - val_accuracy: 0.8460\n",
      "21/21 - 0s - loss: 4.3992 - accuracy: 0.8460 - 57ms/epoch - 3ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 19.1751 - accuracy: 0.7034 - val_loss: 6.2040 - val_accuracy: 0.7753\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.2951 - accuracy: 0.8340 - val_loss: 5.0147 - val_accuracy: 0.8134\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 5.0168 - accuracy: 0.8384 - val_loss: 4.8430 - val_accuracy: 0.8170\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.9985 - accuracy: 0.8405 - val_loss: 4.7699 - val_accuracy: 0.8548\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0375 - accuracy: 0.8386 - val_loss: 4.4597 - val_accuracy: 0.8515\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7330 - accuracy: 0.8442 - val_loss: 4.5079 - val_accuracy: 0.8507\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.8078 - accuracy: 0.8427 - val_loss: 4.7498 - val_accuracy: 0.8208\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7027 - accuracy: 0.8451 - val_loss: 4.5023 - val_accuracy: 0.8443\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5590 - accuracy: 0.8445 - val_loss: 4.6202 - val_accuracy: 0.8315\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5403 - accuracy: 0.8459 - val_loss: 4.8638 - val_accuracy: 0.8539\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6400 - accuracy: 0.8446 - val_loss: 4.7148 - val_accuracy: 0.8301\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5968 - accuracy: 0.8448 - val_loss: 4.5667 - val_accuracy: 0.8576\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5508 - accuracy: 0.8463 - val_loss: 4.4301 - val_accuracy: 0.8547\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 4.5502 - accuracy: 0.8465 - val_loss: 4.3515 - val_accuracy: 0.8507\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5150 - accuracy: 0.8482 - val_loss: 4.4951 - val_accuracy: 0.8366\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5368 - accuracy: 0.8460 - val_loss: 4.3311 - val_accuracy: 0.8496\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4847 - accuracy: 0.8486 - val_loss: 4.4591 - val_accuracy: 0.8421\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4139 - accuracy: 0.8491 - val_loss: 4.6000 - val_accuracy: 0.8282\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4352 - accuracy: 0.8478 - val_loss: 4.3681 - val_accuracy: 0.8547\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5776 - accuracy: 0.8468 - val_loss: 4.2244 - val_accuracy: 0.8521\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5003 - accuracy: 0.8465 - val_loss: 4.4491 - val_accuracy: 0.8370\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4320 - accuracy: 0.8487 - val_loss: 4.3547 - val_accuracy: 0.8560\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3744 - accuracy: 0.8488 - val_loss: 4.3845 - val_accuracy: 0.8477\n",
      "21/21 - 0s - loss: 4.3845 - accuracy: 0.8477 - 40ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 52.4122 - accuracy: 0.3968 - val_loss: 13.4720 - val_accuracy: 0.7240\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4244 - accuracy: 0.7884 - val_loss: 5.7292 - val_accuracy: 0.8277\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5918 - accuracy: 0.8285 - val_loss: 5.0734 - val_accuracy: 0.8378\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1571 - accuracy: 0.8376 - val_loss: 5.2934 - val_accuracy: 0.8223\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0031 - accuracy: 0.8391 - val_loss: 4.9102 - val_accuracy: 0.8287\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8695 - accuracy: 0.8407 - val_loss: 4.7633 - val_accuracy: 0.8405\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7701 - accuracy: 0.8448 - val_loss: 4.6828 - val_accuracy: 0.8342\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7123 - accuracy: 0.8435 - val_loss: 4.6804 - val_accuracy: 0.8396\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7347 - accuracy: 0.8448 - val_loss: 4.6192 - val_accuracy: 0.8369\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6689 - accuracy: 0.8453 - val_loss: 4.8528 - val_accuracy: 0.8314\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7078 - accuracy: 0.8448 - val_loss: 4.5803 - val_accuracy: 0.8440\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6234 - accuracy: 0.8468 - val_loss: 4.8117 - val_accuracy: 0.8292\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5742 - accuracy: 0.8476 - val_loss: 4.6018 - val_accuracy: 0.8414\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5634 - accuracy: 0.8477 - val_loss: 4.5429 - val_accuracy: 0.8430\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5649 - accuracy: 0.8480 - val_loss: 4.5309 - val_accuracy: 0.8489\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4947 - accuracy: 0.8499 - val_loss: 4.5134 - val_accuracy: 0.8447\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5362 - accuracy: 0.8492 - val_loss: 4.4860 - val_accuracy: 0.8399\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5052 - accuracy: 0.8485 - val_loss: 4.4944 - val_accuracy: 0.8482\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5237 - accuracy: 0.8481 - val_loss: 4.6465 - val_accuracy: 0.8525\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4566 - accuracy: 0.8505 - val_loss: 4.4461 - val_accuracy: 0.8441\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4159 - accuracy: 0.8497 - val_loss: 4.6511 - val_accuracy: 0.8356\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4029 - accuracy: 0.8505 - val_loss: 4.4372 - val_accuracy: 0.8434\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4109 - accuracy: 0.8504 - val_loss: 4.6291 - val_accuracy: 0.8456\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3654 - accuracy: 0.8518 - val_loss: 4.5268 - val_accuracy: 0.8427\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4035 - accuracy: 0.8494 - val_loss: 4.5355 - val_accuracy: 0.8400\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4134 - accuracy: 0.8503 - val_loss: 4.4798 - val_accuracy: 0.8410\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3928 - accuracy: 0.8507 - val_loss: 4.4126 - val_accuracy: 0.8523\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3379 - accuracy: 0.8515 - val_loss: 4.4396 - val_accuracy: 0.8484\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4272 - accuracy: 0.8506 - val_loss: 4.4656 - val_accuracy: 0.8542\n",
      "21/21 - 0s - loss: 4.4656 - accuracy: 0.8542 - 56ms/epoch - 3ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 5ms/step - loss: 36.4011 - accuracy: 0.5262 - val_loss: 9.0295 - val_accuracy: 0.7650\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 6.2936 - accuracy: 0.8208 - val_loss: 5.2335 - val_accuracy: 0.8475\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1958 - accuracy: 0.8378 - val_loss: 4.8635 - val_accuracy: 0.8388\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9931 - accuracy: 0.8397 - val_loss: 5.7654 - val_accuracy: 0.7867\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8668 - accuracy: 0.8415 - val_loss: 4.6070 - val_accuracy: 0.8435\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7665 - accuracy: 0.8441 - val_loss: 4.6438 - val_accuracy: 0.8394\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7370 - accuracy: 0.8440 - val_loss: 4.7536 - val_accuracy: 0.8361\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7031 - accuracy: 0.8453 - val_loss: 5.0991 - val_accuracy: 0.8157\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6203 - accuracy: 0.8468 - val_loss: 5.3418 - val_accuracy: 0.8212\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6075 - accuracy: 0.8459 - val_loss: 4.5848 - val_accuracy: 0.8541\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5922 - accuracy: 0.8479 - val_loss: 4.4323 - val_accuracy: 0.8476\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5112 - accuracy: 0.8493 - val_loss: 4.4889 - val_accuracy: 0.8485\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5259 - accuracy: 0.8483 - val_loss: 4.5543 - val_accuracy: 0.8371\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4657 - accuracy: 0.8501 - val_loss: 4.5343 - val_accuracy: 0.8462\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4593 - accuracy: 0.8492 - val_loss: 4.4697 - val_accuracy: 0.8517\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4876 - accuracy: 0.8489 - val_loss: 4.6872 - val_accuracy: 0.8341\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4252 - accuracy: 0.8503 - val_loss: 4.5614 - val_accuracy: 0.8571\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4198 - accuracy: 0.8507 - val_loss: 4.4041 - val_accuracy: 0.8493\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3929 - accuracy: 0.8504 - val_loss: 5.2646 - val_accuracy: 0.7992\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4138 - accuracy: 0.8498 - val_loss: 4.3703 - val_accuracy: 0.8464\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3954 - accuracy: 0.8511 - val_loss: 4.5215 - val_accuracy: 0.8330\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3880 - accuracy: 0.8501 - val_loss: 4.3844 - val_accuracy: 0.8455\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3551 - accuracy: 0.8531 - val_loss: 5.0933 - val_accuracy: 0.8104\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3594 - accuracy: 0.8513 - val_loss: 4.7847 - val_accuracy: 0.8165\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3149 - accuracy: 0.8520 - val_loss: 5.0091 - val_accuracy: 0.8281\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3513 - accuracy: 0.8521 - val_loss: 4.3793 - val_accuracy: 0.8477\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2934 - accuracy: 0.8525 - val_loss: 4.6058 - val_accuracy: 0.8422\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2839 - accuracy: 0.8521 - val_loss: 4.3528 - val_accuracy: 0.8485\n",
      "21/21 - 0s - loss: 4.3528 - accuracy: 0.8485 - 71ms/epoch - 3ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 28.7533 - accuracy: 0.6121 - val_loss: 11.7130 - val_accuracy: 0.7833\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.9891 - accuracy: 0.8230 - val_loss: 4.9476 - val_accuracy: 0.8470\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5173 - accuracy: 0.8344 - val_loss: 6.0651 - val_accuracy: 0.8003\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0017 - accuracy: 0.8405 - val_loss: 4.6875 - val_accuracy: 0.8537\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8328 - accuracy: 0.8446 - val_loss: 5.1873 - val_accuracy: 0.8336\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8324 - accuracy: 0.8450 - val_loss: 4.5253 - val_accuracy: 0.8466\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7488 - accuracy: 0.8452 - val_loss: 6.6328 - val_accuracy: 0.7837\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7391 - accuracy: 0.8451 - val_loss: 4.5586 - val_accuracy: 0.8585\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6670 - accuracy: 0.8466 - val_loss: 4.3938 - val_accuracy: 0.8486\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6287 - accuracy: 0.8477 - val_loss: 4.6135 - val_accuracy: 0.8306\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5955 - accuracy: 0.8486 - val_loss: 4.4760 - val_accuracy: 0.8443\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5005 - accuracy: 0.8497 - val_loss: 4.3720 - val_accuracy: 0.8586\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5369 - accuracy: 0.8492 - val_loss: 4.4194 - val_accuracy: 0.8421\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4886 - accuracy: 0.8508 - val_loss: 6.0989 - val_accuracy: 0.7720\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5329 - accuracy: 0.8482 - val_loss: 4.4191 - val_accuracy: 0.8542\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4241 - accuracy: 0.8524 - val_loss: 4.6631 - val_accuracy: 0.8360\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5892 - accuracy: 0.8472 - val_loss: 4.2216 - val_accuracy: 0.8538\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4737 - accuracy: 0.8508 - val_loss: 4.4570 - val_accuracy: 0.8423\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3803 - accuracy: 0.8510 - val_loss: 4.6086 - val_accuracy: 0.8517\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4370 - accuracy: 0.8503 - val_loss: 4.8641 - val_accuracy: 0.8193\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3817 - accuracy: 0.8512 - val_loss: 4.4180 - val_accuracy: 0.8538\n",
      "21/21 - 0s - loss: 4.4180 - accuracy: 0.8538 - 51ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 7ms/step - loss: 86.0810 - accuracy: 0.1490 - val_loss: 42.8116 - val_accuracy: 0.4472\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 23.0648 - accuracy: 0.6132 - val_loss: 12.2869 - val_accuracy: 0.7342\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 9.4296 - accuracy: 0.7666 - val_loss: 6.5959 - val_accuracy: 0.8125\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.0808 - accuracy: 0.8230 - val_loss: 5.2355 - val_accuracy: 0.8374\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.4099 - accuracy: 0.8334 - val_loss: 5.0860 - val_accuracy: 0.8347\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.1626 - accuracy: 0.8377 - val_loss: 4.8315 - val_accuracy: 0.8411\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.9953 - accuracy: 0.8397 - val_loss: 4.8999 - val_accuracy: 0.8318\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.9040 - accuracy: 0.8436 - val_loss: 4.6668 - val_accuracy: 0.8414\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.8145 - accuracy: 0.8423 - val_loss: 4.6864 - val_accuracy: 0.8408\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.7607 - accuracy: 0.8444 - val_loss: 4.7670 - val_accuracy: 0.8367\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6987 - accuracy: 0.8450 - val_loss: 4.6616 - val_accuracy: 0.8403\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6560 - accuracy: 0.8467 - val_loss: 4.5328 - val_accuracy: 0.8497\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6077 - accuracy: 0.8465 - val_loss: 4.5766 - val_accuracy: 0.8444\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5559 - accuracy: 0.8485 - val_loss: 4.5268 - val_accuracy: 0.8506\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6089 - accuracy: 0.8461 - val_loss: 4.5308 - val_accuracy: 0.8508\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5168 - accuracy: 0.8491 - val_loss: 4.9046 - val_accuracy: 0.8233\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 4.5519 - accuracy: 0.8478 - val_loss: 4.8839 - val_accuracy: 0.8236\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5065 - accuracy: 0.8486 - val_loss: 4.5088 - val_accuracy: 0.8431\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4985 - accuracy: 0.8481 - val_loss: 4.5076 - val_accuracy: 0.8513\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4670 - accuracy: 0.8500 - val_loss: 4.5971 - val_accuracy: 0.8418\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4458 - accuracy: 0.8480 - val_loss: 4.6236 - val_accuracy: 0.8519\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5296 - accuracy: 0.8476 - val_loss: 4.5086 - val_accuracy: 0.8456\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4945 - accuracy: 0.8490 - val_loss: 4.6458 - val_accuracy: 0.8355\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3922 - accuracy: 0.8496 - val_loss: 4.4449 - val_accuracy: 0.8491\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4403 - accuracy: 0.8502 - val_loss: 4.4829 - val_accuracy: 0.8482\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3642 - accuracy: 0.8510 - val_loss: 4.6437 - val_accuracy: 0.8399\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3866 - accuracy: 0.8512 - val_loss: 4.4586 - val_accuracy: 0.8473\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3828 - accuracy: 0.8502 - val_loss: 4.5068 - val_accuracy: 0.8485\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3396 - accuracy: 0.8527 - val_loss: 4.5957 - val_accuracy: 0.8372\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.3804 - accuracy: 0.8503 - val_loss: 4.6085 - val_accuracy: 0.8524\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.3907 - accuracy: 0.8527 - val_loss: 4.4358 - val_accuracy: 0.8457\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3250 - accuracy: 0.8532 - val_loss: 4.4831 - val_accuracy: 0.8403\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3103 - accuracy: 0.8528 - val_loss: 4.5127 - val_accuracy: 0.8372\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2954 - accuracy: 0.8527 - val_loss: 4.5699 - val_accuracy: 0.8327\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3297 - accuracy: 0.8519 - val_loss: 4.4602 - val_accuracy: 0.8436\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3017 - accuracy: 0.8541 - val_loss: 4.5137 - val_accuracy: 0.8419\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2846 - accuracy: 0.8525 - val_loss: 4.4264 - val_accuracy: 0.8462\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.2971 - accuracy: 0.8516 - val_loss: 4.4008 - val_accuracy: 0.8513\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2665 - accuracy: 0.8539 - val_loss: 4.5857 - val_accuracy: 0.8395\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2703 - accuracy: 0.8531 - val_loss: 4.5808 - val_accuracy: 0.8303\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2898 - accuracy: 0.8512 - val_loss: 4.4934 - val_accuracy: 0.8428\n",
      "21/21 - 0s - loss: 4.4934 - accuracy: 0.8428 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 89.0563 - accuracy: 0.1311 - val_loss: 52.5587 - val_accuracy: 0.3730\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 32.5588 - accuracy: 0.5274 - val_loss: 19.0497 - val_accuracy: 0.6495\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 15.0181 - accuracy: 0.6938 - val_loss: 9.6007 - val_accuracy: 0.7596\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.6319 - accuracy: 0.7948 - val_loss: 5.6884 - val_accuracy: 0.8386\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.6474 - accuracy: 0.8302 - val_loss: 5.1505 - val_accuracy: 0.8196\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.2869 - accuracy: 0.8342 - val_loss: 5.0231 - val_accuracy: 0.8281\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.1439 - accuracy: 0.8372 - val_loss: 4.8929 - val_accuracy: 0.8338\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.0076 - accuracy: 0.8397 - val_loss: 4.6779 - val_accuracy: 0.8383\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9600 - accuracy: 0.8409 - val_loss: 4.8048 - val_accuracy: 0.8302\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9399 - accuracy: 0.8402 - val_loss: 4.7323 - val_accuracy: 0.8539\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.8408 - accuracy: 0.8432 - val_loss: 4.7941 - val_accuracy: 0.8364\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.7916 - accuracy: 0.8432 - val_loss: 4.5924 - val_accuracy: 0.8478\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.7466 - accuracy: 0.8437 - val_loss: 4.5785 - val_accuracy: 0.8468\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.7368 - accuracy: 0.8446 - val_loss: 4.5753 - val_accuracy: 0.8496\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.7422 - accuracy: 0.8445 - val_loss: 4.6597 - val_accuracy: 0.8382\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 4.6880 - accuracy: 0.8443 - val_loss: 4.5793 - val_accuracy: 0.8497\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6779 - accuracy: 0.8460 - val_loss: 4.9789 - val_accuracy: 0.8159\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6916 - accuracy: 0.8449 - val_loss: 4.5613 - val_accuracy: 0.8427\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6433 - accuracy: 0.8453 - val_loss: 4.6204 - val_accuracy: 0.8397\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5820 - accuracy: 0.8465 - val_loss: 4.6144 - val_accuracy: 0.8538\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5855 - accuracy: 0.8468 - val_loss: 4.5352 - val_accuracy: 0.8517\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.6206 - accuracy: 0.8465 - val_loss: 5.0942 - val_accuracy: 0.8105\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5624 - accuracy: 0.8475 - val_loss: 4.5740 - val_accuracy: 0.8442\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5827 - accuracy: 0.8470 - val_loss: 4.6293 - val_accuracy: 0.8340\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5495 - accuracy: 0.8481 - val_loss: 4.5018 - val_accuracy: 0.8481\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5540 - accuracy: 0.8467 - val_loss: 4.5013 - val_accuracy: 0.8468\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5439 - accuracy: 0.8466 - val_loss: 4.6793 - val_accuracy: 0.8262\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5341 - accuracy: 0.8475 - val_loss: 4.6856 - val_accuracy: 0.8290\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4862 - accuracy: 0.8489 - val_loss: 4.6571 - val_accuracy: 0.8349\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5129 - accuracy: 0.8478 - val_loss: 4.4858 - val_accuracy: 0.8510\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4597 - accuracy: 0.8494 - val_loss: 4.4901 - val_accuracy: 0.8465\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5082 - accuracy: 0.8485 - val_loss: 4.6015 - val_accuracy: 0.8390\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4741 - accuracy: 0.8485 - val_loss: 4.4957 - val_accuracy: 0.8421\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4624 - accuracy: 0.8490 - val_loss: 4.4743 - val_accuracy: 0.8486\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4498 - accuracy: 0.8499 - val_loss: 4.4583 - val_accuracy: 0.8439\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4417 - accuracy: 0.8493 - val_loss: 4.4510 - val_accuracy: 0.8537\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4230 - accuracy: 0.8505 - val_loss: 4.5638 - val_accuracy: 0.8351\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4163 - accuracy: 0.8495 - val_loss: 4.5627 - val_accuracy: 0.8525\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.4366 - accuracy: 0.8499 - val_loss: 4.4208 - val_accuracy: 0.8483\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3968 - accuracy: 0.8501 - val_loss: 4.4133 - val_accuracy: 0.8498\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3807 - accuracy: 0.8502 - val_loss: 4.4169 - val_accuracy: 0.8440\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4179 - accuracy: 0.8501 - val_loss: 4.3981 - val_accuracy: 0.8487\n",
      "21/21 - 0s - loss: 4.3981 - accuracy: 0.8487 - 41ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 7ms/step - loss: 24.9720 - accuracy: 0.6345 - val_loss: 11.4233 - val_accuracy: 0.7910\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.0783 - accuracy: 0.8191 - val_loss: 6.0659 - val_accuracy: 0.8496\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.0191 - accuracy: 0.8253 - val_loss: 4.6938 - val_accuracy: 0.8563\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.5054 - accuracy: 0.8330 - val_loss: 4.7431 - val_accuracy: 0.8278\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.3073 - accuracy: 0.8338 - val_loss: 4.7596 - val_accuracy: 0.8302\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.8351 - accuracy: 0.8437 - val_loss: 5.6629 - val_accuracy: 0.7876\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5797 - accuracy: 0.8478 - val_loss: 5.0473 - val_accuracy: 0.8129\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9451 - accuracy: 0.8406 - val_loss: 4.6306 - val_accuracy: 0.8335\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9704 - accuracy: 0.8428 - val_loss: 4.4004 - val_accuracy: 0.8559\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9093 - accuracy: 0.8427 - val_loss: 4.3296 - val_accuracy: 0.8494\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 4.5845 - accuracy: 0.8466 - val_loss: 4.3832 - val_accuracy: 0.8401\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.6655 - accuracy: 0.8464 - val_loss: 4.6538 - val_accuracy: 0.8256\n",
      "21/21 - 0s - loss: 4.6538 - accuracy: 0.8256 - 85ms/epoch - 4ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 92.2642 - accuracy: 0.1059 - val_loss: 69.4446 - val_accuracy: 0.2456\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50.9764 - accuracy: 0.4015 - val_loss: 24.8749 - val_accuracy: 0.5911\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8691 - accuracy: 0.6463 - val_loss: 13.9915 - val_accuracy: 0.7212\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 10.4947 - accuracy: 0.7715 - val_loss: 8.0762 - val_accuracy: 0.7871\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1965 - accuracy: 0.8019 - val_loss: 6.2667 - val_accuracy: 0.8195\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.0826 - accuracy: 0.8242 - val_loss: 5.6242 - val_accuracy: 0.8216\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.6311 - accuracy: 0.8302 - val_loss: 5.3169 - val_accuracy: 0.8280\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.4166 - accuracy: 0.8317 - val_loss: 5.0793 - val_accuracy: 0.8316\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.2200 - accuracy: 0.8349 - val_loss: 4.9719 - val_accuracy: 0.8326\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0980 - accuracy: 0.8380 - val_loss: 4.9447 - val_accuracy: 0.8325\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.0044 - accuracy: 0.8403 - val_loss: 4.7790 - val_accuracy: 0.8368\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9175 - accuracy: 0.8406 - val_loss: 4.8900 - val_accuracy: 0.8289\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8541 - accuracy: 0.8416 - val_loss: 4.6966 - val_accuracy: 0.8372\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8046 - accuracy: 0.8436 - val_loss: 4.7801 - val_accuracy: 0.8318\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7731 - accuracy: 0.8427 - val_loss: 4.7181 - val_accuracy: 0.8350\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7038 - accuracy: 0.8441 - val_loss: 4.5872 - val_accuracy: 0.8437\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6946 - accuracy: 0.8464 - val_loss: 4.9620 - val_accuracy: 0.8225\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7875 - accuracy: 0.8431 - val_loss: 4.7877 - val_accuracy: 0.8320\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6347 - accuracy: 0.8463 - val_loss: 4.5456 - val_accuracy: 0.8429\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6025 - accuracy: 0.8461 - val_loss: 4.5133 - val_accuracy: 0.8467\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5629 - accuracy: 0.8479 - val_loss: 4.5970 - val_accuracy: 0.8376\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5553 - accuracy: 0.8467 - val_loss: 4.5286 - val_accuracy: 0.8441\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5442 - accuracy: 0.8469 - val_loss: 4.5033 - val_accuracy: 0.8456\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5116 - accuracy: 0.8488 - val_loss: 4.5186 - val_accuracy: 0.8432\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.4888 - accuracy: 0.8489 - val_loss: 4.5693 - val_accuracy: 0.8422\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4765 - accuracy: 0.8507 - val_loss: 4.4862 - val_accuracy: 0.8435\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4696 - accuracy: 0.8482 - val_loss: 4.5935 - val_accuracy: 0.8400\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4506 - accuracy: 0.8504 - val_loss: 4.5354 - val_accuracy: 0.8411\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4182 - accuracy: 0.8516 - val_loss: 4.6987 - val_accuracy: 0.8310\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.4726 - accuracy: 0.8452 - val_loss: 4.5853 - val_accuracy: 0.8387\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.4008 - accuracy: 0.8503 - val_loss: 4.4322 - val_accuracy: 0.8484\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.3738 - accuracy: 0.8511 - val_loss: 4.5276 - val_accuracy: 0.8378\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.3404 - accuracy: 0.8521 - val_loss: 4.5352 - val_accuracy: 0.8389\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3486 - accuracy: 0.8525 - val_loss: 4.5209 - val_accuracy: 0.8405\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3371 - accuracy: 0.8521 - val_loss: 4.5242 - val_accuracy: 0.8389\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3348 - accuracy: 0.8507 - val_loss: 4.5111 - val_accuracy: 0.8401\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.2974 - accuracy: 0.8532 - val_loss: 4.4319 - val_accuracy: 0.8464\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.2931 - accuracy: 0.8523 - val_loss: 4.4668 - val_accuracy: 0.8429\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.2937 - accuracy: 0.8529 - val_loss: 4.4339 - val_accuracy: 0.8451\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3165 - accuracy: 0.8529 - val_loss: 4.5648 - val_accuracy: 0.8368\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3214 - accuracy: 0.8497 - val_loss: 4.4433 - val_accuracy: 0.8448\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3140 - accuracy: 0.8532 - val_loss: 4.6504 - val_accuracy: 0.8356\n",
      "21/21 - 0s - loss: 4.6504 - accuracy: 0.8356 - 43ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 108.7167 - accuracy: 0.0079 - val_loss: 100.4018 - val_accuracy: 0.0293\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 96.1297 - accuracy: 0.0879 - val_loss: 76.3325 - val_accuracy: 0.2013\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 60.8287 - accuracy: 0.3350 - val_loss: 35.0776 - val_accuracy: 0.5113\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 27.6203 - accuracy: 0.5674 - val_loss: 19.5620 - val_accuracy: 0.6411\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.3850 - accuracy: 0.6676 - val_loss: 13.4686 - val_accuracy: 0.7133\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.3568 - accuracy: 0.7451 - val_loss: 8.9365 - val_accuracy: 0.7711\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6957 - accuracy: 0.8000 - val_loss: 6.6623 - val_accuracy: 0.8027\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.1811 - accuracy: 0.8209 - val_loss: 5.6518 - val_accuracy: 0.8229\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.7090 - accuracy: 0.8286 - val_loss: 5.3554 - val_accuracy: 0.8256\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.4090 - accuracy: 0.8327 - val_loss: 5.0679 - val_accuracy: 0.8435\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.2956 - accuracy: 0.8359 - val_loss: 5.0043 - val_accuracy: 0.8307\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.1195 - accuracy: 0.8375 - val_loss: 5.1708 - val_accuracy: 0.8247\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0667 - accuracy: 0.8390 - val_loss: 4.8199 - val_accuracy: 0.8392\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9809 - accuracy: 0.8405 - val_loss: 4.7538 - val_accuracy: 0.8428\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9046 - accuracy: 0.8409 - val_loss: 4.8476 - val_accuracy: 0.8337\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9173 - accuracy: 0.8412 - val_loss: 5.0944 - val_accuracy: 0.8267\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8625 - accuracy: 0.8427 - val_loss: 4.8403 - val_accuracy: 0.8258\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8075 - accuracy: 0.8430 - val_loss: 4.6432 - val_accuracy: 0.8487\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.7698 - accuracy: 0.8441 - val_loss: 4.7614 - val_accuracy: 0.8371\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7591 - accuracy: 0.8441 - val_loss: 4.7360 - val_accuracy: 0.8309\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7445 - accuracy: 0.8448 - val_loss: 4.6222 - val_accuracy: 0.8458\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7128 - accuracy: 0.8452 - val_loss: 4.6528 - val_accuracy: 0.8405\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7058 - accuracy: 0.8455 - val_loss: 4.6130 - val_accuracy: 0.8392\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.6548 - accuracy: 0.8457 - val_loss: 4.5981 - val_accuracy: 0.8448\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6571 - accuracy: 0.8465 - val_loss: 4.9590 - val_accuracy: 0.8178\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6678 - accuracy: 0.8440 - val_loss: 4.5597 - val_accuracy: 0.8521\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6359 - accuracy: 0.8451 - val_loss: 4.5235 - val_accuracy: 0.8487\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.5654 - accuracy: 0.8482 - val_loss: 4.7867 - val_accuracy: 0.8277\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5750 - accuracy: 0.8472 - val_loss: 4.7984 - val_accuracy: 0.8218\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.5590 - accuracy: 0.8476 - val_loss: 4.5960 - val_accuracy: 0.8382\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5483 - accuracy: 0.8479 - val_loss: 4.8769 - val_accuracy: 0.8260\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5783 - accuracy: 0.8471 - val_loss: 4.8561 - val_accuracy: 0.8275\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5665 - accuracy: 0.8470 - val_loss: 4.4977 - val_accuracy: 0.8461\n",
      "21/21 - 0s - loss: 4.4977 - accuracy: 0.8461 - 45ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 67.0547 - accuracy: 0.2884 - val_loss: 14.3937 - val_accuracy: 0.6281\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3720 - accuracy: 0.7891 - val_loss: 5.3157 - val_accuracy: 0.8351\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8611 - accuracy: 0.8057 - val_loss: 7.3852 - val_accuracy: 0.8360\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8273 - accuracy: 0.8070 - val_loss: 5.2951 - val_accuracy: 0.8385\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.8926 - accuracy: 0.8373 - val_loss: 4.8588 - val_accuracy: 0.8495\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9281 - accuracy: 0.8403 - val_loss: 5.0466 - val_accuracy: 0.8165\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.4091 - accuracy: 0.8331 - val_loss: 4.5989 - val_accuracy: 0.8459\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7646 - accuracy: 0.8435 - val_loss: 5.0369 - val_accuracy: 0.8539\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.0779 - accuracy: 0.8383 - val_loss: 4.5812 - val_accuracy: 0.8461\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6050 - accuracy: 0.8468 - val_loss: 4.7177 - val_accuracy: 0.8530\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.7919 - accuracy: 0.8451 - val_loss: 4.7311 - val_accuracy: 0.8342\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.0390 - accuracy: 0.8403 - val_loss: 5.2114 - val_accuracy: 0.8586\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7770 - accuracy: 0.8436 - val_loss: 4.5285 - val_accuracy: 0.8523\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8396 - accuracy: 0.8414 - val_loss: 4.6432 - val_accuracy: 0.8565\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7549 - accuracy: 0.8473 - val_loss: 5.1165 - val_accuracy: 0.8093\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5506 - accuracy: 0.8474 - val_loss: 4.4970 - val_accuracy: 0.8452\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.0357 - accuracy: 0.8403 - val_loss: 5.1026 - val_accuracy: 0.8125\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.5509 - accuracy: 0.8456 - val_loss: 4.4288 - val_accuracy: 0.8479\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.0795 - accuracy: 0.8421 - val_loss: 4.6446 - val_accuracy: 0.8292\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.7545 - accuracy: 0.8452 - val_loss: 4.5686 - val_accuracy: 0.8423\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8303 - accuracy: 0.8456 - val_loss: 4.8975 - val_accuracy: 0.8282\n",
      "21/21 - 0s - loss: 4.8975 - accuracy: 0.8282 - 41ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 2s 2ms/step - loss: 65.6094 - accuracy: 0.2854 - val_loss: 44.9715 - val_accuracy: 0.4322\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 39.5122 - accuracy: 0.5011 - val_loss: 29.5713 - val_accuracy: 0.5845\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 26.7689 - accuracy: 0.6241 - val_loss: 20.1409 - val_accuracy: 0.6834\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 18.9322 - accuracy: 0.7042 - val_loss: 14.6238 - val_accuracy: 0.7356\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 14.5487 - accuracy: 0.7427 - val_loss: 11.7172 - val_accuracy: 0.7563\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 12.0985 - accuracy: 0.7537 - val_loss: 10.3880 - val_accuracy: 0.7619\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 11.0314 - accuracy: 0.7509 - val_loss: 9.8977 - val_accuracy: 0.7499\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.6063 - accuracy: 0.7422 - val_loss: 9.7666 - val_accuracy: 0.7417\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4680 - accuracy: 0.7366 - val_loss: 9.7987 - val_accuracy: 0.7359\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4237 - accuracy: 0.7335 - val_loss: 9.7782 - val_accuracy: 0.7340\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4114 - accuracy: 0.7324 - val_loss: 9.7896 - val_accuracy: 0.7328\n",
      "21/21 - 0s - loss: 9.7896 - accuracy: 0.7328 - 49ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 60.1784 - accuracy: 0.3241 - val_loss: 40.7726 - val_accuracy: 0.4717\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 35.1697 - accuracy: 0.5397 - val_loss: 25.3767 - val_accuracy: 0.6309\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 21.9139 - accuracy: 0.6734 - val_loss: 15.4854 - val_accuracy: 0.7280\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 14.1978 - accuracy: 0.7445 - val_loss: 10.8181 - val_accuracy: 0.7597\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 11.0369 - accuracy: 0.7508 - val_loss: 9.7905 - val_accuracy: 0.7440\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4655 - accuracy: 0.7375 - val_loss: 9.7724 - val_accuracy: 0.7347\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4149 - accuracy: 0.7325 - val_loss: 9.7920 - val_accuracy: 0.7328\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4089 - accuracy: 0.7297 - val_loss: 9.7816 - val_accuracy: 0.7337\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4093 - accuracy: 0.7304 - val_loss: 9.7794 - val_accuracy: 0.7339\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.4137 - accuracy: 0.7316 - val_loss: 9.7900 - val_accuracy: 0.7329\n",
      "21/21 - 0s - loss: 9.7900 - accuracy: 0.7329 - 41ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9.0835 - accuracy: 0.7914 - val_loss: 5.6342 - val_accuracy: 0.8221\n",
      "Epoch 2/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.0052 - accuracy: 0.8196 - val_loss: 5.2185 - val_accuracy: 0.8547\n",
      "Epoch 3/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2965 - accuracy: 0.8304 - val_loss: 6.2448 - val_accuracy: 0.7742\n",
      "Epoch 4/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.2646 - accuracy: 0.8318 - val_loss: 5.2464 - val_accuracy: 0.8094\n",
      "Epoch 5/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.0407 - accuracy: 0.8335 - val_loss: 4.5117 - val_accuracy: 0.8579\n",
      "Epoch 6/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.0794 - accuracy: 0.8357 - val_loss: 4.4616 - val_accuracy: 0.8440\n",
      "Epoch 7/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.9351 - accuracy: 0.8390 - val_loss: 4.9152 - val_accuracy: 0.8287\n",
      "Epoch 8/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7676 - accuracy: 0.8425 - val_loss: 4.4857 - val_accuracy: 0.8443\n",
      "Epoch 9/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.7416 - accuracy: 0.8427 - val_loss: 4.9900 - val_accuracy: 0.8494\n",
      "Epoch 10/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8466 - accuracy: 0.8412 - val_loss: 4.4916 - val_accuracy: 0.8457\n",
      "Epoch 11/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6663 - accuracy: 0.8460 - val_loss: 4.5994 - val_accuracy: 0.8499\n",
      "Epoch 12/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6619 - accuracy: 0.8458 - val_loss: 4.5599 - val_accuracy: 0.8387\n",
      "Epoch 13/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5906 - accuracy: 0.8458 - val_loss: 4.5498 - val_accuracy: 0.8476\n",
      "Epoch 14/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.6189 - accuracy: 0.8455 - val_loss: 4.8265 - val_accuracy: 0.8271\n",
      "Epoch 15/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5777 - accuracy: 0.8451 - val_loss: 4.4770 - val_accuracy: 0.8389\n",
      "Epoch 16/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.5278 - accuracy: 0.8471 - val_loss: 4.4476 - val_accuracy: 0.8489\n",
      "Epoch 17/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4912 - accuracy: 0.8471 - val_loss: 4.4997 - val_accuracy: 0.8495\n",
      "Epoch 18/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4661 - accuracy: 0.8459 - val_loss: 4.5562 - val_accuracy: 0.8507\n",
      "Epoch 19/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4795 - accuracy: 0.8475 - val_loss: 5.1362 - val_accuracy: 0.8195\n",
      "Epoch 20/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4252 - accuracy: 0.8480 - val_loss: 4.3224 - val_accuracy: 0.8506\n",
      "Epoch 21/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.4303 - accuracy: 0.8484 - val_loss: 4.8404 - val_accuracy: 0.8423\n",
      "Epoch 22/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.2992 - accuracy: 0.8512 - val_loss: 4.7834 - val_accuracy: 0.8374\n",
      "Epoch 23/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3790 - accuracy: 0.8484 - val_loss: 4.3076 - val_accuracy: 0.8502\n",
      "Epoch 24/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3207 - accuracy: 0.8482 - val_loss: 4.9884 - val_accuracy: 0.8182\n",
      "Epoch 25/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3194 - accuracy: 0.8484 - val_loss: 4.4342 - val_accuracy: 0.8548\n",
      "Epoch 26/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3627 - accuracy: 0.8478 - val_loss: 4.5702 - val_accuracy: 0.8386\n",
      "Epoch 27/1000\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.3431 - accuracy: 0.8489 - val_loss: 4.5380 - val_accuracy: 0.8381\n",
      "21/21 - 0s - loss: 4.5380 - accuracy: 0.8381 - 47ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 2s 3ms/step - loss: 85.8837 - accuracy: 0.1401 - val_loss: 67.8462 - val_accuracy: 0.2427\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 64.6941 - accuracy: 0.2901 - val_loss: 54.8537 - val_accuracy: 0.3451\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 53.0366 - accuracy: 0.3815 - val_loss: 44.8874 - val_accuracy: 0.4332\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 43.7476 - accuracy: 0.4602 - val_loss: 36.8470 - val_accuracy: 0.5097\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 36.1852 - accuracy: 0.5297 - val_loss: 30.3256 - val_accuracy: 0.5767\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 30.0554 - accuracy: 0.5901 - val_loss: 25.0734 - val_accuracy: 0.6345\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 25.1251 - accuracy: 0.6412 - val_loss: 20.9373 - val_accuracy: 0.6755\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 21.2281 - accuracy: 0.6816 - val_loss: 17.7071 - val_accuracy: 0.7098\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 18.3864 - accuracy: 0.7087 - val_loss: 15.2501 - val_accuracy: 0.7300\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 15.8649 - accuracy: 0.7324 - val_loss: 13.4294 - val_accuracy: 0.7472\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 14.1304 - accuracy: 0.7473 - val_loss: 12.0946 - val_accuracy: 0.7551\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 12.8736 - accuracy: 0.7514 - val_loss: 11.1814 - val_accuracy: 0.7582\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.9898 - accuracy: 0.7547 - val_loss: 10.5790 - val_accuracy: 0.7608\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 11.3843 - accuracy: 0.7558 - val_loss: 10.1898 - val_accuracy: 0.7584\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.9869 - accuracy: 0.7509 - val_loss: 9.9584 - val_accuracy: 0.7520\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.7356 - accuracy: 0.7461 - val_loss: 9.8353 - val_accuracy: 0.7469\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.5843 - accuracy: 0.7420 - val_loss: 9.7796 - val_accuracy: 0.7430\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4996 - accuracy: 0.7388 - val_loss: 9.7583 - val_accuracy: 0.7396\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4531 - accuracy: 0.7364 - val_loss: 9.7582 - val_accuracy: 0.7374\n",
      "21/21 - 0s - loss: 9.7582 - accuracy: 0.7374 - 43ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 74.3767 - accuracy: 0.2172 - val_loss: 58.0253 - val_accuracy: 0.3191\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 55.7154 - accuracy: 0.3589 - val_loss: 46.9135 - val_accuracy: 0.4145\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 45.2122 - accuracy: 0.4471 - val_loss: 37.5830 - val_accuracy: 0.5024\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 36.2412 - accuracy: 0.5298 - val_loss: 29.6517 - val_accuracy: 0.5837\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 28.6568 - accuracy: 0.6060 - val_loss: 23.0845 - val_accuracy: 0.6554\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 22.4196 - accuracy: 0.6682 - val_loss: 17.8494 - val_accuracy: 0.7081\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 17.5180 - accuracy: 0.7182 - val_loss: 13.9747 - val_accuracy: 0.7417\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 14.0204 - accuracy: 0.7471 - val_loss: 11.4911 - val_accuracy: 0.7570\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 11.8488 - accuracy: 0.7551 - val_loss: 10.1963 - val_accuracy: 0.7585\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.8131 - accuracy: 0.7465 - val_loss: 9.7951 - val_accuracy: 0.7444\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4910 - accuracy: 0.7371 - val_loss: 9.7578 - val_accuracy: 0.7374\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4227 - accuracy: 0.7345 - val_loss: 9.7790 - val_accuracy: 0.7339\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4120 - accuracy: 0.7323 - val_loss: 9.7925 - val_accuracy: 0.7327\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 10.4110 - accuracy: 0.7315 - val_loss: 9.7982 - val_accuracy: 0.7323\n",
      "21/21 - 0s - loss: 9.7982 - accuracy: 0.7323 - 44ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "167/167 [==============================] - 1s 2ms/step - loss: 10.2840 - accuracy: 0.7832 - val_loss: 5.4913 - val_accuracy: 0.8146\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.6304 - accuracy: 0.8288 - val_loss: 7.5663 - val_accuracy: 0.7429\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.3399 - accuracy: 0.8333 - val_loss: 5.0062 - val_accuracy: 0.8179\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 5.0915 - accuracy: 0.8375 - val_loss: 5.3288 - val_accuracy: 0.8063\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.9793 - accuracy: 0.8406 - val_loss: 5.3532 - val_accuracy: 0.7994\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.8062 - accuracy: 0.8442 - val_loss: 4.3877 - val_accuracy: 0.8511\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7001 - accuracy: 0.8470 - val_loss: 4.6630 - val_accuracy: 0.8410\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6684 - accuracy: 0.8459 - val_loss: 4.3306 - val_accuracy: 0.8430\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.7747 - accuracy: 0.8456 - val_loss: 4.4766 - val_accuracy: 0.8456\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6717 - accuracy: 0.8466 - val_loss: 4.4193 - val_accuracy: 0.8434\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5917 - accuracy: 0.8481 - val_loss: 4.3937 - val_accuracy: 0.8552\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5557 - accuracy: 0.8479 - val_loss: 4.5275 - val_accuracy: 0.8438\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5782 - accuracy: 0.8477 - val_loss: 4.9301 - val_accuracy: 0.8172\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5523 - accuracy: 0.8493 - val_loss: 4.6545 - val_accuracy: 0.8534\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.5257 - accuracy: 0.8482 - val_loss: 4.4403 - val_accuracy: 0.8556\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.6441 - accuracy: 0.8462 - val_loss: 4.2263 - val_accuracy: 0.8493\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4157 - accuracy: 0.8507 - val_loss: 4.6417 - val_accuracy: 0.8374\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4358 - accuracy: 0.8496 - val_loss: 4.3191 - val_accuracy: 0.8573\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4415 - accuracy: 0.8505 - val_loss: 4.3503 - val_accuracy: 0.8546\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4221 - accuracy: 0.8511 - val_loss: 4.6781 - val_accuracy: 0.8266\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4965 - accuracy: 0.8503 - val_loss: 4.4671 - val_accuracy: 0.8419\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4314 - accuracy: 0.8495 - val_loss: 4.3078 - val_accuracy: 0.8483\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.4059 - accuracy: 0.8498 - val_loss: 4.3167 - val_accuracy: 0.8479\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3380 - accuracy: 0.8515 - val_loss: 4.2545 - val_accuracy: 0.8490\n",
      "Epoch 25/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3256 - accuracy: 0.8512 - val_loss: 4.5840 - val_accuracy: 0.8419\n",
      "Epoch 26/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3650 - accuracy: 0.8521 - val_loss: 4.6887 - val_accuracy: 0.8267\n",
      "Epoch 27/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.3295 - accuracy: 0.8513 - val_loss: 4.6051 - val_accuracy: 0.8318\n",
      "Epoch 28/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2338 - accuracy: 0.8534 - val_loss: 4.4463 - val_accuracy: 0.8441\n",
      "Epoch 29/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2749 - accuracy: 0.8521 - val_loss: 4.3759 - val_accuracy: 0.8440\n",
      "Epoch 30/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2263 - accuracy: 0.8546 - val_loss: 4.3362 - val_accuracy: 0.8490\n",
      "Epoch 31/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2860 - accuracy: 0.8524 - val_loss: 4.7489 - val_accuracy: 0.8295\n",
      "Epoch 32/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2419 - accuracy: 0.8525 - val_loss: 4.2745 - val_accuracy: 0.8542\n",
      "Epoch 33/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2075 - accuracy: 0.8538 - val_loss: 4.6063 - val_accuracy: 0.8333\n",
      "Epoch 34/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.2092 - accuracy: 0.8521 - val_loss: 4.5881 - val_accuracy: 0.8340\n",
      "Epoch 35/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1693 - accuracy: 0.8552 - val_loss: 4.5552 - val_accuracy: 0.8344\n",
      "Epoch 36/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1853 - accuracy: 0.8542 - val_loss: 4.5089 - val_accuracy: 0.8379\n",
      "Epoch 37/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1955 - accuracy: 0.8523 - val_loss: 4.3481 - val_accuracy: 0.8491\n",
      "Epoch 38/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1686 - accuracy: 0.8543 - val_loss: 4.3688 - val_accuracy: 0.8498\n",
      "Epoch 39/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1142 - accuracy: 0.8545 - val_loss: 4.4158 - val_accuracy: 0.8507\n",
      "Epoch 40/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1389 - accuracy: 0.8553 - val_loss: 4.3411 - val_accuracy: 0.8518\n",
      "Epoch 41/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1017 - accuracy: 0.8549 - val_loss: 4.3596 - val_accuracy: 0.8518\n",
      "Epoch 42/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1445 - accuracy: 0.8536 - val_loss: 4.4719 - val_accuracy: 0.8475\n",
      "Epoch 43/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0742 - accuracy: 0.8556 - val_loss: 4.4852 - val_accuracy: 0.8392\n",
      "Epoch 44/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1379 - accuracy: 0.8533 - val_loss: 4.3859 - val_accuracy: 0.8472\n",
      "Epoch 45/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.1108 - accuracy: 0.8550 - val_loss: 4.7372 - val_accuracy: 0.8248\n",
      "Epoch 46/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0439 - accuracy: 0.8556 - val_loss: 4.5674 - val_accuracy: 0.8416\n",
      "Epoch 47/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0173 - accuracy: 0.8554 - val_loss: 4.4000 - val_accuracy: 0.8410\n",
      "Epoch 48/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0657 - accuracy: 0.8549 - val_loss: 4.4116 - val_accuracy: 0.8441\n",
      "Epoch 49/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 3.9916 - accuracy: 0.8561 - val_loss: 4.4375 - val_accuracy: 0.8493\n",
      "Epoch 50/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0180 - accuracy: 0.8562 - val_loss: 4.4427 - val_accuracy: 0.8447\n",
      "Epoch 51/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0416 - accuracy: 0.8543 - val_loss: 4.6929 - val_accuracy: 0.8467\n",
      "Epoch 52/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 3.9869 - accuracy: 0.8562 - val_loss: 4.4595 - val_accuracy: 0.8365\n",
      "Epoch 53/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 3.9606 - accuracy: 0.8557 - val_loss: 4.4327 - val_accuracy: 0.8494\n",
      "Epoch 54/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 3.9458 - accuracy: 0.8550 - val_loss: 4.4866 - val_accuracy: 0.8346\n",
      "Epoch 55/1000\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 4.0283 - accuracy: 0.8552 - val_loss: 4.7401 - val_accuracy: 0.8376\n",
      "21/21 - 0s - loss: 4.7401 - accuracy: 0.8376 - 39ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 92.2425 - accuracy: 0.0903 - val_loss: 74.5159 - val_accuracy: 0.1904\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 71.9498 - accuracy: 0.2361 - val_loss: 63.0260 - val_accuracy: 0.2793\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 63.1076 - accuracy: 0.3016 - val_loss: 56.0896 - val_accuracy: 0.3348\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 56.6402 - accuracy: 0.3515 - val_loss: 50.3605 - val_accuracy: 0.3835\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 51.0942 - accuracy: 0.3967 - val_loss: 45.3378 - val_accuracy: 0.4290\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 46.1905 - accuracy: 0.4384 - val_loss: 40.8851 - val_accuracy: 0.4706\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 41.8155 - accuracy: 0.4770 - val_loss: 36.8876 - val_accuracy: 0.5093\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 37.8928 - accuracy: 0.5137 - val_loss: 33.3349 - val_accuracy: 0.5461\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 34.3787 - accuracy: 0.5476 - val_loss: 30.1560 - val_accuracy: 0.5785\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 31.2340 - accuracy: 0.5784 - val_loss: 27.3236 - val_accuracy: 0.6087\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 28.4260 - accuracy: 0.6072 - val_loss: 24.7942 - val_accuracy: 0.6378\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 25.9178 - accuracy: 0.6339 - val_loss: 22.5641 - val_accuracy: 0.6601\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 23.6925 - accuracy: 0.6556 - val_loss: 20.5963 - val_accuracy: 0.6789\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 21.7214 - accuracy: 0.6758 - val_loss: 18.8530 - val_accuracy: 0.6972\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.2677 - accuracy: 0.6915 - val_loss: 17.3427 - val_accuracy: 0.7138\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 18.4826 - accuracy: 0.7099 - val_loss: 16.0420 - val_accuracy: 0.7234\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 17.1516 - accuracy: 0.7202 - val_loss: 14.9083 - val_accuracy: 0.7330\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 16.0069 - accuracy: 0.7308 - val_loss: 13.9407 - val_accuracy: 0.7420\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 15.0228 - accuracy: 0.7406 - val_loss: 13.1160 - val_accuracy: 0.7506\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.1824 - accuracy: 0.7478 - val_loss: 12.4274 - val_accuracy: 0.7541\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.4718 - accuracy: 0.7500 - val_loss: 11.8570 - val_accuracy: 0.7558\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.8711 - accuracy: 0.7515 - val_loss: 11.3777 - val_accuracy: 0.7574\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.3723 - accuracy: 0.7530 - val_loss: 10.9914 - val_accuracy: 0.7589\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.9589 - accuracy: 0.7545 - val_loss: 10.6833 - val_accuracy: 0.7603\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.6199 - accuracy: 0.7560 - val_loss: 10.4335 - val_accuracy: 0.7616\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.3446 - accuracy: 0.7560 - val_loss: 10.2358 - val_accuracy: 0.7594\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1226 - accuracy: 0.7533 - val_loss: 10.0949 - val_accuracy: 0.7560\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.9497 - accuracy: 0.7505 - val_loss: 9.9817 - val_accuracy: 0.7528\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.8118 - accuracy: 0.7477 - val_loss: 9.9026 - val_accuracy: 0.7500\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.7084 - accuracy: 0.7452 - val_loss: 9.8440 - val_accuracy: 0.7474\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.6265 - accuracy: 0.7434 - val_loss: 9.8069 - val_accuracy: 0.7452\n",
      "21/21 - 0s - loss: 9.8069 - accuracy: 0.7452 - 39ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 82.8624 - accuracy: 0.1559 - val_loss: 65.4244 - val_accuracy: 0.2609\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 65.0703 - accuracy: 0.2868 - val_loss: 57.7678 - val_accuracy: 0.3212\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 58.2073 - accuracy: 0.3394 - val_loss: 51.7339 - val_accuracy: 0.3716\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 52.3671 - accuracy: 0.3863 - val_loss: 46.3689 - val_accuracy: 0.4195\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 47.0268 - accuracy: 0.4316 - val_loss: 41.4642 - val_accuracy: 0.4653\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 42.1507 - accuracy: 0.4742 - val_loss: 36.9403 - val_accuracy: 0.5088\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 37.6526 - accuracy: 0.5160 - val_loss: 32.8151 - val_accuracy: 0.5517\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 33.5273 - accuracy: 0.5560 - val_loss: 29.0163 - val_accuracy: 0.5903\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 29.7044 - accuracy: 0.5934 - val_loss: 25.5499 - val_accuracy: 0.6289\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 26.2497 - accuracy: 0.6304 - val_loss: 22.4555 - val_accuracy: 0.6611\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 23.1563 - accuracy: 0.6605 - val_loss: 19.7060 - val_accuracy: 0.6879\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 20.4011 - accuracy: 0.6901 - val_loss: 17.2974 - val_accuracy: 0.7138\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 18.0180 - accuracy: 0.7131 - val_loss: 15.2381 - val_accuracy: 0.7301\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 15.9733 - accuracy: 0.7312 - val_loss: 13.5459 - val_accuracy: 0.7460\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.2581 - accuracy: 0.7465 - val_loss: 12.1524 - val_accuracy: 0.7549\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.8677 - accuracy: 0.7522 - val_loss: 11.1196 - val_accuracy: 0.7584\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.8287 - accuracy: 0.7551 - val_loss: 10.3899 - val_accuracy: 0.7619\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.1264 - accuracy: 0.7532 - val_loss: 9.9836 - val_accuracy: 0.7529\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7169 - accuracy: 0.7454 - val_loss: 9.8026 - val_accuracy: 0.7449\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.5159 - accuracy: 0.7392 - val_loss: 9.7570 - val_accuracy: 0.7389\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.4383 - accuracy: 0.7353 - val_loss: 9.7650 - val_accuracy: 0.7357\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.4172 - accuracy: 0.7331 - val_loss: 9.7793 - val_accuracy: 0.7339\n",
      "21/21 - 0s - loss: 9.7793 - accuracy: 0.7339 - 38ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 14.8593 - accuracy: 0.7473 - val_loss: 6.2638 - val_accuracy: 0.8259\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5965 - accuracy: 0.8195 - val_loss: 5.7659 - val_accuracy: 0.8226\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6263 - accuracy: 0.8351 - val_loss: 5.2969 - val_accuracy: 0.8294\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2978 - accuracy: 0.8355 - val_loss: 5.1975 - val_accuracy: 0.8075\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9099 - accuracy: 0.8428 - val_loss: 5.2659 - val_accuracy: 0.8282\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8325 - accuracy: 0.8435 - val_loss: 6.1269 - val_accuracy: 0.7981\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7620 - accuracy: 0.8440 - val_loss: 4.5777 - val_accuracy: 0.8421\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8011 - accuracy: 0.8430 - val_loss: 4.8964 - val_accuracy: 0.8203\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7500 - accuracy: 0.8430 - val_loss: 5.1170 - val_accuracy: 0.8049\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6766 - accuracy: 0.8463 - val_loss: 5.7039 - val_accuracy: 0.7881\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6146 - accuracy: 0.8457 - val_loss: 4.6166 - val_accuracy: 0.8233\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5345 - accuracy: 0.8471 - val_loss: 4.7372 - val_accuracy: 0.8499\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5104 - accuracy: 0.8470 - val_loss: 4.4198 - val_accuracy: 0.8384\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5312 - accuracy: 0.8494 - val_loss: 4.8501 - val_accuracy: 0.8213\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4862 - accuracy: 0.8484 - val_loss: 4.2795 - val_accuracy: 0.8452\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4302 - accuracy: 0.8480 - val_loss: 4.3956 - val_accuracy: 0.8525\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4219 - accuracy: 0.8501 - val_loss: 4.6848 - val_accuracy: 0.8469\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4276 - accuracy: 0.8492 - val_loss: 4.3918 - val_accuracy: 0.8376\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4012 - accuracy: 0.8498 - val_loss: 5.2018 - val_accuracy: 0.8098\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4196 - accuracy: 0.8488 - val_loss: 4.3303 - val_accuracy: 0.8444\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4287 - accuracy: 0.8503 - val_loss: 4.2880 - val_accuracy: 0.8417\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3806 - accuracy: 0.8516 - val_loss: 4.6073 - val_accuracy: 0.8261\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3241 - accuracy: 0.8511 - val_loss: 4.5771 - val_accuracy: 0.8399\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2840 - accuracy: 0.8522 - val_loss: 4.2263 - val_accuracy: 0.8442\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2858 - accuracy: 0.8522 - val_loss: 4.2006 - val_accuracy: 0.8502\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3346 - accuracy: 0.8506 - val_loss: 4.4125 - val_accuracy: 0.8511\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2152 - accuracy: 0.8539 - val_loss: 4.7669 - val_accuracy: 0.8506\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2532 - accuracy: 0.8538 - val_loss: 4.8018 - val_accuracy: 0.8141\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2766 - accuracy: 0.8499 - val_loss: 4.2897 - val_accuracy: 0.8474\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2870 - accuracy: 0.8511 - val_loss: 4.4288 - val_accuracy: 0.8549\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2164 - accuracy: 0.8532 - val_loss: 5.7308 - val_accuracy: 0.8075\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.1708 - accuracy: 0.8527 - val_loss: 4.3950 - val_accuracy: 0.8571\n",
      "21/21 - 0s - loss: 4.3950 - accuracy: 0.8571 - 45ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 106.5932 - accuracy: 0.0101 - val_loss: 98.4111 - val_accuracy: 0.0321\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 99.2776 - accuracy: 0.0563 - val_loss: 90.9667 - val_accuracy: 0.0836\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 92.3592 - accuracy: 0.1024 - val_loss: 84.9520 - val_accuracy: 0.1247\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 86.9032 - accuracy: 0.1373 - val_loss: 80.3840 - val_accuracy: 0.1549\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 82.5372 - accuracy: 0.1658 - val_loss: 76.3565 - val_accuracy: 0.1823\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 78.5901 - accuracy: 0.1916 - val_loss: 72.6691 - val_accuracy: 0.2082\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 74.9317 - accuracy: 0.2164 - val_loss: 69.2387 - val_accuracy: 0.2329\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 71.5035 - accuracy: 0.2401 - val_loss: 66.0020 - val_accuracy: 0.2569\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 68.2629 - accuracy: 0.2632 - val_loss: 62.9375 - val_accuracy: 0.2802\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 65.1900 - accuracy: 0.2858 - val_loss: 60.0182 - val_accuracy: 0.3031\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 62.2623 - accuracy: 0.3078 - val_loss: 57.2523 - val_accuracy: 0.3254\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 59.4776 - accuracy: 0.3294 - val_loss: 54.6086 - val_accuracy: 0.3473\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 56.8179 - accuracy: 0.3501 - val_loss: 52.0974 - val_accuracy: 0.3685\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 54.2783 - accuracy: 0.3701 - val_loss: 49.7089 - val_accuracy: 0.3893\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 51.8617 - accuracy: 0.3902 - val_loss: 47.4045 - val_accuracy: 0.4100\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 49.5410 - accuracy: 0.4096 - val_loss: 45.2350 - val_accuracy: 0.4300\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 47.3318 - accuracy: 0.4288 - val_loss: 43.1530 - val_accuracy: 0.4498\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 45.2253 - accuracy: 0.4472 - val_loss: 41.1493 - val_accuracy: 0.4682\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 43.2059 - accuracy: 0.4646 - val_loss: 39.2617 - val_accuracy: 0.4860\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 41.2876 - accuracy: 0.4819 - val_loss: 37.4517 - val_accuracy: 0.5037\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 39.4504 - accuracy: 0.4987 - val_loss: 35.7384 - val_accuracy: 0.5209\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 37.7067 - accuracy: 0.5153 - val_loss: 34.0906 - val_accuracy: 0.5380\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 36.0391 - accuracy: 0.5318 - val_loss: 32.5361 - val_accuracy: 0.5547\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 34.4520 - accuracy: 0.5470 - val_loss: 31.0620 - val_accuracy: 0.5692\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 32.9480 - accuracy: 0.5612 - val_loss: 29.6424 - val_accuracy: 0.5838\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 31.5078 - accuracy: 0.5753 - val_loss: 28.3156 - val_accuracy: 0.5978\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 30.1476 - accuracy: 0.5891 - val_loss: 27.0455 - val_accuracy: 0.6118\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 28.8508 - accuracy: 0.6026 - val_loss: 25.8507 - val_accuracy: 0.6254\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 27.6229 - accuracy: 0.6159 - val_loss: 24.7153 - val_accuracy: 0.6387\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 26.4584 - accuracy: 0.6288 - val_loss: 23.6392 - val_accuracy: 0.6505\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 25.3546 - accuracy: 0.6394 - val_loss: 22.6289 - val_accuracy: 0.6595\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 24.3114 - accuracy: 0.6491 - val_loss: 21.6719 - val_accuracy: 0.6684\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 23.3252 - accuracy: 0.6590 - val_loss: 20.7666 - val_accuracy: 0.6772\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 22.3936 - accuracy: 0.6684 - val_loss: 19.9107 - val_accuracy: 0.6858\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 21.5129 - accuracy: 0.6778 - val_loss: 19.1125 - val_accuracy: 0.6941\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 20.6856 - accuracy: 0.6869 - val_loss: 18.3600 - val_accuracy: 0.7024\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 19.9923 - accuracy: 0.6947 - val_loss: 17.6610 - val_accuracy: 0.7103\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 19.1918 - accuracy: 0.7038 - val_loss: 17.0026 - val_accuracy: 0.7160\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 18.4845 - accuracy: 0.7093 - val_loss: 16.3797 - val_accuracy: 0.7208\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.8380 - accuracy: 0.7144 - val_loss: 15.8022 - val_accuracy: 0.7254\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 17.2330 - accuracy: 0.7194 - val_loss: 15.2675 - val_accuracy: 0.7299\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 16.6686 - accuracy: 0.7245 - val_loss: 14.7666 - val_accuracy: 0.7343\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 16.1403 - accuracy: 0.7295 - val_loss: 14.3016 - val_accuracy: 0.7386\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 15.6477 - accuracy: 0.7342 - val_loss: 13.8709 - val_accuracy: 0.7427\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 15.1892 - accuracy: 0.7388 - val_loss: 13.4699 - val_accuracy: 0.7468\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 14.7573 - accuracy: 0.7436 - val_loss: 12.9464 - val_accuracy: 0.7571\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 14.3333 - accuracy: 0.7490 - val_loss: 12.7651 - val_accuracy: 0.7532\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 14.0018 - accuracy: 0.7486 - val_loss: 12.4475 - val_accuracy: 0.7540\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 13.6623 - accuracy: 0.7495 - val_loss: 12.1608 - val_accuracy: 0.7549\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 13.3508 - accuracy: 0.7503 - val_loss: 11.8962 - val_accuracy: 0.7557\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 13.0627 - accuracy: 0.7511 - val_loss: 11.6567 - val_accuracy: 0.7565\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 12.7989 - accuracy: 0.7519 - val_loss: 11.4364 - val_accuracy: 0.7572\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 12.5548 - accuracy: 0.7526 - val_loss: 11.2378 - val_accuracy: 0.7580\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 12.3329 - accuracy: 0.7533 - val_loss: 11.0555 - val_accuracy: 0.7587\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 12.1287 - accuracy: 0.7540 - val_loss: 10.8929 - val_accuracy: 0.7594\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.9426 - accuracy: 0.7547 - val_loss: 10.7482 - val_accuracy: 0.7600\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.7749 - accuracy: 0.7554 - val_loss: 10.6152 - val_accuracy: 0.7607\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.6219 - accuracy: 0.7559 - val_loss: 10.4957 - val_accuracy: 0.7613\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.4826 - accuracy: 0.7566 - val_loss: 10.3920 - val_accuracy: 0.7619\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.3582 - accuracy: 0.7566 - val_loss: 10.2985 - val_accuracy: 0.7607\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.2457 - accuracy: 0.7551 - val_loss: 10.2148 - val_accuracy: 0.7589\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.1438 - accuracy: 0.7536 - val_loss: 10.1424 - val_accuracy: 0.7573\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.0535 - accuracy: 0.7521 - val_loss: 10.0783 - val_accuracy: 0.7556\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.9712 - accuracy: 0.7509 - val_loss: 10.0250 - val_accuracy: 0.7541\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.9008 - accuracy: 0.7494 - val_loss: 9.9738 - val_accuracy: 0.7526\n",
      "21/21 - 0s - loss: 9.9738 - accuracy: 0.7526 - 47ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 96.8008 - accuracy: 0.0603 - val_loss: 83.9027 - val_accuracy: 0.1267\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 84.8478 - accuracy: 0.1491 - val_loss: 78.0397 - val_accuracy: 0.1705\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 80.1713 - accuracy: 0.1808 - val_loss: 74.1729 - val_accuracy: 0.1975\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 76.4417 - accuracy: 0.2059 - val_loss: 70.6962 - val_accuracy: 0.2223\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 72.9685 - accuracy: 0.2299 - val_loss: 67.3925 - val_accuracy: 0.2465\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 69.6441 - accuracy: 0.2533 - val_loss: 64.2225 - val_accuracy: 0.2704\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 66.4420 - accuracy: 0.2765 - val_loss: 61.1659 - val_accuracy: 0.2940\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 63.3436 - accuracy: 0.2996 - val_loss: 58.2029 - val_accuracy: 0.3177\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 60.3366 - accuracy: 0.3225 - val_loss: 55.3266 - val_accuracy: 0.3413\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 57.4299 - accuracy: 0.3451 - val_loss: 52.5593 - val_accuracy: 0.3646\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 54.6261 - accuracy: 0.3675 - val_loss: 49.8855 - val_accuracy: 0.3878\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 51.8997 - accuracy: 0.3898 - val_loss: 47.2933 - val_accuracy: 0.4110\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 49.2563 - accuracy: 0.4122 - val_loss: 44.7799 - val_accuracy: 0.4343\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 46.6964 - accuracy: 0.4344 - val_loss: 42.3546 - val_accuracy: 0.4571\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 44.2419 - accuracy: 0.4558 - val_loss: 40.0285 - val_accuracy: 0.4787\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 41.8739 - accuracy: 0.4767 - val_loss: 37.7960 - val_accuracy: 0.5003\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 39.5903 - accuracy: 0.4977 - val_loss: 35.6317 - val_accuracy: 0.5220\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 37.3946 - accuracy: 0.5186 - val_loss: 33.5710 - val_accuracy: 0.5436\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 35.2762 - accuracy: 0.5392 - val_loss: 31.5877 - val_accuracy: 0.5640\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 33.2398 - accuracy: 0.5585 - val_loss: 29.6798 - val_accuracy: 0.5834\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 31.2971 - accuracy: 0.5774 - val_loss: 27.8678 - val_accuracy: 0.6027\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 29.4424 - accuracy: 0.5963 - val_loss: 26.1483 - val_accuracy: 0.6219\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 27.6845 - accuracy: 0.6151 - val_loss: 24.5233 - val_accuracy: 0.6410\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 26.0225 - accuracy: 0.6331 - val_loss: 22.9899 - val_accuracy: 0.6562\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 24.4277 - accuracy: 0.6482 - val_loss: 21.5209 - val_accuracy: 0.6698\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 22.9136 - accuracy: 0.6629 - val_loss: 20.1451 - val_accuracy: 0.6834\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 21.5140 - accuracy: 0.6778 - val_loss: 18.8693 - val_accuracy: 0.6968\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 20.1922 - accuracy: 0.6925 - val_loss: 17.6792 - val_accuracy: 0.7101\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 18.9570 - accuracy: 0.7053 - val_loss: 16.5667 - val_accuracy: 0.7193\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 17.7964 - accuracy: 0.7148 - val_loss: 15.5455 - val_accuracy: 0.7275\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 16.7219 - accuracy: 0.7240 - val_loss: 14.5971 - val_accuracy: 0.7358\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 15.7478 - accuracy: 0.7332 - val_loss: 13.7482 - val_accuracy: 0.7439\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 14.8566 - accuracy: 0.7425 - val_loss: 12.9834 - val_accuracy: 0.7520\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 14.0370 - accuracy: 0.7485 - val_loss: 12.2960 - val_accuracy: 0.7545\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 13.3122 - accuracy: 0.7506 - val_loss: 11.6986 - val_accuracy: 0.7563\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.6822 - accuracy: 0.7524 - val_loss: 11.1941 - val_accuracy: 0.7581\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 12.1360 - accuracy: 0.7540 - val_loss: 10.7687 - val_accuracy: 0.7599\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.6642 - accuracy: 0.7557 - val_loss: 10.4186 - val_accuracy: 0.7617\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 11.2749 - accuracy: 0.7553 - val_loss: 10.1490 - val_accuracy: 0.7574\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.9595 - accuracy: 0.7508 - val_loss: 9.9561 - val_accuracy: 0.7520\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.7381 - accuracy: 0.7464 - val_loss: 9.8359 - val_accuracy: 0.7470\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.5931 - accuracy: 0.7420 - val_loss: 9.7815 - val_accuracy: 0.7432\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 10.5048 - accuracy: 0.7389 - val_loss: 9.7588 - val_accuracy: 0.7398\n",
      "21/21 - 0s - loss: 9.7588 - accuracy: 0.7398 - 44ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 24.8931 - accuracy: 0.6564 - val_loss: 6.9763 - val_accuracy: 0.7967\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.8986 - accuracy: 0.8165 - val_loss: 5.9660 - val_accuracy: 0.8273\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.1264 - accuracy: 0.8276 - val_loss: 5.3032 - val_accuracy: 0.8534\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.5406 - accuracy: 0.8354 - val_loss: 5.0589 - val_accuracy: 0.8347\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.3369 - accuracy: 0.8371 - val_loss: 4.8564 - val_accuracy: 0.8331\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.0872 - accuracy: 0.8415 - val_loss: 4.8280 - val_accuracy: 0.8394\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.9656 - accuracy: 0.8424 - val_loss: 4.5510 - val_accuracy: 0.8529\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9181 - accuracy: 0.8429 - val_loss: 4.5544 - val_accuracy: 0.8583\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.7829 - accuracy: 0.8454 - val_loss: 4.6988 - val_accuracy: 0.8485\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.8244 - accuracy: 0.8460 - val_loss: 4.4847 - val_accuracy: 0.8403\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6870 - accuracy: 0.8468 - val_loss: 4.5833 - val_accuracy: 0.8453\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 4.7336 - accuracy: 0.8461 - val_loss: 4.5107 - val_accuracy: 0.8592\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6735 - accuracy: 0.8464 - val_loss: 4.4053 - val_accuracy: 0.8460\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6796 - accuracy: 0.8468 - val_loss: 4.4118 - val_accuracy: 0.8579\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.7110 - accuracy: 0.8454 - val_loss: 4.8252 - val_accuracy: 0.8325\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5864 - accuracy: 0.8484 - val_loss: 4.3414 - val_accuracy: 0.8538\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6567 - accuracy: 0.8458 - val_loss: 4.6123 - val_accuracy: 0.8377\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5715 - accuracy: 0.8486 - val_loss: 4.3856 - val_accuracy: 0.8592\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6016 - accuracy: 0.8492 - val_loss: 4.3047 - val_accuracy: 0.8528\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4973 - accuracy: 0.8498 - val_loss: 4.6443 - val_accuracy: 0.8411\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6131 - accuracy: 0.8475 - val_loss: 4.2601 - val_accuracy: 0.8552\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4180 - accuracy: 0.8513 - val_loss: 4.2431 - val_accuracy: 0.8545\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4437 - accuracy: 0.8511 - val_loss: 4.3333 - val_accuracy: 0.8450\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4081 - accuracy: 0.8513 - val_loss: 4.3402 - val_accuracy: 0.8428\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4437 - accuracy: 0.8502 - val_loss: 5.1901 - val_accuracy: 0.8197\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3354 - accuracy: 0.8522 - val_loss: 4.4370 - val_accuracy: 0.8453\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3241 - accuracy: 0.8528 - val_loss: 4.5592 - val_accuracy: 0.8365\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3300 - accuracy: 0.8529 - val_loss: 4.1925 - val_accuracy: 0.8551\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.3164 - accuracy: 0.8525 - val_loss: 4.3371 - val_accuracy: 0.8400\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3299 - accuracy: 0.8512 - val_loss: 4.5483 - val_accuracy: 0.8593\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3197 - accuracy: 0.8516 - val_loss: 4.5641 - val_accuracy: 0.8577\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3656 - accuracy: 0.8520 - val_loss: 4.2650 - val_accuracy: 0.8445\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3014 - accuracy: 0.8530 - val_loss: 4.3525 - val_accuracy: 0.8415\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3216 - accuracy: 0.8532 - val_loss: 5.8972 - val_accuracy: 0.7754\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3092 - accuracy: 0.8514 - val_loss: 4.4219 - val_accuracy: 0.8497\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2955 - accuracy: 0.8538 - val_loss: 4.4979 - val_accuracy: 0.8541\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2966 - accuracy: 0.8533 - val_loss: 4.2124 - val_accuracy: 0.8496\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2071 - accuracy: 0.8534 - val_loss: 4.2233 - val_accuracy: 0.8571\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2622 - accuracy: 0.8534 - val_loss: 4.2389 - val_accuracy: 0.8484\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2565 - accuracy: 0.8534 - val_loss: 4.6467 - val_accuracy: 0.8287\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2030 - accuracy: 0.8547 - val_loss: 4.3758 - val_accuracy: 0.8499\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2363 - accuracy: 0.8542 - val_loss: 4.1847 - val_accuracy: 0.8548\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2191 - accuracy: 0.8541 - val_loss: 4.2210 - val_accuracy: 0.8563\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.1821 - accuracy: 0.8542 - val_loss: 4.2571 - val_accuracy: 0.8426\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2243 - accuracy: 0.8537 - val_loss: 4.4977 - val_accuracy: 0.8338\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2560 - accuracy: 0.8530 - val_loss: 4.1650 - val_accuracy: 0.8515\n",
      "21/21 - 0s - loss: 4.1650 - accuracy: 0.8515 - 37ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 97.6230 - accuracy: 0.0265 - val_loss: 88.2623 - val_accuracy: 0.0596\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 93.4286 - accuracy: 0.0503 - val_loss: 86.1234 - val_accuracy: 0.0727\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 91.1718 - accuracy: 0.0643 - val_loss: 83.1393 - val_accuracy: 0.0950\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 84.4694 - accuracy: 0.1132 - val_loss: 73.8149 - val_accuracy: 0.1639\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 74.4371 - accuracy: 0.1923 - val_loss: 64.0035 - val_accuracy: 0.2581\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 63.1341 - accuracy: 0.2968 - val_loss: 56.0359 - val_accuracy: 0.3351\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 58.2522 - accuracy: 0.3386 - val_loss: 53.5479 - val_accuracy: 0.3561\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 55.9931 - accuracy: 0.3564 - val_loss: 51.5793 - val_accuracy: 0.3729\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 54.0843 - accuracy: 0.3718 - val_loss: 49.8240 - val_accuracy: 0.3882\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 52.3467 - accuracy: 0.3860 - val_loss: 48.2212 - val_accuracy: 0.4025\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 50.7401 - accuracy: 0.3994 - val_loss: 46.7216 - val_accuracy: 0.4162\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 49.2337 - accuracy: 0.4123 - val_loss: 45.2968 - val_accuracy: 0.4294\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 47.7954 - accuracy: 0.4248 - val_loss: 43.9543 - val_accuracy: 0.4421\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46.4336 - accuracy: 0.4368 - val_loss: 42.6629 - val_accuracy: 0.4542\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45.1266 - accuracy: 0.4480 - val_loss: 41.4255 - val_accuracy: 0.4656\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.8702 - accuracy: 0.4589 - val_loss: 40.2416 - val_accuracy: 0.4767\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42.6598 - accuracy: 0.4695 - val_loss: 39.1070 - val_accuracy: 0.4875\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 41.5008 - accuracy: 0.4799 - val_loss: 38.0034 - val_accuracy: 0.4982\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40.3743 - accuracy: 0.4902 - val_loss: 36.9444 - val_accuracy: 0.5087\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 39.2896 - accuracy: 0.5003 - val_loss: 35.9208 - val_accuracy: 0.5190\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 38.2415 - accuracy: 0.5102 - val_loss: 34.9292 - val_accuracy: 0.5292\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 37.2305 - accuracy: 0.5201 - val_loss: 33.9650 - val_accuracy: 0.5393\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 36.2442 - accuracy: 0.5298 - val_loss: 33.0429 - val_accuracy: 0.5492\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 35.2934 - accuracy: 0.5391 - val_loss: 32.1505 - val_accuracy: 0.5584\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 34.3776 - accuracy: 0.5477 - val_loss: 31.2791 - val_accuracy: 0.5671\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 33.4822 - accuracy: 0.5561 - val_loss: 30.4434 - val_accuracy: 0.5755\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 32.6193 - accuracy: 0.5644 - val_loss: 29.6331 - val_accuracy: 0.5839\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 31.7814 - accuracy: 0.5725 - val_loss: 28.8501 - val_accuracy: 0.5921\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 30.9744 - accuracy: 0.5807 - val_loss: 28.0851 - val_accuracy: 0.6003\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 30.1858 - accuracy: 0.5886 - val_loss: 27.3512 - val_accuracy: 0.6084\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 29.4245 - accuracy: 0.5964 - val_loss: 26.6413 - val_accuracy: 0.6163\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 28.6909 - accuracy: 0.6043 - val_loss: 25.9477 - val_accuracy: 0.6242\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 27.9766 - accuracy: 0.6120 - val_loss: 25.2795 - val_accuracy: 0.6320\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 27.2854 - accuracy: 0.6196 - val_loss: 24.6340 - val_accuracy: 0.6397\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 26.6139 - accuracy: 0.6271 - val_loss: 24.0148 - val_accuracy: 0.6472\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 25.9702 - accuracy: 0.6337 - val_loss: 23.4088 - val_accuracy: 0.6525\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 25.3417 - accuracy: 0.6395 - val_loss: 22.8257 - val_accuracy: 0.6577\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 24.7354 - accuracy: 0.6452 - val_loss: 22.2620 - val_accuracy: 0.6629\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 24.1467 - accuracy: 0.6509 - val_loss: 21.7201 - val_accuracy: 0.6680\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 23.5792 - accuracy: 0.6566 - val_loss: 21.1929 - val_accuracy: 0.6730\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 23.0392 - accuracy: 0.6617 - val_loss: 20.7020 - val_accuracy: 0.6778\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 22.5055 - accuracy: 0.6673 - val_loss: 20.1975 - val_accuracy: 0.6828\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 21.9905 - accuracy: 0.6726 - val_loss: 19.7239 - val_accuracy: 0.6877\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 21.4959 - accuracy: 0.6779 - val_loss: 19.2659 - val_accuracy: 0.6925\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 21.0140 - accuracy: 0.6831 - val_loss: 18.8307 - val_accuracy: 0.6972\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 20.5555 - accuracy: 0.6882 - val_loss: 18.4049 - val_accuracy: 0.7019\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 20.1084 - accuracy: 0.6933 - val_loss: 17.9964 - val_accuracy: 0.7065\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 19.6802 - accuracy: 0.6983 - val_loss: 17.5988 - val_accuracy: 0.7111\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 19.2625 - accuracy: 0.7029 - val_loss: 17.2210 - val_accuracy: 0.7143\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 18.8610 - accuracy: 0.7060 - val_loss: 16.8602 - val_accuracy: 0.7170\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.4797 - accuracy: 0.7091 - val_loss: 16.5047 - val_accuracy: 0.7198\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.1048 - accuracy: 0.7122 - val_loss: 16.1696 - val_accuracy: 0.7224\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.7470 - accuracy: 0.7151 - val_loss: 15.8477 - val_accuracy: 0.7250\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.4021 - accuracy: 0.7180 - val_loss: 15.5387 - val_accuracy: 0.7275\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.0724 - accuracy: 0.7209 - val_loss: 15.2371 - val_accuracy: 0.7301\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.7521 - accuracy: 0.7237 - val_loss: 14.9494 - val_accuracy: 0.7326\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.4450 - accuracy: 0.7265 - val_loss: 14.6745 - val_accuracy: 0.7351\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.1500 - accuracy: 0.7293 - val_loss: 14.4111 - val_accuracy: 0.7375\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.8672 - accuracy: 0.7320 - val_loss: 14.1579 - val_accuracy: 0.7399\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.5965 - accuracy: 0.7347 - val_loss: 13.9136 - val_accuracy: 0.7423\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.3330 - accuracy: 0.7373 - val_loss: 13.6841 - val_accuracy: 0.7446\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.0825 - accuracy: 0.7399 - val_loss: 13.4650 - val_accuracy: 0.7468\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.8441 - accuracy: 0.7424 - val_loss: 13.2522 - val_accuracy: 0.7491\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.6136 - accuracy: 0.7449 - val_loss: 13.0493 - val_accuracy: 0.7513\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.3922 - accuracy: 0.7473 - val_loss: 12.8571 - val_accuracy: 0.7529\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.7483 - val_loss: 12.6720 - val_accuracy: 0.7534\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.9802 - accuracy: 0.7488 - val_loss: 12.4954 - val_accuracy: 0.7539\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.7857 - accuracy: 0.7493 - val_loss: 12.3298 - val_accuracy: 0.7544\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.6027 - accuracy: 0.7497 - val_loss: 12.1693 - val_accuracy: 0.7549\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 13.4263 - accuracy: 0.7501 - val_loss: 12.0169 - val_accuracy: 0.7553\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.2561 - accuracy: 0.7506 - val_loss: 11.8747 - val_accuracy: 0.7558\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.0974 - accuracy: 0.7511 - val_loss: 11.7355 - val_accuracy: 0.7562\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.9420 - accuracy: 0.7515 - val_loss: 11.6057 - val_accuracy: 0.7567\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.7943 - accuracy: 0.7520 - val_loss: 11.4758 - val_accuracy: 0.7574\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.6880 - accuracy: 0.7527 - val_loss: 11.3719 - val_accuracy: 0.7574\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.5253 - accuracy: 0.7527 - val_loss: 11.2594 - val_accuracy: 0.7579\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.4008 - accuracy: 0.7531 - val_loss: 11.1522 - val_accuracy: 0.7583\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.2797 - accuracy: 0.7535 - val_loss: 11.0535 - val_accuracy: 0.7587\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.1662 - accuracy: 0.7539 - val_loss: 10.9597 - val_accuracy: 0.7591\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.0583 - accuracy: 0.7543 - val_loss: 10.8720 - val_accuracy: 0.7594\n",
      "Epoch 81/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.9559 - accuracy: 0.7547 - val_loss: 10.7894 - val_accuracy: 0.7598\n",
      "Epoch 82/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.8587 - accuracy: 0.7550 - val_loss: 10.7119 - val_accuracy: 0.7602\n",
      "Epoch 83/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.7666 - accuracy: 0.7554 - val_loss: 10.6388 - val_accuracy: 0.7605\n",
      "Epoch 84/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.6811 - accuracy: 0.7557 - val_loss: 10.5675 - val_accuracy: 0.7609\n",
      "Epoch 85/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.5964 - accuracy: 0.7561 - val_loss: 10.5044 - val_accuracy: 0.7612\n",
      "Epoch 86/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.5193 - accuracy: 0.7564 - val_loss: 10.4434 - val_accuracy: 0.7616\n",
      "Epoch 87/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.4468 - accuracy: 0.7568 - val_loss: 10.3849 - val_accuracy: 0.7619\n",
      "Epoch 88/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.3755 - accuracy: 0.7569 - val_loss: 10.3329 - val_accuracy: 0.7614\n",
      "Epoch 89/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.3112 - accuracy: 0.7561 - val_loss: 10.2822 - val_accuracy: 0.7604\n",
      "Epoch 90/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.2482 - accuracy: 0.7552 - val_loss: 10.2370 - val_accuracy: 0.7594\n",
      "Epoch 91/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.1901 - accuracy: 0.7544 - val_loss: 10.1946 - val_accuracy: 0.7585\n",
      "Epoch 92/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.1364 - accuracy: 0.7535 - val_loss: 10.1532 - val_accuracy: 0.7575\n",
      "Epoch 93/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 11.0841 - accuracy: 0.7527 - val_loss: 10.1162 - val_accuracy: 0.7566\n",
      "21/21 - 0s - loss: 10.1162 - accuracy: 0.7566 - 57ms/epoch - 3ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 10ms/step - loss: 104.7379 - accuracy: 0.0201 - val_loss: 95.7906 - val_accuracy: 0.0443\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 97.4836 - accuracy: 0.0625 - val_loss: 90.3927 - val_accuracy: 0.0812\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 93.3594 - accuracy: 0.0888 - val_loss: 87.0506 - val_accuracy: 0.1040\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 89.9585 - accuracy: 0.1122 - val_loss: 83.7778 - val_accuracy: 0.1288\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 86.3195 - accuracy: 0.1400 - val_loss: 80.7363 - val_accuracy: 0.1521\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 83.9094 - accuracy: 0.1561 - val_loss: 78.6503 - val_accuracy: 0.1662\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 81.7774 - accuracy: 0.1702 - val_loss: 76.5600 - val_accuracy: 0.1809\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 79.7027 - accuracy: 0.1841 - val_loss: 74.6464 - val_accuracy: 0.1942\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 77.7915 - accuracy: 0.1968 - val_loss: 72.8294 - val_accuracy: 0.2070\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 75.9593 - accuracy: 0.2092 - val_loss: 71.0783 - val_accuracy: 0.2196\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 74.1898 - accuracy: 0.2213 - val_loss: 69.3807 - val_accuracy: 0.2319\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 72.4706 - accuracy: 0.2333 - val_loss: 67.7271 - val_accuracy: 0.2440\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 70.7903 - accuracy: 0.2452 - val_loss: 66.1085 - val_accuracy: 0.2561\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 69.1398 - accuracy: 0.2569 - val_loss: 64.5206 - val_accuracy: 0.2681\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 67.5235 - accuracy: 0.2685 - val_loss: 62.9632 - val_accuracy: 0.2800\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65.9340 - accuracy: 0.2802 - val_loss: 61.4333 - val_accuracy: 0.2919\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 64.3782 - accuracy: 0.2918 - val_loss: 59.9375 - val_accuracy: 0.3038\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 62.8470 - accuracy: 0.3033 - val_loss: 58.4580 - val_accuracy: 0.3156\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 61.3374 - accuracy: 0.3149 - val_loss: 57.0074 - val_accuracy: 0.3274\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 59.8562 - accuracy: 0.3264 - val_loss: 55.5819 - val_accuracy: 0.3392\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 58.3928 - accuracy: 0.3377 - val_loss: 54.1749 - val_accuracy: 0.3509\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 56.9589 - accuracy: 0.3490 - val_loss: 52.7971 - val_accuracy: 0.3625\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 55.5469 - accuracy: 0.3601 - val_loss: 51.4405 - val_accuracy: 0.3742\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 54.1560 - accuracy: 0.3713 - val_loss: 50.1017 - val_accuracy: 0.3858\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 52.7903 - accuracy: 0.3826 - val_loss: 48.7935 - val_accuracy: 0.3974\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 51.4430 - accuracy: 0.3936 - val_loss: 47.4984 - val_accuracy: 0.4091\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 50.1089 - accuracy: 0.4048 - val_loss: 46.2189 - val_accuracy: 0.4209\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 48.8046 - accuracy: 0.4160 - val_loss: 44.9749 - val_accuracy: 0.4325\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 47.5301 - accuracy: 0.4272 - val_loss: 43.7531 - val_accuracy: 0.4441\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 46.2737 - accuracy: 0.4382 - val_loss: 42.5493 - val_accuracy: 0.4553\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 45.0358 - accuracy: 0.4488 - val_loss: 41.3687 - val_accuracy: 0.4662\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 43.8220 - accuracy: 0.4593 - val_loss: 40.2113 - val_accuracy: 0.4770\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 42.6332 - accuracy: 0.4698 - val_loss: 39.0753 - val_accuracy: 0.4878\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 41.4632 - accuracy: 0.4803 - val_loss: 37.9596 - val_accuracy: 0.4987\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 40.3085 - accuracy: 0.4908 - val_loss: 36.8577 - val_accuracy: 0.5096\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 39.1816 - accuracy: 0.5013 - val_loss: 35.7859 - val_accuracy: 0.5204\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 38.0785 - accuracy: 0.5118 - val_loss: 34.7368 - val_accuracy: 0.5313\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 36.9964 - accuracy: 0.5223 - val_loss: 33.7114 - val_accuracy: 0.5421\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 35.9389 - accuracy: 0.5328 - val_loss: 32.7087 - val_accuracy: 0.5528\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 34.9022 - accuracy: 0.5429 - val_loss: 31.7224 - val_accuracy: 0.5627\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 33.8770 - accuracy: 0.5524 - val_loss: 30.7519 - val_accuracy: 0.5724\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 32.8781 - accuracy: 0.5619 - val_loss: 29.8080 - val_accuracy: 0.5821\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 31.9085 - accuracy: 0.5715 - val_loss: 28.8974 - val_accuracy: 0.5916\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 30.9550 - accuracy: 0.5809 - val_loss: 27.9957 - val_accuracy: 0.6013\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 30.0279 - accuracy: 0.5904 - val_loss: 27.1263 - val_accuracy: 0.6109\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 29.1241 - accuracy: 0.5998 - val_loss: 26.2732 - val_accuracy: 0.6205\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 28.2322 - accuracy: 0.6092 - val_loss: 25.4374 - val_accuracy: 0.6302\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 27.3693 - accuracy: 0.6187 - val_loss: 24.6307 - val_accuracy: 0.6398\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.5267 - accuracy: 0.6281 - val_loss: 23.8382 - val_accuracy: 0.6487\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 25.7068 - accuracy: 0.6361 - val_loss: 23.0768 - val_accuracy: 0.6554\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 24.9099 - accuracy: 0.6436 - val_loss: 22.3305 - val_accuracy: 0.6622\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 24.1335 - accuracy: 0.6510 - val_loss: 21.6107 - val_accuracy: 0.6690\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 23.3740 - accuracy: 0.6584 - val_loss: 20.9057 - val_accuracy: 0.6758\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 22.6438 - accuracy: 0.6658 - val_loss: 20.2329 - val_accuracy: 0.6825\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 21.9326 - accuracy: 0.6732 - val_loss: 19.5704 - val_accuracy: 0.6893\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 21.2372 - accuracy: 0.6807 - val_loss: 18.9302 - val_accuracy: 0.6961\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 20.5697 - accuracy: 0.6881 - val_loss: 18.3219 - val_accuracy: 0.7028\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 19.9279 - accuracy: 0.6954 - val_loss: 17.7294 - val_accuracy: 0.7095\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 19.2992 - accuracy: 0.7025 - val_loss: 17.1534 - val_accuracy: 0.7148\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 18.6950 - accuracy: 0.7073 - val_loss: 16.6075 - val_accuracy: 0.7190\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 18.1122 - accuracy: 0.7121 - val_loss: 16.0748 - val_accuracy: 0.7232\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.5523 - accuracy: 0.7167 - val_loss: 15.5744 - val_accuracy: 0.7272\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.0197 - accuracy: 0.7213 - val_loss: 15.0939 - val_accuracy: 0.7313\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.5010 - accuracy: 0.7260 - val_loss: 14.6256 - val_accuracy: 0.7355\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.0041 - accuracy: 0.7307 - val_loss: 14.1834 - val_accuracy: 0.7397\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.5250 - accuracy: 0.7353 - val_loss: 13.7591 - val_accuracy: 0.7438\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.0774 - accuracy: 0.7400 - val_loss: 13.3688 - val_accuracy: 0.7478\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.6499 - accuracy: 0.7446 - val_loss: 12.9899 - val_accuracy: 0.7520\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.2411 - accuracy: 0.7480 - val_loss: 12.6357 - val_accuracy: 0.7535\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.8510 - accuracy: 0.7491 - val_loss: 12.2996 - val_accuracy: 0.7545\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.4925 - accuracy: 0.7499 - val_loss: 11.9947 - val_accuracy: 0.7554\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.1483 - accuracy: 0.7510 - val_loss: 11.7014 - val_accuracy: 0.7563\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.8209 - accuracy: 0.7518 - val_loss: 11.4275 - val_accuracy: 0.7573\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.5189 - accuracy: 0.7527 - val_loss: 11.1799 - val_accuracy: 0.7582\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.2423 - accuracy: 0.7536 - val_loss: 10.9561 - val_accuracy: 0.7591\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.9855 - accuracy: 0.7546 - val_loss: 10.7491 - val_accuracy: 0.7600\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.7468 - accuracy: 0.7555 - val_loss: 10.5615 - val_accuracy: 0.7609\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 11.5280 - accuracy: 0.7564 - val_loss: 10.3972 - val_accuracy: 0.7618\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 11.3382 - accuracy: 0.7562 - val_loss: 10.2547 - val_accuracy: 0.7598\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.1632 - accuracy: 0.7539 - val_loss: 10.1300 - val_accuracy: 0.7569\n",
      "Epoch 81/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.0060 - accuracy: 0.7513 - val_loss: 10.0226 - val_accuracy: 0.7541\n",
      "Epoch 82/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.8661 - accuracy: 0.7489 - val_loss: 9.9317 - val_accuracy: 0.7511\n",
      "Epoch 83/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.7521 - accuracy: 0.7464 - val_loss: 9.8680 - val_accuracy: 0.7485\n",
      "21/21 - 0s - loss: 9.8680 - accuracy: 0.7485 - 42ms/epoch - 2ms/step\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 10ms/step - loss: 37.9751 - accuracy: 0.5441 - val_loss: 9.4131 - val_accuracy: 0.8155\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.7103 - accuracy: 0.8075 - val_loss: 6.5481 - val_accuracy: 0.8294\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.1054 - accuracy: 0.8166 - val_loss: 6.5105 - val_accuracy: 0.8077\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.9237 - accuracy: 0.8132 - val_loss: 6.2368 - val_accuracy: 0.8216\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.7221 - accuracy: 0.8175 - val_loss: 6.0957 - val_accuracy: 0.8241\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5061 - accuracy: 0.8229 - val_loss: 5.8485 - val_accuracy: 0.8250\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1467 - accuracy: 0.8285 - val_loss: 5.7529 - val_accuracy: 0.8148\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.8103 - accuracy: 0.8328 - val_loss: 5.0446 - val_accuracy: 0.8477\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.4741 - accuracy: 0.8387 - val_loss: 4.9957 - val_accuracy: 0.8344\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.2257 - accuracy: 0.8423 - val_loss: 5.3699 - val_accuracy: 0.8033\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.0615 - accuracy: 0.8422 - val_loss: 4.8402 - val_accuracy: 0.8351\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.9909 - accuracy: 0.8444 - val_loss: 4.5864 - val_accuracy: 0.8517\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.9028 - accuracy: 0.8470 - val_loss: 4.8589 - val_accuracy: 0.8241\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.8517 - accuracy: 0.8461 - val_loss: 4.5058 - val_accuracy: 0.8426\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7338 - accuracy: 0.8470 - val_loss: 4.6229 - val_accuracy: 0.8458\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7966 - accuracy: 0.8463 - val_loss: 4.4936 - val_accuracy: 0.8523\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7272 - accuracy: 0.8457 - val_loss: 4.6995 - val_accuracy: 0.8282\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7841 - accuracy: 0.8471 - val_loss: 4.4077 - val_accuracy: 0.8513\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.7114 - accuracy: 0.8489 - val_loss: 4.7208 - val_accuracy: 0.8365\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6536 - accuracy: 0.8476 - val_loss: 4.7703 - val_accuracy: 0.8444\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.5535 - accuracy: 0.8508 - val_loss: 4.9339 - val_accuracy: 0.8157\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.7792 - accuracy: 0.8418 - val_loss: 4.3076 - val_accuracy: 0.8558\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5325 - accuracy: 0.8514 - val_loss: 4.7070 - val_accuracy: 0.8264\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4641 - accuracy: 0.8506 - val_loss: 4.3574 - val_accuracy: 0.8520\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4728 - accuracy: 0.8521 - val_loss: 4.3533 - val_accuracy: 0.8438\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4101 - accuracy: 0.8534 - val_loss: 4.6462 - val_accuracy: 0.8303\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4568 - accuracy: 0.8522 - val_loss: 5.3974 - val_accuracy: 0.8075\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.6372 - accuracy: 0.8465 - val_loss: 4.2733 - val_accuracy: 0.8505\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3947 - accuracy: 0.8535 - val_loss: 4.4276 - val_accuracy: 0.8337\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.4309 - accuracy: 0.8521 - val_loss: 4.5367 - val_accuracy: 0.8343\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.4025 - accuracy: 0.8515 - val_loss: 4.3258 - val_accuracy: 0.8473\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.5201 - accuracy: 0.8492 - val_loss: 4.3104 - val_accuracy: 0.8496\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.4458 - accuracy: 0.8516 - val_loss: 4.7632 - val_accuracy: 0.8163\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4.3885 - accuracy: 0.8524 - val_loss: 4.2731 - val_accuracy: 0.8539\n",
      "21/21 - 0s - loss: 4.2731 - accuracy: 0.8539 - 43ms/epoch - 2ms/step\n",
      "Best hyperparameters: {'activation': 'tanh', 'batch_size': 32, 'optimizer': 'sgd', 'dropout': 'no'}\n",
      "Best validation accuracy: 0.8571187257766724\n"
     ]
    }
   ],
   "source": [
    "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용X)\n",
    "act_func = ['relu', 'tanh']\n",
    "batch_lst = [8, 16, 32, 64, 128]\n",
    "opt_lst = ['adam', 'rmsprop', 'sgd']\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            # 모델 구현\n",
    "            model = Sequential()\n",
    "            model.add(Dense(64, activation=func, input_dim=x.shape[1]))\n",
    "            model.add(Dense(32, activation=func))              \n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(4, activation=func))\n",
    "            model.add(Dense(1, activation='linear'))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(loss='mse', optimizer=opti, metrics=[accuracy])\n",
    "\n",
    "            # early stopping 구현 - 커스텀 정확도 기준\n",
    "            early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'optimizer': opti, 'dropout': 'no'}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST MODEL\n",
    "1. early stopping을 통해 정확도가 높은 모델 선정\n",
    "\n",
    "2. 검증 데이터를 통해 검증 정확도가 높은 모델 선정 - 과적합 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'activation': 'tanh', 'batch_size': 32, 'optimizer': 'sgd', 'dropout': 'no'}\n",
      "Best accuracy: 0.8571187257766724\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best accuracy:', best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[안내] 모델이 실행됩니다.\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 13.5313 - accuracy: 0.7575 - val_loss: 7.3383 - val_accuracy: 0.7576\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.2903 - accuracy: 0.8226 - val_loss: 6.3149 - val_accuracy: 0.8223\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4810 - accuracy: 0.8344 - val_loss: 4.9085 - val_accuracy: 0.8352\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2057 - accuracy: 0.8381 - val_loss: 5.2294 - val_accuracy: 0.8051\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0363 - accuracy: 0.8402 - val_loss: 4.5126 - val_accuracy: 0.8513\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8435 - accuracy: 0.8448 - val_loss: 4.9233 - val_accuracy: 0.8417\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7926 - accuracy: 0.8445 - val_loss: 4.6663 - val_accuracy: 0.8236\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6748 - accuracy: 0.8466 - val_loss: 4.4445 - val_accuracy: 0.8392\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7245 - accuracy: 0.8458 - val_loss: 4.4625 - val_accuracy: 0.8362\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6081 - accuracy: 0.8463 - val_loss: 4.4224 - val_accuracy: 0.8580\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6589 - accuracy: 0.8471 - val_loss: 4.3952 - val_accuracy: 0.8426\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5481 - accuracy: 0.8503 - val_loss: 4.2798 - val_accuracy: 0.8556\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5250 - accuracy: 0.8479 - val_loss: 4.7666 - val_accuracy: 0.8437\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6017 - accuracy: 0.8468 - val_loss: 4.4020 - val_accuracy: 0.8478\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4885 - accuracy: 0.8475 - val_loss: 5.6330 - val_accuracy: 0.8288\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5399 - accuracy: 0.8475 - val_loss: 4.5743 - val_accuracy: 0.8357\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4681 - accuracy: 0.8514 - val_loss: 4.3446 - val_accuracy: 0.8550\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4849 - accuracy: 0.8515 - val_loss: 4.3708 - val_accuracy: 0.8484\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3935 - accuracy: 0.8522 - val_loss: 4.2507 - val_accuracy: 0.8546\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4843 - accuracy: 0.8490 - val_loss: 4.1961 - val_accuracy: 0.8462\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3963 - accuracy: 0.8500 - val_loss: 4.2363 - val_accuracy: 0.8493\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3189 - accuracy: 0.8518 - val_loss: 4.7057 - val_accuracy: 0.8297\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3220 - accuracy: 0.8514 - val_loss: 4.2688 - val_accuracy: 0.8462\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3753 - accuracy: 0.8517 - val_loss: 4.3364 - val_accuracy: 0.8436\n",
      "131/131 [==============================] - 0s 1ms/step\n",
      "[안내] 최종 모델\n",
      "[안내] train loss, accuracy\n",
      "84/84 - 0s - loss: 4.1426 - accuracy: 0.8550 - 122ms/epoch - 1ms/step\n",
      "[안내] validation loss, accuracy\n",
      "21/21 - 0s - loss: 4.3364 - accuracy: 0.8436 - 45ms/epoch - 2ms/step\n",
      "[안내] 실행 시간 : 6.070 seconds\n",
      "[안내] 샘플 10개의 결과\n",
      "      Rings       pred\n",
      "1437      6   6.981085\n",
      "728      13  12.539680\n",
      "3470     11  12.399845\n",
      "2856     11   9.402239\n",
      "1178      9  11.320084\n",
      "1061      6   5.034081\n",
      "2467     16  11.640235\n",
      "2486     13  14.279268\n",
      "3289     15  11.623315\n",
      "850      10  11.831802\n"
     ]
    }
   ],
   "source": [
    "# 최고 모델 사용자 친화적 구현\n",
    "start_time = time.time()\n",
    "print(\"[안내] 모델이 실행됩니다.\")\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='tanh', input_dim=x.shape[1]))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "model.add(Dense(4, activation='tanh'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=[accuracy])\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "\n",
    "if input_2 == 'y':\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    y_pred = model.predict(X)\n",
    "else:\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "print(\"[안내] 최종 모델\")\n",
    "if input_2 == 'y':\n",
    "    print(\"[안내] train loss, accuracy\")\n",
    "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "    print(\"[안내] validation loss, accuracy\")\n",
    "    loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "else:\n",
    "    print(\"[안내] train loss, accuracy\")\n",
    "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "    print(\"[안내] test loss, accuracy\")\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"[안내] 실행 시간 : {:.3f} seconds\".format(execution_time))\n",
    "\n",
    "input_3 = input(\"[안내] 예측 샘플을 확인할까요? : \")\n",
    "if input_3 == 'y':\n",
    "    print(\"[안내] 샘플 10개의 결과\")\n",
    "    new_y = y\n",
    "    stacked_array = np.vstack((y_pred))\n",
    "    new_df = pd.DataFrame(stacked_array)\n",
    "    new_y = pd.DataFrame(new_y)\n",
    "    new_y['pred'] = new_df[0]\n",
    "    print(new_y.sample(10))\n",
    "else:\n",
    "    print(\"[안내] 실행을 종료합니다.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model Advanced\n",
    "실행 샘플 데이터 - 분포가 많은 값으로 예측한 것으로 추측\n",
    "-> dropout 을 사용한 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[안내] 모델이 실행됩니다.\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 2s 4ms/step - loss: 39.9279 - accuracy: 0.4857 - val_loss: 8.6186 - val_accuracy: 0.8031\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 20.1747 - accuracy: 0.6566 - val_loss: 6.0916 - val_accuracy: 0.8434\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 17.6490 - accuracy: 0.6749 - val_loss: 6.9548 - val_accuracy: 0.8296\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 16.1590 - accuracy: 0.6954 - val_loss: 6.1991 - val_accuracy: 0.8353\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 14.0945 - accuracy: 0.7142 - val_loss: 5.5175 - val_accuracy: 0.8501\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.4944 - accuracy: 0.7231 - val_loss: 5.3725 - val_accuracy: 0.8489\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.3775 - accuracy: 0.7276 - val_loss: 4.9858 - val_accuracy: 0.8444\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.6834 - accuracy: 0.7342 - val_loss: 5.4584 - val_accuracy: 0.8511\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.5178 - accuracy: 0.7424 - val_loss: 5.7562 - val_accuracy: 0.8473\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.4888 - accuracy: 0.7435 - val_loss: 5.5588 - val_accuracy: 0.8508\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.5177 - accuracy: 0.7576 - val_loss: 4.8759 - val_accuracy: 0.8488\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.1149 - accuracy: 0.7544 - val_loss: 4.8450 - val_accuracy: 0.8576\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.8062 - accuracy: 0.7565 - val_loss: 4.4886 - val_accuracy: 0.8519\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.0953 - accuracy: 0.7615 - val_loss: 4.5862 - val_accuracy: 0.8542\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.3795 - accuracy: 0.7593 - val_loss: 5.2512 - val_accuracy: 0.8560\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4866 - accuracy: 0.7667 - val_loss: 4.8480 - val_accuracy: 0.8583\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7910 - accuracy: 0.7643 - val_loss: 4.4812 - val_accuracy: 0.8543\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.5229 - accuracy: 0.7696 - val_loss: 4.8556 - val_accuracy: 0.8571\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.7444 - accuracy: 0.7647 - val_loss: 4.6316 - val_accuracy: 0.8570\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.4380 - accuracy: 0.7761 - val_loss: 4.6377 - val_accuracy: 0.8544\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0565 - accuracy: 0.7705 - val_loss: 4.5018 - val_accuracy: 0.8510\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.0488 - accuracy: 0.7778 - val_loss: 4.5816 - val_accuracy: 0.8517\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.8714 - accuracy: 0.7757 - val_loss: 4.6215 - val_accuracy: 0.8584\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.1445 - accuracy: 0.7747 - val_loss: 5.2088 - val_accuracy: 0.8516\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2436 - accuracy: 0.7786 - val_loss: 4.4895 - val_accuracy: 0.8555\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.2391 - accuracy: 0.7768 - val_loss: 4.8947 - val_accuracy: 0.8556\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.1836 - accuracy: 0.7784 - val_loss: 4.8641 - val_accuracy: 0.8545\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.0100 - accuracy: 0.7786 - val_loss: 4.7892 - val_accuracy: 0.8539\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.4178 - accuracy: 0.7806 - val_loss: 4.8472 - val_accuracy: 0.8517\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.7472 - accuracy: 0.7787 - val_loss: 4.7063 - val_accuracy: 0.8546\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.5463 - accuracy: 0.7822 - val_loss: 4.4561 - val_accuracy: 0.8577\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.8055 - accuracy: 0.7808 - val_loss: 4.4568 - val_accuracy: 0.8535\n",
      "Epoch 33/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.6386 - accuracy: 0.7822 - val_loss: 4.5633 - val_accuracy: 0.8575\n",
      "Epoch 34/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.4872 - accuracy: 0.7836 - val_loss: 4.4552 - val_accuracy: 0.8575\n",
      "Epoch 35/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.2146 - accuracy: 0.7859 - val_loss: 4.6959 - val_accuracy: 0.8585\n",
      "Epoch 36/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.7069 - accuracy: 0.7855 - val_loss: 4.6098 - val_accuracy: 0.8571\n",
      "Epoch 37/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.4483 - accuracy: 0.7877 - val_loss: 4.5887 - val_accuracy: 0.8533\n",
      "Epoch 38/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.3307 - accuracy: 0.7882 - val_loss: 4.4735 - val_accuracy: 0.8562\n",
      "Epoch 39/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.0840 - accuracy: 0.7926 - val_loss: 4.4850 - val_accuracy: 0.8541\n",
      "Epoch 40/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.9249 - accuracy: 0.7928 - val_loss: 4.4458 - val_accuracy: 0.8505\n",
      "Epoch 41/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.8769 - accuracy: 0.7918 - val_loss: 4.5169 - val_accuracy: 0.8540\n",
      "Epoch 42/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.0534 - accuracy: 0.7890 - val_loss: 4.8471 - val_accuracy: 0.8563\n",
      "Epoch 43/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.9671 - accuracy: 0.7933 - val_loss: 4.5205 - val_accuracy: 0.8532\n",
      "Epoch 44/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6005 - accuracy: 0.7944 - val_loss: 4.8622 - val_accuracy: 0.8571\n",
      "Epoch 45/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.0278 - accuracy: 0.7931 - val_loss: 4.5445 - val_accuracy: 0.8558\n",
      "Epoch 46/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6723 - accuracy: 0.7959 - val_loss: 4.6080 - val_accuracy: 0.8549\n",
      "Epoch 47/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.7742 - accuracy: 0.7964 - val_loss: 4.4834 - val_accuracy: 0.8537\n",
      "Epoch 48/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.9700 - accuracy: 0.7929 - val_loss: 4.4830 - val_accuracy: 0.8559\n",
      "Epoch 49/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6440 - accuracy: 0.7956 - val_loss: 4.4421 - val_accuracy: 0.8549\n",
      "Epoch 50/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1991 - accuracy: 0.7998 - val_loss: 4.4663 - val_accuracy: 0.8458\n",
      "Epoch 51/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.1652 - accuracy: 0.7936 - val_loss: 4.3798 - val_accuracy: 0.8534\n",
      "Epoch 52/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3027 - accuracy: 0.8017 - val_loss: 4.6045 - val_accuracy: 0.8554\n",
      "Epoch 53/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2316 - accuracy: 0.8006 - val_loss: 4.4725 - val_accuracy: 0.8542\n",
      "Epoch 54/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6984 - accuracy: 0.7982 - val_loss: 4.5271 - val_accuracy: 0.8526\n",
      "Epoch 55/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1169 - accuracy: 0.8036 - val_loss: 4.4601 - val_accuracy: 0.8561\n",
      "Epoch 56/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1679 - accuracy: 0.8049 - val_loss: 4.3654 - val_accuracy: 0.8538\n",
      "Epoch 57/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3688 - accuracy: 0.8014 - val_loss: 4.4303 - val_accuracy: 0.8514\n",
      "Epoch 58/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0960 - accuracy: 0.8039 - val_loss: 4.6401 - val_accuracy: 0.8549\n",
      "Epoch 59/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0917 - accuracy: 0.8002 - val_loss: 4.5175 - val_accuracy: 0.8543\n",
      "Epoch 60/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.7652 - accuracy: 0.8070 - val_loss: 4.5803 - val_accuracy: 0.8569\n",
      "Epoch 61/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.4458 - accuracy: 0.8012 - val_loss: 4.5434 - val_accuracy: 0.8565\n",
      "Epoch 62/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.9221 - accuracy: 0.8064 - val_loss: 4.4815 - val_accuracy: 0.8475\n",
      "Epoch 63/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.8650 - accuracy: 0.8089 - val_loss: 4.3782 - val_accuracy: 0.8531\n",
      "Epoch 64/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3848 - accuracy: 0.8033 - val_loss: 4.4291 - val_accuracy: 0.8535\n",
      "Epoch 65/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0464 - accuracy: 0.8053 - val_loss: 4.5372 - val_accuracy: 0.8565\n",
      "Epoch 66/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.8615 - accuracy: 0.8106 - val_loss: 4.3668 - val_accuracy: 0.8531\n",
      "Epoch 67/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0829 - accuracy: 0.8084 - val_loss: 4.4676 - val_accuracy: 0.8526\n",
      "Epoch 68/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6813 - accuracy: 0.8088 - val_loss: 4.7473 - val_accuracy: 0.8551\n",
      "Epoch 69/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6875 - accuracy: 0.8090 - val_loss: 4.5200 - val_accuracy: 0.8555\n",
      "Epoch 70/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6861 - accuracy: 0.8131 - val_loss: 4.5730 - val_accuracy: 0.8558\n",
      "Epoch 71/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5822 - accuracy: 0.8127 - val_loss: 4.5358 - val_accuracy: 0.8564\n",
      "Epoch 72/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6742 - accuracy: 0.8112 - val_loss: 4.3864 - val_accuracy: 0.8448\n",
      "Epoch 73/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.4608 - accuracy: 0.8136 - val_loss: 4.3269 - val_accuracy: 0.8526\n",
      "Epoch 74/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.7052 - accuracy: 0.8097 - val_loss: 4.4375 - val_accuracy: 0.8445\n",
      "Epoch 75/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6639 - accuracy: 0.8121 - val_loss: 4.5474 - val_accuracy: 0.8523\n",
      "Epoch 76/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0832 - accuracy: 0.8084 - val_loss: 4.3439 - val_accuracy: 0.8498\n",
      "Epoch 77/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.4022 - accuracy: 0.8141 - val_loss: 4.2696 - val_accuracy: 0.8559\n",
      "Epoch 78/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.4580 - accuracy: 0.8113 - val_loss: 4.4619 - val_accuracy: 0.8530\n",
      "Epoch 79/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.3734 - accuracy: 0.8165 - val_loss: 4.3176 - val_accuracy: 0.8486\n",
      "Epoch 80/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0675 - accuracy: 0.8202 - val_loss: 4.2993 - val_accuracy: 0.8508\n",
      "Epoch 81/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4367 - accuracy: 0.8158 - val_loss: 4.3873 - val_accuracy: 0.8460\n",
      "Epoch 82/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1866 - accuracy: 0.8192 - val_loss: 4.3710 - val_accuracy: 0.8517\n",
      "Epoch 83/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7897 - accuracy: 0.8113 - val_loss: 4.5201 - val_accuracy: 0.8511\n",
      "Epoch 84/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0256 - accuracy: 0.8175 - val_loss: 4.3808 - val_accuracy: 0.8478\n",
      "Epoch 85/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3108 - accuracy: 0.8174 - val_loss: 4.3463 - val_accuracy: 0.8468\n",
      "131/131 [==============================] - 0s 1ms/step\n",
      "[안내] 최종 모델\n",
      "[안내] train loss, accuracy\n",
      "84/84 - 0s - loss: 3.7997 - accuracy: 0.8607 - 125ms/epoch - 1ms/step\n",
      "[안내] validation loss, accuracy\n",
      "21/21 - 0s - loss: 4.3463 - accuracy: 0.8468 - 52ms/epoch - 2ms/step\n",
      "[안내] 실행 시간 : 19.306 seconds\n",
      "[안내] 샘플 10개의 결과\n",
      "      Rings       pred\n",
      "41       14  11.026981\n",
      "2398     14   9.980166\n",
      "534      10   9.393583\n",
      "4063     11  11.600614\n",
      "2330      9   8.405786\n",
      "2369     12  14.531243\n",
      "1855      9   7.935930\n",
      "2974     12  10.983240\n",
      "679       8   8.640882\n",
      "1218      5   6.573978\n"
     ]
    }
   ],
   "source": [
    "# 최고 모델 사용자 친화적 구현\n",
    "start_time = time.time()\n",
    "print(\"[안내] 모델이 실행됩니다.\")\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=x.shape[1]))\n",
    "model.add(Dropout(0.1))  # Dropout 추가\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.1))  # Dropout 추가\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))  # Dropout 추가\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.1))  # Dropout 추가\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dropout(0.1))  # Dropout 추가\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[accuracy])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "\n",
    "if input_2 == 'y':\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    y_pred = model.predict(X)\n",
    "else:\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "print(\"[안내] 최종 모델\")\n",
    "if input_2 == 'y':\n",
    "    print(\"[안내] train loss, accuracy\")\n",
    "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "    print(\"[안내] validation loss, accuracy\")\n",
    "    loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "else:\n",
    "    print(\"[안내] train loss, accuracy\")\n",
    "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "    print(\"[안내] test loss, accuracy\")\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"[안내] 실행 시간 : {:.3f} seconds\".format(execution_time))\n",
    "\n",
    "input_3 = input(\"[안내] 예측 샘플을 확인할까요? : \")\n",
    "if input_3 == 'y':\n",
    "    print(\"[안내] 샘플 10개의 결과\")\n",
    "    new_y = y\n",
    "    stacked_array = np.vstack((y_pred))\n",
    "    new_df = pd.DataFrame(stacked_array)\n",
    "    new_y = pd.DataFrame(new_y)\n",
    "    new_y['pred'] = new_df[0]\n",
    "    print(new_y.sample(10))\n",
    "else:\n",
    "    print(\"[안내] 실행을 종료합니다.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 model 구현\n",
    "* 고려사항\n",
    "\n",
    "1. 실행시간이 짧은 Best Model 1번 사용\n",
    "\n",
    "2. 사용자 친화적 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저로 부터 입력을 받아 검증 데이터 셋을 사용할 것인지, 표준화를 사용할 것인지 정함.\n",
    "def create_best():\n",
    "    print(\"[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\")\n",
    "    input_1 = input(\"[안내] 데이터를 표준화 하시겠습니까? : \")\n",
    "    input_2 = input(\"[안내] 검증 데이터셋을 분리할까요? : \")\n",
    "\n",
    "    # 표준화 진행 여부\n",
    "    if input_1 == 'y':\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(x)\n",
    "        print(\"[안내] 데이터 표준화를 진행했습니다.\")\n",
    "    else:\n",
    "        X = x\n",
    "        print(\"[안내] 데이터 표준화를 진행하지 않습니다.\")\n",
    "\n",
    "    # 검증 데이터 진행 여부\n",
    "    if input_2 == 'y':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "        print(\"[안내] 검증 데이터를 추가로 분리했습니다.\")\n",
    "\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(\"[안내] 검증 데이터를 분리하지 않았습니다.\")\n",
    "\n",
    "    # 최고 모델 사용자 친화적 구현\n",
    "    start_time = time.time()\n",
    "    print(\"[안내] 모델이 실행됩니다.\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='tanh', input_dim=x.shape[1]))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dense(8, activation='tanh'))\n",
    "    model.add(Dense(4, activation='tanh'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='sgd', metrics=[accuracy])\n",
    "    early_stopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "\n",
    "    if input_2 == 'y':\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        y_pred = model.predict(X)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "    print(\"[안내] 최종 모델\")\n",
    "    if input_2 == 'y':\n",
    "        print(\"[안내] train loss, accuracy\")\n",
    "        train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "        print(\"[안내] validation loss, accuracy\")\n",
    "        loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "    else:\n",
    "        print(\"[안내] train loss, accuracy\")\n",
    "        train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "        print(\"[안내] test loss, accuracy\")\n",
    "        loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    print(\"[안내] 실행 시간 : {:.3f} seconds\".format(execution_time))\n",
    "\n",
    "    input_3 = input(\"[안내] 예측 샘플을 확인할까요? : \")\n",
    "    if input_3 == 'y':\n",
    "        print(\"[안내] 샘플 10개의 결과\")\n",
    "        new_y = y\n",
    "        stacked_array = np.vstack((y_pred))\n",
    "        new_df = pd.DataFrame(stacked_array)\n",
    "        new_y = pd.DataFrame(new_y)\n",
    "        new_y['pred'] = new_df[0]\n",
    "        print(new_y.sample(10))\n",
    "        print(\"[안내] 실행을 종료합니다.\")\n",
    "\n",
    "    else:\n",
    "        print(\"[안내] 실행을 종료합니다.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[안내] 모델링을 시작합니다. (y or n)으로 진행해주세요\n",
      "[안내] 데이터 표준화를 진행했습니다.\n",
      "[안내] 검증 데이터를 추가로 분리했습니다.\n",
      "[안내] 모델이 실행됩니다.\n",
      "Epoch 1/1000\n",
      "84/84 [==============================] - 1s 4ms/step - loss: 14.8807 - accuracy: 0.7425 - val_loss: 6.8556 - val_accuracy: 0.7796\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.4742 - accuracy: 0.8189 - val_loss: 6.0546 - val_accuracy: 0.8004\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4681 - accuracy: 0.8347 - val_loss: 5.6419 - val_accuracy: 0.7908\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1346 - accuracy: 0.8383 - val_loss: 5.2808 - val_accuracy: 0.8156\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0836 - accuracy: 0.8383 - val_loss: 4.9870 - val_accuracy: 0.8370\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8500 - accuracy: 0.8452 - val_loss: 5.0930 - val_accuracy: 0.8229\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7599 - accuracy: 0.8456 - val_loss: 4.6503 - val_accuracy: 0.8341\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7465 - accuracy: 0.8449 - val_loss: 4.7282 - val_accuracy: 0.8400\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6223 - accuracy: 0.8487 - val_loss: 4.6614 - val_accuracy: 0.8440\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5859 - accuracy: 0.8476 - val_loss: 4.9642 - val_accuracy: 0.8084\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5688 - accuracy: 0.8473 - val_loss: 5.5856 - val_accuracy: 0.8205\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4998 - accuracy: 0.8502 - val_loss: 5.2856 - val_accuracy: 0.7932\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4561 - accuracy: 0.8516 - val_loss: 4.5705 - val_accuracy: 0.8486\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5058 - accuracy: 0.8495 - val_loss: 4.3193 - val_accuracy: 0.8497\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4128 - accuracy: 0.8515 - val_loss: 4.8551 - val_accuracy: 0.8252\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4178 - accuracy: 0.8514 - val_loss: 5.9671 - val_accuracy: 0.7804\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5043 - accuracy: 0.8480 - val_loss: 4.3322 - val_accuracy: 0.8435\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3307 - accuracy: 0.8522 - val_loss: 4.4643 - val_accuracy: 0.8449\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3723 - accuracy: 0.8514 - val_loss: 4.3455 - val_accuracy: 0.8463\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3511 - accuracy: 0.8510 - val_loss: 4.3745 - val_accuracy: 0.8514\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3122 - accuracy: 0.8520 - val_loss: 4.3747 - val_accuracy: 0.8416\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2808 - accuracy: 0.8533 - val_loss: 4.5865 - val_accuracy: 0.8427\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.3376 - accuracy: 0.8512 - val_loss: 4.9135 - val_accuracy: 0.8107\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2942 - accuracy: 0.8518 - val_loss: 4.4367 - val_accuracy: 0.8389\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2715 - accuracy: 0.8525 - val_loss: 4.4740 - val_accuracy: 0.8354\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2872 - accuracy: 0.8529 - val_loss: 4.7518 - val_accuracy: 0.8339\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.2789 - accuracy: 0.8531 - val_loss: 4.5857 - val_accuracy: 0.8274\n",
      "131/131 [==============================] - 0s 943us/step\n",
      "[안내] 최종 모델\n",
      "[안내] train loss, accuracy\n",
      "84/84 - 0s - loss: 4.2456 - accuracy: 0.8389 - 96ms/epoch - 1ms/step\n",
      "[안내] validation loss, accuracy\n",
      "21/21 - 0s - loss: 4.5857 - accuracy: 0.8274 - 43ms/epoch - 2ms/step\n",
      "[안내] 실행 시간 : 5.841 seconds\n",
      "[안내] 샘플 10개의 결과\n",
      "      Rings       pred\n",
      "2183      6  15.308678\n",
      "1033     10  13.749382\n",
      "1779      9   7.927064\n",
      "2590      8  10.104479\n",
      "248       7   6.621666\n",
      "2931      9  10.401048\n",
      "3664      9  10.256289\n",
      "2276     14  14.942583\n",
      "1082      7   7.944169\n",
      "3249      6   7.652831\n",
      "[안내] 실행을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "create_best()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
