{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler,StandardScaler\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기\n",
    "\n",
    "- 최종적으로 데이터는 EDA과정을 feature를 생성한 값을 사용한다\n",
    "\n",
    "- if! normalize 과정이 주는 영향 체크 필요(모델2, 모델3은 오히려 성능 감소)\n",
    "\n",
    "- y는 log scale을 취했을 때에 평균적인 validation accuracy가 0.1 상승하는 것을 확인했음. - log 스케일로 진행\n",
    " : 과정에서 필요한 costom metric의 경우 exp 값을 취해 정상적으로 계산되게 만들어 주는 것이 필요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_model1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df.columns.tolist()\n",
    "feature_cols.remove('Target')\n",
    "target_cols = ['Target']\n",
    "remove_list = ['Sex_I','Sex_F','Sex_M']\n",
    "for col in remove_list:\n",
    "    feature_cols.remove(col)\n",
    "pipeline = Pipeline([('normalizer', Normalizer()),\n",
    "                     ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Target'], axis = 1)\n",
    "y = df['Target']\n",
    "\n",
    "# target 칼럼 log scale 적용\n",
    "y = np.log10(y)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test = train_test_split(X, test_size= 0.2, random_state = 42)\n",
    "y_train, y_test = train_test_split(y, test_size= 0.2, random_state = 42)\n",
    "X_train, X_val = train_test_split(X_train, test_size = 0.2, random_state = 42)\n",
    "y_train, y_val = train_test_split(y_train, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# pipeline을 통해 normalize와 standard scaler 적용\n",
    "X_train[feature_cols] = pipeline.fit_transform(X_train[feature_cols])\n",
    "X_test[feature_cols] = pipeline.transform(X_test[feature_cols])\n",
    "X_val[feature_cols] = pipeline.transform(X_val[feature_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현\n",
    "\n",
    "1. 인터넷 검색 모델\n",
    "\n",
    "2. 최적의 파라미터 및 은닉층, 노드수 계산 모델\n",
    "\n",
    "3. 최종 모델 선택 - 시간 고려(X) /// 추후 시간을 고려하는 모델과 성능을 고려하는 모델 두 가지 선택기능 구현 가능성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 인터넷 검색 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Final_model =======\n",
      "train loss, train accuracy\n",
      "84/84 - 0s - loss: 0.0656 - accuracy: 0.9349 - 91ms/epoch - 1ms/step\n",
      "validation loss, validation accuracy\n",
      "21/21 - 0s - loss: 0.0651 - accuracy: 0.9350 - 40ms/epoch - 2ms/step\n",
      "====== Final_model =======\n",
      "train loss, train accuracy\n",
      "84/84 - 0s - loss: 0.0648 - accuracy: 0.9359 - 95ms/epoch - 1ms/step\n",
      "validation loss, validation accuracy\n",
      "21/21 - 0s - loss: 0.0649 - accuracy: 0.9354 - 44ms/epoch - 2ms/step\n",
      "====== Final_model =======\n",
      "train loss, train accuracy\n",
      "84/84 - 0s - loss: 0.0695 - accuracy: 0.9304 - 92ms/epoch - 1ms/step\n",
      "validation loss, validation accuracy\n",
      "21/21 - 0s - loss: 0.0692 - accuracy: 0.9303 - 44ms/epoch - 2ms/step\n",
      "====== Final_model =======\n",
      "train loss, train accuracy\n",
      "84/84 - 0s - loss: 0.0699 - accuracy: 0.9306 - 91ms/epoch - 1ms/step\n",
      "validation loss, validation accuracy\n",
      "21/21 - 0s - loss: 0.0693 - accuracy: 0.9309 - 43ms/epoch - 2ms/step\n",
      "====== Final_model =======\n",
      "train loss, train accuracy\n",
      "84/84 - 0s - loss: 0.0709 - accuracy: 0.9302 - 98ms/epoch - 1ms/step\n",
      "validation loss, validation accuracy\n",
      "21/21 - 0s - loss: 0.0695 - accuracy: 0.9311 - 37ms/epoch - 2ms/step\n",
      "0.9325694561004638\n"
     ]
    }
   ],
   "source": [
    "# 인터넷 구현 모델\n",
    "\n",
    "# optimizer 구현 부분\n",
    "schedule = tensorflow.optimizers.schedules.PiecewiseConstantDecay(\n",
    "                [100, 150], [1e-0, 1e-1, 1e-2])\n",
    "step = tf.Variable(0, trainable=False)\n",
    "wd = lambda: 1e-3 * schedule(step)\n",
    "optimizer = AdamW(learning_rate=0.001, weight_decay=wd)\n",
    "def custom_opt(n):\n",
    "    schedule = tensorflow.optimizers.schedules.PiecewiseConstantDecay([100, 150], [1e-0, 1e-1, 1e-2])\n",
    "    step = tf.Variable(0, trainable=False)\n",
    "    wd = lambda: 1e-3 * schedule(step)\n",
    "    opt = AdamW(learning_rate = n, weight_decay = wd)\n",
    "    return opt\n",
    "\n",
    "# custom_metric 구현 - log scale 고려\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.math.exp(y_true)\n",
    "    y_pred = tf.math.exp(y_pred)\n",
    "    return 1 - tf.abs((y_true - y_pred) / y_true)\n",
    "check = []\n",
    "for _ in range(5):\n",
    "    # 모델 구현\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='elu', input_dim=X_train.shape[1]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))              \n",
    "    model.add(Dense(16, activation='elu'))\n",
    "    model.add(Dense(16, activation='elu'))\n",
    "    model.add(Dense(1, activation='elu'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(loss='mae', optimizer=optimizer , metrics=[accuracy])\n",
    "\n",
    "    # early stopping 구현추가\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=256, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    print(\"====== Final_model =======\")\n",
    "    print(\"train loss, train accuracy\")\n",
    "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose =2)\n",
    "\n",
    "    print(\"validation loss, validation accuracy\")\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "    check.append(val_acc)\n",
    "\n",
    "print(np.mean(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize 효과 체크\n",
    "# train test split\n",
    "X_train_scaled, X_test_scaled = train_test_split(X, test_size= 0.2, random_state = 42)\n",
    "y_train, y_test = train_test_split(y, test_size= 0.2, random_state = 42)\n",
    "X_train_scaled, X_val_scaled = train_test_split(X_train_scaled, test_size = 0.2, random_state = 42)\n",
    "y_train, y_val = train_test_split(y_train, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# standard scaler 적용\n",
    "X_train_scaled[feature_cols] = scaler.fit_transform(X_train_scaled[feature_cols])\n",
    "X_test_scaled[feature_cols] = scaler.transform(X_test_scaled[feature_cols])\n",
    "X_val_scaled[feature_cols] = scaler.transform(X_val_scaled[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Final_model =======\n",
      "train loss, train accuracy\n",
      "84/84 - 0s - loss: 0.0679 - accuracy: 0.9329 - 99ms/epoch - 1ms/step\n",
      "validation loss, validation accuracy\n",
      "21/21 - 0s - loss: 0.0672 - accuracy: 0.9332 - 40ms/epoch - 2ms/step\n",
      "====== Final_model =======\n",
      "train loss, train accuracy\n",
      "84/84 - 0s - loss: 0.0810 - accuracy: 0.9196 - 88ms/epoch - 1ms/step\n",
      "validation loss, validation accuracy\n",
      "21/21 - 0s - loss: 0.0793 - accuracy: 0.9210 - 38ms/epoch - 2ms/step\n",
      "====== Final_model =======\n",
      "train loss, train accuracy\n",
      "84/84 - 0s - loss: 0.0715 - accuracy: 0.9298 - 92ms/epoch - 1ms/step\n",
      "validation loss, validation accuracy\n",
      "21/21 - 0s - loss: 0.0697 - accuracy: 0.9313 - 39ms/epoch - 2ms/step\n",
      "====== Final_model =======\n",
      "train loss, train accuracy\n",
      "84/84 - 0s - loss: 0.0677 - accuracy: 0.9327 - 86ms/epoch - 1ms/step\n",
      "validation loss, validation accuracy\n",
      "21/21 - 0s - loss: 0.0675 - accuracy: 0.9326 - 38ms/epoch - 2ms/step\n",
      "====== Final_model =======\n",
      "train loss, train accuracy\n",
      "84/84 - 0s - loss: 0.0701 - accuracy: 0.9298 - 97ms/epoch - 1ms/step\n",
      "validation loss, validation accuracy\n",
      "21/21 - 0s - loss: 0.0692 - accuracy: 0.9305 - 40ms/epoch - 2ms/step\n",
      "0.9297221779823304\n"
     ]
    }
   ],
   "source": [
    "# to check\n",
    "# 인터넷 구현 모델\n",
    "\n",
    "# optimizer 구현 부분\n",
    "schedule = tensorflow.optimizers.schedules.PiecewiseConstantDecay(\n",
    "                [100, 150], [1e-0, 1e-1, 1e-2])\n",
    "step = tf.Variable(0, trainable=False)\n",
    "wd = lambda: 1e-3 * schedule(step)\n",
    "optimizer = AdamW(learning_rate=0.001, weight_decay=wd)\n",
    "def custom_opt(n):\n",
    "    schedule = tensorflow.optimizers.schedules.PiecewiseConstantDecay([100, 150], [1e-0, 1e-1, 1e-2])\n",
    "    step = tf.Variable(0, trainable=False)\n",
    "    wd = lambda: 1e-3 * schedule(step)\n",
    "    opt = AdamW(learning_rate = n, weight_decay = wd)\n",
    "    return opt\n",
    "\n",
    "# custom_metric 구현 - log scale 고려\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.math.exp(y_true)\n",
    "    y_pred = tf.math.exp(y_pred)\n",
    "    return 1 - tf.abs((y_true - y_pred) / y_true)\n",
    "check = []\n",
    "\n",
    "for _ in range(5):\n",
    "    # 모델 구현\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='elu', input_dim=X_train_scaled.shape[1]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))              \n",
    "    model.add(Dense(16, activation='elu'))\n",
    "    model.add(Dense(16, activation='elu'))\n",
    "    model.add(Dense(1, activation='elu'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(loss='mae', optimizer=optimizer , metrics=[accuracy])\n",
    "\n",
    "    # early stopping 구현추가\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs=1000, batch_size=256, validation_data=(X_val_scaled, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "\n",
    "    print(\"====== Final_model =======\")\n",
    "    print(\"train loss, train accuracy\")\n",
    "    train_loss, train_acc = model.evaluate(X_train_scaled, y_train, verbose =2)\n",
    "\n",
    "    print(\"validation loss, validation accuracy\")\n",
    "    val_loss, val_acc = model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "    check.append(val_acc)\n",
    "\n",
    "print(np.mean(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy : 0.9340 // validation accuracy 0.9325\n",
    "\n",
    "# normalize 한 값이 더 좋음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 최적의 파라미터 및 은닉층, 노드수 계산 모델\n",
    "\n",
    "- optimizer의 경우 속도 면에서는 rmsprop, sgd가 좋았고, adam은 성능 부분에서 더 좋았음. → learning rate를 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_opt2(n):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=n)\n",
    "    return opt\n",
    "\n",
    "best_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9334 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9352 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.9579 - accuracy: 0.3828 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0078 - accuracy: 0.9351 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9366 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.9579 - accuracy: 0.3828 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.9579 - accuracy: 0.3828 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9306 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9200 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9330 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0091 - accuracy: 0.9240 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0089 - accuracy: 0.9323 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0108 - accuracy: 0.9123 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9350 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.9579 - accuracy: 0.3828 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9341 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9348 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.9579 - accuracy: 0.3828 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9338 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9351 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9363 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9361 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9352 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0080 - accuracy: 0.9288 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9338 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9203 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9329 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9355 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9336 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9349 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0103 - accuracy: 0.9285 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0110 - accuracy: 0.9219 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0111 - accuracy: 0.9218 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9309 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9315 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9300 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0102 - accuracy: 0.9267 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9281 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9312 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9311 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9318 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9321 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9319 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9320 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0286 - accuracy: 0.9188 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9328 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9319 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9308 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9323 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0102 - accuracy: 0.9278 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9316 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9320 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9315 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9308 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9327 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9318 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9307 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9326 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9310 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9315 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8945 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0185 - accuracy: 0.8940 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8952 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8950 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8950 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8952 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8949 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8950 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8950 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8954 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8963 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8968 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8955 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8960 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8951 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8955 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8970 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8974 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8962 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8950 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8961 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8973 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8977 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8975 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8965 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8962 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8974 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8976 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8977 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8978 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.3019 - accuracy: 0.8457 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0186 - accuracy: 0.8974 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9198 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9358 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9371 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9345 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9363 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9319 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9329 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9359 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9363 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9357 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9361 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9343 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9325 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9309 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9322 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9329 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0089 - accuracy: 0.9198 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9344 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9368 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0078 - accuracy: 0.9313 - 55ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9358 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9344 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0078 - accuracy: 0.9332 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9366 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9336 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9328 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9347 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9347 - 36ms/epoch - 2ms/step\n",
      "Best hyperparameters: {'activation': 'elu', 'batch_size': 8, 'learning_rate': 0.001}\n",
      "Best validation accuracy: 0.9370531439781189\n",
      "Best time: 2.2029964923858643\n",
      "time hyper_params: {'activation': 'sigmoid', 'batch_size': 128, 'learning_rate': 0.009}\n"
     ]
    }
   ],
   "source": [
    "# a. Dropout 미사용 (순정)\n",
    "\n",
    "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용)\n",
    "act_func = ['relu', 'tanh', 'sigmoid', 'elu']\n",
    "batch_lst = [8, 32, 64, 128, 256]\n",
    "opt_lst = [0.01, 0.009, 0.006, 0.003, 0.001, 0.0005]\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            # 모델 구현\n",
    "            model = Sequential()\n",
    "            model.add(Dense(256, activation=func, input_dim=X_train.shape[1]))\n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(Dense(64, activation=func))\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(1, activation=func))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(loss='mse', optimizer=custom_opt2(opti), metrics=[accuracy])\n",
    "\n",
    "            # early stopping 구현 - 커스텀 정확도 기준\n",
    "            early_stopping = EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            cal_time = end_time - start_time\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'learning_rate': opti}\n",
    "\n",
    "            if cal_time < best_time:\n",
    "                best_time = cal_time\n",
    "                time_hyper = {'activation': func, 'batch_size': batch, 'learning_rate': opti}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "best_lst.append(best_accuracy)\n",
    "\n",
    "print('Best time:', best_time)\n",
    "print('time hyper_params:', time_hyper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 0s - loss: 0.0083 - accuracy: 0.9283 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0087 - accuracy: 0.9243 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9350 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9310 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9368 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9374 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9361 - 33ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0084 - accuracy: 0.9231 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9360 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.9579 - accuracy: 0.3828 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0154 - accuracy: 0.9074 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0245 - accuracy: 0.8764 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0084 - accuracy: 0.9340 - 33ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9365 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9366 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9360 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0196 - accuracy: 0.8925 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0180 - accuracy: 0.8965 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0078 - accuracy: 0.9347 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9363 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0079 - accuracy: 0.9361 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9363 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0302 - accuracy: 0.8619 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0203 - accuracy: 0.8893 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9372 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0125 - accuracy: 0.9180 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0082 - accuracy: 0.9345 - 33ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0101 - accuracy: 0.9274 - 33ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0138 - accuracy: 0.9120 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0182 - accuracy: 0.8963 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0111 - accuracy: 0.9258 - 33ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0104 - accuracy: 0.9267 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0105 - accuracy: 0.9246 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0101 - accuracy: 0.9270 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9321 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9313 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9291 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0105 - accuracy: 0.9283 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9303 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0099 - accuracy: 0.9286 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9323 - 33ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9327 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9321 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9312 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9319 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9323 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9322 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9321 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9325 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9319 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9291 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9323 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9327 - 34ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9329 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9317 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9302 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9327 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9323 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9321 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9312 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8947 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8945 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8951 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8943 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8949 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8952 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8949 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8949 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8945 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8960 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8959 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8965 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8954 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8953 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8957 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8955 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8973 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8967 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9317 - 51ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8972 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8968 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8971 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8974 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8975 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8961 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8960 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8969 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8970 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8977 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0185 - accuracy: 0.8979 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0186 - accuracy: 0.8936 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0184 - accuracy: 0.8975 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0118 - accuracy: 0.9197 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0089 - accuracy: 0.9267 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9369 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9287 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9368 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0083 - accuracy: 0.9252 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9346 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9367 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9361 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9313 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9373 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9342 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9330 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9354 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9367 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9373 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9361 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9350 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9299 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0067 - accuracy: 0.9375 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9375 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9348 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9285 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9315 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0067 - accuracy: 0.9372 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9327 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9322 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9362 - 42ms/epoch - 2ms/step\n",
      "Best hyperparameters: {'activation': 'elu', 'batch_size': 128, 'learning_rate': 0.003}\n",
      "Best validation accuracy: 0.9375010132789612\n",
      "Best time: 2.387566566467285\n",
      "time hyper_params: {'activation': 'relu', 'batch_size': 256, 'learning_rate': 0.009}\n"
     ]
    }
   ],
   "source": [
    "# b. Dropout 사용\n",
    "\n",
    "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용)\n",
    "act_func = ['relu', 'tanh', 'sigmoid', 'elu']\n",
    "batch_lst = [8, 32, 64, 128, 256]\n",
    "opt_lst = [0.01, 0.009, 0.006, 0.003, 0.001, 0.0005]\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            # 모델 구현\n",
    "            model = Sequential()\n",
    "            model.add(Dense(256, activation=func, input_dim=X_train.shape[1]))\n",
    "            model.add(Dropout(0.2)) # Dropout 추가\n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(Dropout(0.2)) # Dropout 추가\n",
    "            model.add(Dense(64, activation=func))\n",
    "            model.add(Dropout(0.2)) # Dropout 추가\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(1, activation=func))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(loss='mse', optimizer=custom_opt2(opti), metrics=[accuracy])\n",
    "\n",
    "            # early stopping 구현 - 커스텀 정확도 기준\n",
    "            early_stopping = EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            cal_time = end_time - start_time\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'learning_rate': opti}\n",
    "\n",
    "            if cal_time < best_time:\n",
    "                best_time = cal_time\n",
    "                time_hyper = {'activation': func, 'batch_size': batch, 'learning_rate': opti}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "best_lst.append(best_accuracy)\n",
    "\n",
    "print('Best time:', best_time)\n",
    "print('time hyper_params:', time_hyper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 0s - loss: 0.0105 - accuracy: 0.9182 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9200 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9312 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9359 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9350 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9346 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0078 - accuracy: 0.9308 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9361 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9342 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0078 - accuracy: 0.9326 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9364 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9346 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9324 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9366 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0078 - accuracy: 0.9352 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9349 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9375 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.9579 - accuracy: 0.3828 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9368 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9367 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9361 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9364 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0080 - accuracy: 0.9346 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9371 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9335 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0066 - accuracy: 0.9374 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9367 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0067 - accuracy: 0.9367 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9343 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9363 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0108 - accuracy: 0.9237 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0105 - accuracy: 0.9250 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0131 - accuracy: 0.9142 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0099 - accuracy: 0.9299 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9295 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9314 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9320 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0112 - accuracy: 0.9260 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9317 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9301 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9310 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9324 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9307 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9328 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9302 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9317 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9322 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9306 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9322 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9307 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9310 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9322 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9319 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0103 - accuracy: 0.9269 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9308 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9319 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9306 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9319 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0103 - accuracy: 0.9272 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0114 - accuracy: 0.9210 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0099 - accuracy: 0.9281 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0109 - accuracy: 0.9253 - 35ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0102 - accuracy: 0.9297 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9284 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9318 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9310 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9318 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9297 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9327 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9297 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9308 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9307 - 47ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9306 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9307 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9316 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9303 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0100 - accuracy: 0.9295 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0100 - accuracy: 0.9285 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9300 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9295 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9301 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0099 - accuracy: 0.9294 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0102 - accuracy: 0.9280 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0107 - accuracy: 0.9262 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0100 - accuracy: 0.9285 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9307 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0099 - accuracy: 0.9294 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0100 - accuracy: 0.9280 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0109 - accuracy: 0.9256 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0109 - accuracy: 0.9253 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0079 - accuracy: 0.9305 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9234 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9291 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9365 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9316 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0081 - accuracy: 0.9262 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9304 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9328 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9360 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9341 - 47ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9358 - 46ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9360 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0085 - accuracy: 0.9228 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9333 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9376 - 48ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9322 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9332 - 51ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9310 - 55ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9362 - 47ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0078 - accuracy: 0.9291 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9378 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9346 - 51ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0082 - accuracy: 0.9257 - 54ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9324 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9353 - 57ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9339 - 53ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9352 - 48ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9360 - 56ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9365 - 46ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9314 - 50ms/epoch - 2ms/step\n",
      "Best hyperparameters: {'activation': 'elu', 'batch_size': 128, 'learning_rate': 0.006}\n",
      "Best validation accuracy: 0.9377886652946472\n",
      "Best time: 3.8067638874053955\n",
      "time hyper_params: {'activation': 'relu', 'batch_size': 64, 'learning_rate': 0.0005}\n"
     ]
    }
   ],
   "source": [
    "# c. Dropout, batchNormalize 사용\n",
    "\n",
    "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용)\n",
    "act_func = ['relu', 'tanh', 'sigmoid', 'elu']\n",
    "batch_lst = [8, 32, 64, 128, 256]\n",
    "opt_lst = [0.01, 0.009, 0.006, 0.003, 0.001, 0.0005]\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            # 모델 구현\n",
    "            model = Sequential()\n",
    "            model.add(Dense(256, activation=func, input_dim=X_train.shape[1]))\n",
    "            model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(64, activation=func))\n",
    "            model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(1, activation=func))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(loss='mse', optimizer=custom_opt2(opti), metrics=[accuracy])\n",
    "\n",
    "            # early stopping 구현 - 커스텀 정확도 기준\n",
    "            early_stopping = EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            cal_time = end_time - start_time\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'learning_rate': opti}\n",
    "\n",
    "            if cal_time < best_time:\n",
    "                best_time = cal_time\n",
    "                time_hyper = {'activation': func, 'batch_size': batch, 'learning_rate': opti}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "best_lst.append(best_accuracy)\n",
    "\n",
    "print('Best time:', best_time)\n",
    "print('time hyper_params:', time_hyper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 0s - loss: 0.0079 - accuracy: 0.9333 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0078 - accuracy: 0.9313 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9262 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9349 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9301 - 49ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9340 - 48ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9346 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0079 - accuracy: 0.9323 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9340 - 47ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9317 - 56ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9348 - 47ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9366 - 59ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9337 - 57ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9355 - 55ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9348 - 57ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9343 - 77ms/epoch - 4ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9360 - 50ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9373 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9336 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9376 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9371 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9346 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0082 - accuracy: 0.9342 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0079 - accuracy: 0.9335 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0083 - accuracy: 0.9336 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.9579 - accuracy: 0.3828 - 51ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.9579 - accuracy: 0.3828 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9342 - 48ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0079 - accuracy: 0.9357 - 46ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9327 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0137 - accuracy: 0.9132 - 46ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0113 - accuracy: 0.9228 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0104 - accuracy: 0.9264 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0103 - accuracy: 0.9261 - 46ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9319 - 53ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9326 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9318 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9317 - 55ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9320 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9327 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9317 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9321 - 46ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9283 - 49ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9312 - 49ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9320 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0099 - accuracy: 0.9281 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9313 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9310 - 49ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9322 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9315 - 48ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9312 - 72ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9298 - 49ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9313 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9321 - 49ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9318 - 46ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0108 - accuracy: 0.9269 - 47ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9314 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9319 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9301 - 50ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9311 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9301 - 48ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0103 - accuracy: 0.9265 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0104 - accuracy: 0.9280 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9323 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9329 - 50ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 0.9330 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9296 - 49ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0099 - accuracy: 0.9276 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9316 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0094 - accuracy: 0.9315 - 47ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9299 - 54ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9307 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0180 - accuracy: 0.8966 - 40ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8954 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0101 - accuracy: 0.9275 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9310 - 47ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9300 - 55ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0099 - accuracy: 0.9289 - 54ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8956 - 59ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0182 - accuracy: 0.8960 - 51ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 0.9299 - 57ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0097 - accuracy: 0.9304 - 52ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0107 - accuracy: 0.9261 - 59ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0100 - accuracy: 0.9285 - 49ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8970 - 64ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 0.8968 - 64ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0182 - accuracy: 0.8968 - 65ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0104 - accuracy: 0.9264 - 47ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0108 - accuracy: 0.9256 - 50ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0106 - accuracy: 0.9266 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0116 - accuracy: 0.9141 - 46ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0095 - accuracy: 0.9288 - 61ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0098 - accuracy: 0.9154 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9362 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0093 - accuracy: 0.9264 - 54ms/epoch - 3ms/step\n",
      "21/21 - 0s - loss: 0.0082 - accuracy: 0.9254 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0088 - accuracy: 0.9242 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0089 - accuracy: 0.9308 - 50ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9344 - 43ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9372 - 46ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9365 - 46ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9363 - 51ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9298 - 45ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9309 - 48ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9354 - 44ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9349 - 49ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9361 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9333 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0076 - accuracy: 0.9298 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0075 - accuracy: 0.9329 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0074 - accuracy: 0.9337 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0070 - accuracy: 0.9354 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9366 - 52ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0073 - accuracy: 0.9327 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0080 - accuracy: 0.9339 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9373 - 41ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9362 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9371 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9363 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9341 - 38ms/epoch - 2ms/step\n",
      "Best hyperparameters: {'activation': 'relu', 'batch_size': 128, 'learning_rate': 0.009}\n",
      "Best validation accuracy: 0.9375995397567749\n",
      "Best time: 3.9070000648498535\n",
      "time hyper_params: {'activation': 'relu', 'batch_size': 256, 'learning_rate': 0.009}\n"
     ]
    }
   ],
   "source": [
    "# d. 모델 구조 변경 (다이아몬드)\n",
    "\n",
    "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용)\n",
    "act_func = ['relu', 'tanh', 'sigmoid', 'elu']\n",
    "batch_lst = [8, 32, 64, 128, 256]\n",
    "opt_lst = [0.01, 0.009, 0.006, 0.003, 0.001, 0.0005]\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            # 모델 구현\n",
    "            model = Sequential()\n",
    "            model.add(Dense(32, activation=func, input_dim=X_train.shape[1]))\n",
    "            model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(256, activation=func))\n",
    "            model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(64, activation=func))\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(1, activation=func))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(loss='mse', optimizer=custom_opt2(opti), metrics=[accuracy])\n",
    "\n",
    "            # early stopping 구현 - 커스텀 정확도 기준\n",
    "            early_stopping = EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            cal_time = end_time - start_time\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'learning_rate': opti}\n",
    "\n",
    "            if cal_time < best_time:\n",
    "                best_time = cal_time\n",
    "                time_hyper = {'activation': func, 'batch_size': batch, 'learning_rate': opti}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "best_lst.append(best_accuracy)\n",
    "\n",
    "print('Best time:', best_time)\n",
    "print('time hyper_params:', time_hyper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 최종 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9369 - 36ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9293 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9367 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0071 - accuracy: 0.9371 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9368 - 37ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0083 - accuracy: 0.9338 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0068 - accuracy: 0.9378 - 38ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0069 - accuracy: 0.9378 - 39ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 0.9353 - 42ms/epoch - 2ms/step\n",
      "21/21 - 0s - loss: 0.0081 - accuracy: 0.9340 - 38ms/epoch - 2ms/step\n",
      "Best hyperparameters: {'activation': 'relu', 'batch_size': 256, 'learning_rate': 0.009}\n",
      "Best validation accuracy: 0.9377842545509338\n",
      "Best time: 4.463998556137085\n",
      "time hyper_params: {'activation': 'relu', 'batch_size': 256, 'learning_rate': 0.006}\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters: {'activation': 'relu', 'batch_size': 128, 'learning_rate': 0.01}\n",
    "# Best validation accuracy: 0.9382919073104858\n",
    "# Best time: 4.589000701904297\n",
    "# time hyper_params: {'activation': 'relu', 'batch_size': 128, 'learning_rate': 0.009}\n",
    "\n",
    "# c. Dropout, batchNormalize 사용\n",
    "\n",
    "# 최고의 모델 찾기 - 검증 데이터와 표준화 진행한 데이터로 성능 구현(dropout사용)\n",
    "\n",
    "act_func = ['relu']\n",
    "batch_lst = [128, 256]\n",
    "opt_lst = [0.01, 0.009, 0.006, 0.003, 0.001]\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "best_time = 11111.0\n",
    "time_hyper = {}\n",
    "\n",
    "for func in act_func:\n",
    "    for batch in batch_lst:\n",
    "        for opti in opt_lst:\n",
    "            # 모델 구현\n",
    "            model = Sequential()\n",
    "            model.add(Dense(256, activation=func, input_dim=X_train.shape[1]))\n",
    "            model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(128, activation=func))\n",
    "            model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(64, activation=func))\n",
    "            model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(32, activation=func))\n",
    "            model.add(Dense(16, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(8, activation=func))\n",
    "            model.add(Dense(1, activation=func))\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(loss='mse', optimizer=custom_opt2(opti), metrics=[accuracy])\n",
    "\n",
    "            # early stopping 구현 - 커스텀 정확도 기준\n",
    "            early_stopping = EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=batch, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "            end_time = time.time()\n",
    "            cal_time = end_time - start_time\n",
    "            loss, acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_hyperparams = {'activation': func, 'batch_size': batch, 'learning_rate': opti}\n",
    "\n",
    "            if cal_time < best_time:\n",
    "                best_time = cal_time\n",
    "                time_hyper = {'activation': func, 'batch_size': batch, 'learning_rate': opti}\n",
    "\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "print('Best validation accuracy:', best_accuracy)\n",
    "best_lst.append(best_accuracy)\n",
    "\n",
    "print('Best time:', best_time)\n",
    "print('time hyper_params:', time_hyper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Final Model ====\n",
      "걸린시간 : 7.3850014209747314\n",
      "==== train los acc ====\n",
      "84/84 - 0s - loss: 0.0070 - accuracy: 0.9387 - 140ms/epoch - 2ms/step\n",
      "==== val los acc ====\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9367 - 52ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters: {'activation': 'elu', 'batch_size': 128, 'learning_rate': 0.006}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='elu', input_dim=X_train.shape[1]))\n",
    "model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='elu'))\n",
    "model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(Dense(16, activation='elu'))\n",
    "model.add(Dense(8, activation='elu'))\n",
    "model.add(Dense(8, activation='elu'))\n",
    "model.add(Dense(1, activation='elu'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='mse', optimizer=custom_opt2(0.006), metrics=[accuracy])\n",
    "\n",
    "# early stopping 구현 - 커스텀 정확도 기준\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=128, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"==== Final Model ====\")\n",
    "print(\"걸린시간 :\",end_time-start_time)\n",
    "print(\"==== train los acc ====\")\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose = 2)\n",
    "print(\"==== val los acc ====\")\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Final Model ====\n",
      "걸린시간 : 5.8289971351623535\n",
      "==== train los acc ====\n",
      "84/84 - 0s - loss: 0.0069 - accuracy: 0.9380 - 127ms/epoch - 2ms/step\n",
      "==== val los acc ====\n",
      "21/21 - 0s - loss: 0.0072 - accuracy: 0.9347 - 61ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters: {'activation': 'relu', 'batch_size': 128, 'learning_rate': 0.009}\n",
    "\n",
    "# 모델 구현\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())  # BatchNormalization 추가\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='mse', optimizer=custom_opt2(0.009), metrics=[accuracy])\n",
    "\n",
    "# early stopping 구현 - 커스텀 정확도 기준\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=128, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose = 0)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"==== Final Model ====\")\n",
    "print(\"걸린시간 :\",end_time-start_time)\n",
    "print(\"==== train los acc ====\")\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose = 2)\n",
    "print(\"==== val los acc ====\")\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
