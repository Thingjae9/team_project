{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2oHp_ri7KN0u"
      },
      "outputs": [],
      "source": [
        "import csv \n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RND_MEAN = 0\n",
        "RND_STD = 1.0\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# method definition\n",
        "def main(epoch_count=30, mb_size=30, report=1, train_ratio=0.8):\n",
        "    load_dataset()\n",
        "    init_param()\n",
        "    train_and_test(epoch_count, mb_size, report, train_ratio)\n",
        "\n",
        "\n",
        "\n",
        "# method definition\n",
        "def load_dataset():\n",
        "    with open('Regression_data.csv') as csvfile:\n",
        "        csvreader = csv.reader(csvfile)\n",
        "        next(csvreader)\n",
        "        rows = []\n",
        "        for row in csvreader:\n",
        "            rows.append(row)\n",
        "    \n",
        "    global data, input_cnt, output_cnt\n",
        "    input_cnt, output_cnt = 10, 1\n",
        "    \n",
        "    data = np.zeros([len(rows), input_cnt + output_cnt])\n",
        "    for n, row in enumerate(rows):\n",
        "        if row[0] == 'M':\n",
        "            data[n, 0] = 1\n",
        "        if row[0] == 'F':\n",
        "            data[n, 1] = 1\n",
        "        if row[0] == 'I':\n",
        "            data[n, 2] = 1\n",
        "        data[n, 3:] = row[1:]\n",
        "\n",
        "    # Data normalization\n",
        "    # data[:, 3:] = (data[:, 3:] - np.mean(data[:, 3:], axis=0)) / np.std(data[:, 3:], axis=0)\n",
        "\n",
        "\n",
        "# method definition\n",
        "def init_param():\n",
        "    global weight, bias\n",
        "    weight = np.random.normal(RND_MEAN, RND_STD, [input_cnt, output_cnt])\n",
        "    bias = np.zeros([output_cnt])\n",
        "\n",
        "# method definition\n",
        "def forward_neuralnet(x):\n",
        "    y_hat = np.matmul(x, weight) + bias\n",
        "    print(\"y_hat: \", y_hat)\n",
        "    return y_hat, x\n",
        "\n",
        "# method definition\n",
        "def forward_postproc(y_hat, y):\n",
        "    diff = y_hat - y\n",
        "    square = np.square(diff)\n",
        "    loss = np.mean(square)\n",
        "    return loss, diff\n",
        "\n",
        "# method definition\n",
        "def eval_accuracy(y_hat, y):\n",
        "    mdiff = np.mean(np.abs((y_hat - y) / y))\n",
        "    return 1 - mdiff\n",
        "\n",
        "def backprop_neuralnet(G_output, x):\n",
        "    global weight, bias\n",
        "    x_transpose = x.transpose()\n",
        "    G_w = np.matmul(x_transpose, G_output)\n",
        "    G_b = np.sum(G_output, axis=0)\n",
        "    weight -= LEARNING_RATE * G_w\n",
        "    bias -= LEARNING_RATE * G_b\n",
        "\n",
        "def backprop_postproc(diff):\n",
        "    M_N = diff.shape\n",
        "    g_mse_square = np.ones(M_N) / np.prod(M_N)\n",
        "    g_square_diff = 2 * diff\n",
        "    g_diff_output = 1\n",
        "    G_diff = g_mse_square * g_square_diff\n",
        "    G_output = g_diff_output * G_diff\n",
        "    return G_output\n",
        "\n",
        "# Override method\n",
        "def run_train(x, y):\n",
        "    \n",
        "    y_hat, aux_nn_x = forward_neuralnet(x)\n",
        "    print(y_hat)\n",
        "    loss, aux_pp_diff = forward_postproc(y_hat, y)\n",
        "    accuracy = eval_accuracy(y_hat, y)\n",
        "    G_output = backprop_postproc(aux_pp_diff)\n",
        "    backprop_neuralnet(G_output, aux_nn_x)\n",
        "    return loss, accuracy\n",
        "\n",
        "# Override method\n",
        "def run_test(x, y):\n",
        "    \n",
        "    y_hat, _ = forward_neuralnet(x)\n",
        "    accuracy = eval_accuracy(y_hat, y)\n",
        "    return accuracy\n",
        "\n",
        "# New method definition\n",
        "def batch_normalization(x):\n",
        "    mean = np.mean(x, axis=0)\n",
        "    std = np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3N6h7MFKj4Y"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의 \n",
        "def arrange_data(mb_size, train_ratio):\n",
        "    \n",
        "    # 활용 빈도가 높은 변수들은 전역변수로 할당하며, 활용빈도가 낮은 변수의 경우 반환처리 하였습니다. \n",
        "    global data, shuffle_map, test_begin_index\n",
        "\n",
        "    '''세부 기능 1)전체 데이터의 인덱싱 생성 후 셔플링.'''\n",
        "    # 실험에 쓰일 데이터(data)의 수에 맞게 인덱싱(0,1,2,3,...)을 생성하는 과정 입니다.\n",
        "    # 입출력 예시\n",
        "    # >>>data.shape[0] \n",
        "    # 20\n",
        "    shuffle_map = np.arange(data.shape[0])\n",
        "    # 학습의 효율을 높여주기 위해 인덱싱(shuffle_map)을 뒤섞어 줍니다.\n",
        "    np.random.shuffle(shuffle_map)\n",
        "\n",
        "    '''세부 기능 2)1에폭에 필요한 미니배치의 수 연산.'''\n",
        "    # 1 에폭을 위한 미니배치의 수(mini_batch_step_count)는 \n",
        "    # 전체 데이터(data.shape[0])에서 학습 데이터의 비율(train_ratio)만큼의 개수를 구한 후 \n",
        "    # 미니배치 크기(mb_size)로 나눠 몫 만을 구해줍니다. \n",
        "    # ( ※ mb_size 는 하나의 미니배치에 포함된 데이터의 수 입니다.)\n",
        "    mini_batch_step_count = int(data.shape[0] * train_ratio) // mb_size\n",
        "\n",
        "    '''세부 기능 3)학습 데이터와 테스트 데이터의 경계 인덱스를 구함.'''\n",
        "    # 전체 데이터에서 학습 데이터와 테스트 데이터가 나뉘는 경계가 되는 인덱스를 \n",
        "    # 테스트 데이터가 시작되는 인덱스로 설정하였습니다. \n",
        "    # 이 값을 구하기 위해서는 다양한 방식이 있지만, \n",
        "    # 미니배치 스탭 수(mini_batch_step_count)와 미니배치 크기(mb_size)를 곱해 \n",
        "    # 학습 및 테스트 데이터 경계 인덱스(test_begin_index)를 구해줍니다.\n",
        "    test_begin_index = mini_batch_step_count * mb_size\n",
        "    \n",
        "\n",
        "    # 다수의 변수가 생성되었지만 mini_batch_step_count 변수만 밖으로 반환합니다.\n",
        "    # 활용 빈도가 높은 변수들은 전역변수로 할당하며, 활용빈도가 낮은 변수의 경우 반환처리 하였습니다. \n",
        "    return mini_batch_step_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BIQWDx2TN9-c"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def get_train_data(mb_size, nth):\n",
        "    \n",
        "    # 학습 데이터의 경우 새로운 Epoch 의 학습이 수행되기 전(if nth == 0)\n",
        "    # 학습 데이터 인덱싱 정보를 무작위로 섞어(np.random.shuffle()) 학습의 효과를 높여줍니다.\n",
        "    # 학습의 효과를 높여주는 선행 연구에 근거함\n",
        "    if nth == 0:\n",
        "        np.random.shuffle(shuffle_map[:test_begin_index])\n",
        "\n",
        "    # 학습 데이터의 분리는 미니배치를 고려해야 합니다. \n",
        "    # 전체 데이터(data)에서 뒤섞인 인덱싱값으로 접근(shuffle_map)하여 미니배치 처리를 수행합니다.\n",
        "    # 만약 미니배치 사이즈(mb_size) 값이 4 라면 다음과 같이 나눠볼 수 있습니다. \n",
        "    # 0 : 4\n",
        "    # 4 : 8\n",
        "    # 8 : 12\n",
        "    # 12 : 16\n",
        "    # 그리고 이와 같은 배수의 연산을 위한 수식을 미니배치 크기(mb_size)와 몇 번째 미니배치 처리 단계(nth) 값을 활용합니다.\n",
        "    train_data = data[shuffle_map[mb_size * nth : mb_size * (nth+1)]]\n",
        "    \n",
        "    # 미니배치에 따라 나눠진 학습 데이터를 입출력 벡터로 나눠 반환합니다. \n",
        "    return train_data[:,:-output_cnt], train_data[:,-output_cnt:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bHtS82_IN58O"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def get_test_data():\n",
        "\n",
        "    \"\"\" 전체 데이터에서 테스트 데이터 분리 과정 \"\"\"\n",
        "    # 전체 데이터(data)의 인덱싱 정보를 갖고 있는 변수(shuffle_map)에 접근하여 테스트 데이터를 얻어냅니다. \n",
        "    # 테스트 데이터의 경우 테스트 데이터의 시작 인덱싱 위치(test_begin_index)를 기준으로 인덱싱 끝 까지 범위를 갖도록 합니다. \n",
        "    test_data = data[shuffle_map[test_begin_index:]]\n",
        "\n",
        "    \"\"\" 테스트 데이터에서 입출력 벡터 분리 과정 \"\"\"\n",
        "    # test_data 변수는 입출력 벡터를 포함한 테스트 데이터 입니다. \n",
        "    # 그렇기에 입출력 벡터를 분리하기 위한 과정을 수행하여야 합니다. \n",
        "    # 출력 계층 값을 담는 변수(output_cnt)를 활용하여 슬라이싱 과정을 수행합니다. \n",
        "    # 행은 모두 포함하지만 열의 경우 다음과 같이 구분할 수 있습니다.  \n",
        "    return test_data[:,:-output_cnt], test_data[:,-output_cnt:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sjKTLk6tKnDT"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의 \n",
        "def train_and_test(epoch_count, mb_size, report, train_ratio):\n",
        "    \n",
        "    '''1) 데이터 셔플링 - arrange_data()'''\n",
        "    # 메서드를 통해 데이터를 섞어주고 1 에폭에 필요한 미니배치 수 를 반환합니다. \n",
        "    mini_batch_step_count = arrange_data(mb_size,train_ratio)\n",
        "\n",
        "    '''2) 테스트 데이터 분리 - get_test_data()'''\n",
        "    # 학습 데이터는 미니배치를 고려하여야 하기에 \n",
        "    # 미니배치 고려가 필요 없는 테스트 데이터 분리 메서드를 먼저 배치합니다. \n",
        "    test_x, test_y = get_test_data()\n",
        "\n",
        "    # 다음은 학습 및 테스트 수행 단계를 정의하는 과정 입니다.\n",
        "    # 학습은 사용자가 지정한 학습횟수(에폭-epoch_count)에 맞춰 학습을 반복하도록 정의합니다. \n",
        "    for epoch in range(epoch_count):\n",
        "\n",
        "        # 학습 진행에 따른 정보를 담기 위해 빈 리스트를 사전에 정의하여 줍니다. \n",
        "        losses, accs = [], []\n",
        "\n",
        "        # 1 에폭이 수행되기 위해서는 미니배치 처리에 따른 학습이 모두 완료되어야 합니다. \n",
        "        # 그리고 에폭은 사용자가 1 이상의 값을 설정할 수 있어야 하므로, \n",
        "        # 이를 위한 이중 반복문 구조를 설계할 수 있습니다. \n",
        "        # 만약 학습 데이터의 수가 16개, 미니배치 크기(mb_size)가 4개라면 \n",
        "        # 1 에폭을 위해서는 총 4번(mini_batch_step_count)의 미니배치에 따른 학습이 수행되어야 합니다. \n",
        "        for nth in range(mini_batch_step_count):\n",
        "            \n",
        "            '''3) 학습 데이터 분리 - get_train_data()'''\n",
        "            # 학습 데이터의 경우 에폭마다의 미니배치 처리 단계(nth)를 고려하여 학습 데이터의 입출력 벡터를 변수화 합니다. \n",
        "            train_x, train_y = get_train_data(mb_size, nth)\n",
        "            \n",
        "            '''4) 학습 - run_train()'''\n",
        "            # 미니배치 처리 단계(nth)에 따른 학습 데이터의 입출력 벡터를 학습합니다.\n",
        "            # 지금은 run_train() 메서드의 이름만 정의해둔 상황입니다. \n",
        "            # 정리하면 미니배치 단계에 따라 임의로 설정한 고정된 실험 결과값을 반환합니다. \n",
        "            #TODO run_train() 메서드는 다음 과정에서 하위 메서드 정의\n",
        "            loss, acc = run_train(train_x,train_y)\n",
        "            \n",
        "            # 미니배치 단계에 따른 실험 결괏값(loss, acc)들을 append() 메서드로 묶어줍니다. \n",
        "            losses.append(loss)\n",
        "            accs.append(acc)\n",
        "\n",
        "        '''5) 테스트 - run_test()'''\n",
        "        # 테스트 과정은 사용자가 지정한 1 이상의 결과 보고 주기(report)에 따른 에폭 마다 수행하도록 합니다. \n",
        "        # 모든 에폭마다 테스트를 수행할 수도 있지만, 그건 효율적인 방식이 되지 못합니다. \n",
        "        \n",
        "        # 상황 예제 1) \n",
        "        # 만약 학습 반복 주기(에폭)를 10 이라 하며, 결과 보고 주기(report)를 2 라 하면 \n",
        "        # 다음과 같은 주기로 테스트 결과를 반환하도록 합니다.\n",
        "        # 0(x), 1(o), 2(x), 3(o), 4(x), 5(o), 6(x), 7(o), 8(x), 9(o) \n",
        "        \n",
        "        # 상황 예제 2) \n",
        "        # 만약 학습 반복 주기(에폭)를 10 이라 하며, 결과 보고 주기(report)를 3 이라 하면 \n",
        "        # 다음과 같은 주기로 테스트 결과를 반환하도록 합니다.\n",
        "        # 0(x), 1(x), 2(o), 3(x), 4(x), 5(o), 6(x), 7(x), 8(o), 9(x) \n",
        "        \n",
        "        # 이와같은 조건을 갖는 주기를 반환할 수 있도록 코드를 작성합니다. \n",
        "\n",
        "        # 이러한 경우 나머지를 반환하는 연산자와 비교 연산자를 활용할 수 있습니다. \n",
        "        if report > 0 and (epoch+1) % report == 0:\n",
        "            \n",
        "            # 위 조건에 부합하는 경우 테스트를 진행합니다. \n",
        "            acc = run_test(test_x, test_y)\n",
        "\n",
        "            # 수행한 결과를 사용자에게 출력합니다. \n",
        "            # 현재 에폭\n",
        "            # 현재 에폭에 따른 미니배치 단계별 결과의 학습 손실(loss) 평균값\n",
        "            # 현재 에폭에 따른 미니배치 단계별 결과의 학습 정확도(accs) 평균값\n",
        "            # 현재 에폭의 정확도(loss)\n",
        "            print(\"Epoch {}   : Train - Loss = {:.3f}, Accuracy = {:.3f} / Test - Accuracy = {:.3f}\".\\\n",
        "                  format(epoch+1, np.mean(losses), np.mean(accs), acc))\n",
        "            \n",
        "        \n",
        "    '''5) 최종 테스트 - run_test()'''\n",
        "    # 학습을 모두 마쳤다면 주어진 조건에 다른 모델 파라미터에 대한 조정이 완료되었다는 의미 입니다. \n",
        "    # 그렇기에 최종 테스트를 수행하여 학습을 모두 마친 AI 모델에 대한 성능 평가를 run_test() 메서드로 수행합니다. \n",
        "    final_acc = run_test(test_x, test_y)\n",
        "\n",
        "    # 학습에 따른 최종 결괏값 출력\n",
        "    print(\"=\"*30, ' Final TEST ', '='*30)\n",
        "    print('\\nFinal Accuracy = {:.3f}'.format(final_acc))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
